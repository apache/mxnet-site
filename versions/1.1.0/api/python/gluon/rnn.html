<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="Gluon Recurrent Neural Network API" property="og:title">
<meta content="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/og-logo.png" property="og:image">
<meta content="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/og-logo.png" property="og:image:secure_url">
<meta content="Gluon Recurrent Neural Network API" property="og:description"/>
<title>Gluon Recurrent Neural Network API — mxnet  documentation</title>
<link crossorigin="anonymous" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" rel="stylesheet"/>
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet"/>
<link href="../../../_static/basic.css" rel="stylesheet" type="text/css">
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mxnet.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
<script src="https://code.jquery.com/jquery-1.11.1.min.js" type="text/javascript"></script>
<script src="../../../_static/underscore.js" type="text/javascript"></script>
<script src="../../../_static/searchtools_custom.js" type="text/javascript"></script>
<script src="../../../_static/doctools.js" type="text/javascript"></script>
<script src="../../../_static/selectlang.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script type="text/javascript"> jQuery(function() { Search.loadIndex("/versions/1.1.0/searchindex.js"); Search.init();}); </script>
<script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new
      Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-96378503-1', 'auto');
      ga('send', 'pageview');

    </script>
<!-- -->
<!-- <script type="text/javascript" src="../../../_static/jquery.js"></script> -->
<!-- -->
<!-- <script type="text/javascript" src="../../../_static/underscore.js"></script> -->
<!-- -->
<!-- <script type="text/javascript" src="../../../_static/doctools.js"></script> -->
<!-- -->
<!-- <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<!-- -->
<link href="../../../genindex.html" rel="index" title="Index">
<link href="../../../search.html" rel="search" title="Search"/>
<link href="gluon.html" rel="up" title="Gluon Package"/>
<link href="loss.html" rel="next" title="Gluon Loss API"/>
<link href="nn.html" rel="prev" title="Gluon Neural Network Layers"/>
<link href="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet-icon.png" rel="icon" type="image/png"/>
</link></link></link></meta></meta></meta></head>
<body background="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet-background-compressed.jpeg" role="document">
<div class="content-block"><div class="navbar navbar-fixed-top">
<div class="container" id="navContainer">
<div class="innder" id="header-inner">
<h1 id="logo-wrap">
<a href="../../../" id="logo"><img src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/mxnet_logo.png"/></a>
</h1>
<nav class="nav-bar" id="main-nav">
<a class="main-nav-link" href="/versions/1.1.0/install/index.html">Install</a>
<span id="dropdown-menu-position-anchor">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">Gluon <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu">
<li><a class="main-nav-link" href="/versions/1.1.0/tutorials/gluon/gluon.html">About</a></li>
<li><a class="main-nav-link" href="https://www.d2l.ai/">Dive into Deep Learning</a></li>
<li><a class="main-nav-link" href="https://gluon-cv.mxnet.io">GluonCV Toolkit</a></li>
<li><a class="main-nav-link" href="https://gluon-nlp.mxnet.io/">GluonNLP Toolkit</a></li>
</ul>
</span>
<span id="dropdown-menu-position-anchor">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">API <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu">
<li><a class="main-nav-link" href="/versions/1.1.0/api/python/index.html">Python</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/api/c++/index.html">C++</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/api/julia/index.html">Julia</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/api/perl/index.html">Perl</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/api/r/index.html">R</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/api/scala/index.html">Scala</a></li>
</ul>
</span>
<span id="dropdown-menu-position-anchor-docs">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">Docs <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu-docs">
<li><a class="main-nav-link" href="/versions/1.1.0/faq/index.html">FAQ</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/tutorials/index.html">Tutorials</a>
<li><a class="main-nav-link" href="https://github.com/apache/incubator-mxnet/tree/v1.1.0/example">Examples</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/architecture/index.html">Architecture</a></li>
<li><a class="main-nav-link" href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home">Developer Wiki</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/model_zoo/index.html">Model Zoo</a></li>
<li><a class="main-nav-link" href="https://github.com/onnx/onnx-mxnet">ONNX</a></li>
</li></ul>
</span>
<span id="dropdown-menu-position-anchor-community">
<a aria-expanded="true" aria-haspopup="true" class="main-nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button">Community <span class="caret"></span></a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu-community">
<li><a class="main-nav-link" href="http://discuss.mxnet.io">Forum</a></li>
<li><a class="main-nav-link" href="https://github.com/apache/incubator-mxnet/tree/v1.1.0">Github</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/community/contribute.html">Contribute</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/community/powered_by.html">Powered By</a></li>
</ul>
</span>
<span id="dropdown-menu-position-anchor-version" style="position: relative"><a href="#" class="main-nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="true">1.1.0<span class="caret"></span></a><ul id="package-dropdown-menu" class="dropdown-menu"><li><a href="/">master</a></li><li><a href="/versions/1.7.0/">1.7.0</a></li><li><a href=/versions/1.6.0/>1.6.0</a></li><li><a href=/versions/1.5.0/>1.5.0</a></li><li><a href=/versions/1.4.1/>1.4.1</a></li><li><a href=/versions/1.3.1/>1.3.1</a></li><li><a href=/versions/1.2.1/>1.2.1</a></li><li><a href=/versions/1.1.0/>1.1.0</a></li><li><a href=/versions/1.0.0/>1.0.0</a></li><li><a href=/versions/0.12.1/>0.12.1</a></li><li><a href=/versions/0.11.0/>0.11.0</a></li></ul></span></nav>
<script> function getRootPath(){ return "../../../" } </script>
<div class="burgerIcon dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" role="button">☰</a>
<ul class="dropdown-menu" id="burgerMenu">
<li><a href="/versions/1.1.0/install/index.html">Install</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/tutorials/index.html">Tutorials</a></li>
<li class="dropdown-submenu dropdown">
<a aria-expanded="true" aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" tabindex="-1">Gluon</a>
<ul class="dropdown-menu navbar-menu" id="package-dropdown-menu">
<li><a class="main-nav-link" href="/versions/1.1.0/tutorials/gluon/gluon.html">About</a></li>
<li><a class="main-nav-link" href="http://gluon.mxnet.io">The Straight Dope (Tutorials)</a></li>
<li><a class="main-nav-link" href="https://gluon-cv.mxnet.io">GluonCV Toolkit</a></li>
<li><a class="main-nav-link" href="https://gluon-nlp.mxnet.io/">GluonNLP Toolkit</a></li>
</ul>
</li>
<li class="dropdown-submenu">
<a aria-expanded="true" aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" tabindex="-1">API</a>
<ul class="dropdown-menu">
<li><a class="main-nav-link" href="/versions/1.1.0/api/python/index.html">Python</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/api/c++/index.html">C++</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/api/julia/index.html">Julia</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/api/perl/index.html">Perl</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/api/r/index.html">R</a></li>
<li><a class="main-nav-link" href="/versions/1.1.0/api/scala/index.html">Scala</a></li>
</ul>
</li>
<li class="dropdown-submenu">
<a aria-expanded="true" aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" tabindex="-1">Docs</a>
<ul class="dropdown-menu">
<li><a href="/versions/1.1.0/faq/index.html" tabindex="-1">FAQ</a></li>
<li><a href="/versions/1.1.0/tutorials/index.html" tabindex="-1">Tutorials</a></li>
<li><a href="https://github.com/apache/incubator-mxnet/tree/v1.1.0/example" tabindex="-1">Examples</a></li>
<li><a href="/versions/1.1.0/architecture/index.html" tabindex="-1">Architecture</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home" tabindex="-1">Developer Wiki</a></li>
<li><a href="/versions/1.1.0/model_zoo/index.html" tabindex="-1">Gluon Model Zoo</a></li>
<li><a href="https://github.com/onnx/onnx-mxnet" tabindex="-1">ONNX</a></li>
</ul>
</li>
<li class="dropdown-submenu dropdown">
<a aria-haspopup="true" class="dropdown-toggle burger-link" data-toggle="dropdown" href="#" role="button" tabindex="-1">Community</a>
<ul class="dropdown-menu">
<li><a href="http://discuss.mxnet.io" tabindex="-1">Forum</a></li>
<li><a href="https://github.com/apache/incubator-mxnet/tree/v1.1.0" tabindex="-1">Github</a></li>
<li><a href="/versions/1.1.0/community/contribute.html" tabindex="-1">Contribute</a></li>
<li><a href="/versions/1.1.0/community/powered_by.html" tabindex="-1">Powered By</a></li>
</ul>
</li>
<li id="dropdown-menu-position-anchor-version-mobile" class="dropdown-submenu" style="position: relative"><a href="#" tabindex="-1">1.1.0</a><ul class="dropdown-menu"><li><a tabindex="-1" href=/>master</a></li><li><a tabindex="-1" href=/versions/1.6.0/>1.6.0</a></li><li><a tabindex="-1" href=/versions/1.5.0/>1.5.0</a></li><li><a tabindex="-1" href=/versions/1.4.1/>1.4.1</a></li><li><a tabindex="-1" href=/versions/1.3.1/>1.3.1</a></li><li><a tabindex="-1" href=/versions/1.2.1/>1.2.1</a></li><li><a tabindex="-1" href=/versions/1.1.0/>1.1.0</a></li><li><a tabindex="-1" href=/versions/1.0.0/>1.0.0</a></li><li><a tabindex="-1" href=/versions/0.12.1/>0.12.1</a></li><li><a tabindex="-1" href=/versions/0.11.0/>0.11.0</a></li></ul></li></ul>
</div>
<div class="plusIcon dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#" role="button"><span aria-hidden="true" class="glyphicon glyphicon-plus"></span></a>
<ul class="dropdown-menu dropdown-menu-right" id="plusMenu"></ul>
</div>
<div id="search-input-wrap">
<form action="../../../search.html" autocomplete="off" class="" method="get" role="search">
<div class="form-group inner-addon left-addon">
<i class="glyphicon glyphicon-search"></i>
<input class="form-control" name="q" placeholder="Search" type="text"/>
</div>
<input name="check_keywords" type="hidden" value="yes">
<input name="area" type="hidden" value="default"/>
</input></form>
<div id="search-preview"></div>
</div>
<div id="searchIcon">
<span aria-hidden="true" class="glyphicon glyphicon-search"></span>
</div>
<!-- <div id="lang-select-wrap"> -->
<!--   <label id="lang-select-label"> -->
<!--     <\!-- <i class="fa fa-globe"></i> -\-> -->
<!--     <span></span> -->
<!--   </label> -->
<!--   <select id="lang-select"> -->
<!--     <option value="en">Eng</option> -->
<!--     <option value="zh">中文</option> -->
<!--   </select> -->
<!-- </div> -->
<!--     <a id="mobile-nav-toggle">
        <span class="mobile-nav-toggle-bar"></span>
        <span class="mobile-nav-toggle-bar"></span>
        <span class="mobile-nav-toggle-bar"></span>
      </a> -->
</div>
</div>
</div>
<script type="text/javascript">
        $('body').css('background', 'white');
    </script>
<div class="container">
<div class="row">
<div aria-label="main navigation" class="sphinxsidebar leftsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Python Documents</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#ndarray-api">NDArray API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#symbol-api">Symbol API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#module-api">Module API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#autograd-api">Autograd API</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#gluon-api">Gluon API</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="gluon.html">Gluon Package</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="gluon.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="gluon.html#parameter">Parameter</a></li>
<li class="toctree-l4"><a class="reference internal" href="gluon.html#containers">Containers</a></li>
<li class="toctree-l4"><a class="reference internal" href="gluon.html#trainer">Trainer</a></li>
<li class="toctree-l4"><a class="reference internal" href="gluon.html#utilities">Utilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="gluon.html#api-reference">API Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nn.html">Gluon Neural Network Layers</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Gluon Recurrent Neural Network API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="#api-reference">API Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="loss.html">Gluon Loss API</a></li>
<li class="toctree-l3"><a class="reference internal" href="data.html">Gluon Data API</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_zoo.html">Gluon Model Zoo</a></li>
<li class="toctree-l3"><a class="reference internal" href="contrib.html">Gluon Contrib API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#kvstore-api">KVStore API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#io-api">IO API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#image-api">Image API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#optimization-api">Optimization API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#callback-api">Callback API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#metric-api">Metric API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#run-time-compilation-api">Run-Time Compilation API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#contrib-package">Contrib Package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../r/index.html">R Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../julia/index.html">Julia Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../c++/index.html">C++ Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../scala/index.html">Scala Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../perl/index.html">Perl Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq/index.html">HowTo Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architecture/index.html">System Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/index.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community/index.html">Community</a></li>
</ul>
</div>
</div>
<div class="content">
<div class="page-tracker"></div>
<div class="section" id="gluon-recurrent-neural-network-api">
<span id="gluon-recurrent-neural-network-api"></span><h1>Gluon Recurrent Neural Network API<a class="headerlink" href="#gluon-recurrent-neural-network-api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="overview">
<span id="overview"></span><h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>This document lists the recurrent neural network API in Gluon:</p>
<div class="section" id="recurrent-layers">
<span id="recurrent-layers"></span><h3>Recurrent Layers<a class="headerlink" href="#recurrent-layers" title="Permalink to this headline">¶</a></h3>
<p>Recurrent layers can be used in <code class="docutils literal"><span class="pre">Sequential</span></code> with other regular neural network layers.
For example, to construct a sequence labeling model where a prediction is made for each
time-step:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">name_scope</span><span class="p">():</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">20</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">flatten</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
<span class="n">model</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%"/>
<col width="90%"/>
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#mxnet.gluon.rnn.RNN" title="mxnet.gluon.rnn.RNN"><code class="xref py py-obj docutils literal"><span class="pre">RNN</span></code></a></td>
<td>Applies a multi-layer Elman RNN with <cite>tanh</cite> or <cite>ReLU</cite> non-linearity to an input sequence.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#mxnet.gluon.rnn.LSTM" title="mxnet.gluon.rnn.LSTM"><code class="xref py py-obj docutils literal"><span class="pre">LSTM</span></code></a></td>
<td>Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#mxnet.gluon.rnn.GRU" title="mxnet.gluon.rnn.GRU"><code class="xref py py-obj docutils literal"><span class="pre">GRU</span></code></a></td>
<td>Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="recurrent-cells">
<span id="recurrent-cells"></span><h3>Recurrent Cells<a class="headerlink" href="#recurrent-cells" title="Permalink to this headline">¶</a></h3>
<p>Recurrent cells allows fine-grained control when defining recurrent models. User
can explicit step and unroll to construct complex networks. It provides more
flexibility but is slower than recurrent layers. Recurrent cells can be stacked
with <code class="docutils literal"><span class="pre">SequentialRNNCell</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">SequentialRNNCell</span><span class="p">()</span>
<span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">name_scope</span><span class="p">():</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="mi">20</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="mi">20</span><span class="p">))</span>
<span class="n">states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">begin_state</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">states</span><span class="p">)</span>
    <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%"/>
<col width="90%"/>
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell" title="mxnet.gluon.rnn.RNNCell"><code class="xref py py-obj docutils literal"><span class="pre">RNNCell</span></code></a></td>
<td>Elman RNN recurrent neural network cell.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell" title="mxnet.gluon.rnn.LSTMCell"><code class="xref py py-obj docutils literal"><span class="pre">LSTMCell</span></code></a></td>
<td>Long-Short Term Memory (LSTM) network cell.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell" title="mxnet.gluon.rnn.GRUCell"><code class="xref py py-obj docutils literal"><span class="pre">GRUCell</span></code></a></td>
<td>Gated Rectified Unit (GRU) network cell.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell" title="mxnet.gluon.rnn.RecurrentCell"><code class="xref py py-obj docutils literal"><span class="pre">RecurrentCell</span></code></a></td>
<td>Abstract base class for RNN cells</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell" title="mxnet.gluon.rnn.SequentialRNNCell"><code class="xref py py-obj docutils literal"><span class="pre">SequentialRNNCell</span></code></a></td>
<td>Sequentially stacking multiple RNN cells.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell" title="mxnet.gluon.rnn.BidirectionalCell"><code class="xref py py-obj docutils literal"><span class="pre">BidirectionalCell</span></code></a></td>
<td>Bidirectional RNN cell.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell" title="mxnet.gluon.rnn.DropoutCell"><code class="xref py py-obj docutils literal"><span class="pre">DropoutCell</span></code></a></td>
<td>Applies dropout on input.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell" title="mxnet.gluon.rnn.ZoneoutCell"><code class="xref py py-obj docutils literal"><span class="pre">ZoneoutCell</span></code></a></td>
<td>Applies Zoneout on base cell.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell" title="mxnet.gluon.rnn.ResidualCell"><code class="xref py py-obj docutils literal"><span class="pre">ResidualCell</span></code></a></td>
<td>Adds residual connection as described in Wu et al, 2016 (<a class="reference external" href="https://arxiv.org/abs/1609.08144">https://arxiv.org/abs/1609.08144</a>).</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="api-reference">
<span id="api-reference"></span><h2>API Reference<a class="headerlink" href="#api-reference" title="Permalink to this headline">¶</a></h2>
<script src="../../_static/js/auto_module_index.js" type="text/javascript"></script><span class="target" id="module-mxnet.gluon.rnn"></span><p>Recurrent neural network module.</p>
<dl class="class">
<dt id="mxnet.gluon.rnn.BidirectionalCell">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">BidirectionalCell</code><span class="sig-paren">(</span><em>l_cell</em>, <em>r_cell</em>, <em>output_prefix='bi_'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#BidirectionalCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bidirectional RNN cell.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>l_cell</strong> (<a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell" title="mxnet.gluon.rnn.RecurrentCell"><em>RecurrentCell</em></a>) – Cell for forward unrolling</li>
<li><strong>r_cell</strong> (<a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell" title="mxnet.gluon.rnn.RecurrentCell"><em>RecurrentCell</em></a>) – Cell for backward unrolling</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.DropoutCell">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">DropoutCell</code><span class="sig-paren">(</span><em>rate</em>, <em>prefix=None</em>, <em>params=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#DropoutCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies dropout on input.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>rate</strong> (<em>float</em>) – Percentage of elements to drop out, which
is 1 - percentage to retain.</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs:</dt>
<dd><ul class="first last simple">
<li><strong>data</strong>: input tensor with shape <cite>(batch_size, size)</cite>.</li>
<li><strong>states</strong>: a list of recurrent state tensors.</li>
</ul>
</dd>
<dt>Outputs:</dt>
<dd><ul class="first last simple">
<li><strong>out</strong>: output tensor with shape <cite>(batch_size, size)</cite>.</li>
<li><strong>next_states</strong>: returns input <cite>states</cite> directly.</li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.GRU">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">GRU</code><span class="sig-paren">(</span><em>hidden_size</em>, <em>num_layers=1</em>, <em>layout='TNC'</em>, <em>dropout=0</em>, <em>bidirectional=False</em>, <em>input_size=0</em>, <em>i2h_weight_initializer=None</em>, <em>h2h_weight_initializer=None</em>, <em>i2h_bias_initializer='zeros'</em>, <em>h2h_bias_initializer='zeros'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_layer.html#GRU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.GRU" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.</p>
<p>For each element in the input sequence, each layer computes the following
function:</p>
<div class="math">
\[\begin{split}\begin{array}{ll}
r_t = sigmoid(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\
i_t = sigmoid(W_{ii} x_t + b_{ii} + W_hi h_{(t-1)} + b_{hi}) \\
n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\
h_t = (1 - i_t) * n_t + i_t * h_{(t-1)} \\
\end{array}\end{split}\]</div>
<p>where <span class="math">\(h_t\)</span> is the hidden state at time <cite>t</cite>, <span class="math">\(x_t\)</span> is the hidden
state of the previous layer at time <cite>t</cite> or <span class="math">\(input_t\)</span> for the first layer,
and <span class="math">\(r_t\)</span>, <span class="math">\(i_t\)</span>, <span class="math">\(n_t\)</span> are the reset, input, and new gates, respectively.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hidden_size</strong> (<em>int</em>) – The number of features in the hidden state h</li>
<li><strong>num_layers</strong> (<em>int</em><em>, </em><em>default 1</em>) – Number of recurrent layers.</li>
<li><strong>layout</strong> (<em>str</em><em>, </em><em>default 'TNC'</em>) – The format of input and output tensors. T, N and C stand for
sequence length, batch size, and feature dimensions respectively.</li>
<li><strong>dropout</strong> (<em>float</em><em>, </em><em>default 0</em>) – If non-zero, introduces a dropout layer on the outputs of each
RNN layer except the last layer</li>
<li><strong>bidirectional</strong> (<em>bool</em><em>, </em><em>default False</em>) – If True, becomes a bidirectional RNN.</li>
<li><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the input weights matrix, used for the linear
transformation of the inputs.</li>
<li><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</li>
<li><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the bias vector.</li>
<li><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the bias vector.</li>
<li><strong>input_size</strong> (<em>int</em><em>, </em><em>default 0</em>) – The number of expected features in the input x.
If not specified, it will be inferred from input.</li>
<li><strong>prefix</strong> (<em>str</em><em> or </em><em>None</em>) – Prefix of this <cite>Block</cite>.</li>
<li><strong>params</strong> (<a class="reference internal" href="gluon.html#mxnet.gluon.ParameterDict" title="mxnet.gluon.ParameterDict"><em>ParameterDict</em></a><em> or </em><em>None</em>) – Shared Parameters for this <cite>Block</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs:</dt>
<dd><ul class="first last simple">
<li><strong>data</strong>: input tensor with shape <cite>(sequence_length, batch_size, input_size)</cite>
when <cite>layout</cite> is “TNC”. For other layouts dimensions are permuted accordingly.</li>
<li><strong>states</strong>: initial recurrent state tensor with shape
<cite>(num_layers, batch_size, num_hidden)</cite>. If <cite>bidirectional</cite> is True,
shape will instead be <cite>(2*num_layers, batch_size, num_hidden)</cite>. If
<cite>states</cite> is None, zeros will be used as default begin states.</li>
</ul>
</dd>
<dt>Outputs:</dt>
<dd><ul class="first last simple">
<li><strong>out</strong>: output tensor with shape <cite>(sequence_length, batch_size, num_hidden)</cite>
when <cite>layout</cite> is “TNC”. If <cite>bidirectional</cite> is True, output shape will instead
be <cite>(sequence_length, batch_size, 2*num_hidden)</cite></li>
<li><strong>out_states</strong>: output recurrent state tensor with the same shape as <cite>states</cite>.
If <cite>states</cite> is None <cite>out_states</cite> will not be returned.</li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">>>> </span><span class="n">layer</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">>>> </span><span class="n">layer</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
<span class="gp">>>> </span><span class="nb">input</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">>>> </span><span class="c1"># by default zeros are used as begin state</span>
<span class="gp">>>> </span><span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">>>> </span><span class="c1"># manually specify begin state.</span>
<span class="gp">>>> </span><span class="n">h0</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">>>> </span><span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.GRUCell">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">GRUCell</code><span class="sig-paren">(</span><em>hidden_size</em>, <em>i2h_weight_initializer=None</em>, <em>h2h_weight_initializer=None</em>, <em>i2h_bias_initializer='zeros'</em>, <em>h2h_bias_initializer='zeros'</em>, <em>input_size=0</em>, <em>prefix=None</em>, <em>params=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#GRUCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Gated Rectified Unit (GRU) network cell.
Note: this is an implementation of the cuDNN version of GRUs
(slight modification compared to Cho et al. 2014).</p>
<p>Each call computes the following function:</p>
<div class="math">
\[\begin{split}\begin{array}{ll}
r_t = sigmoid(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\
i_t = sigmoid(W_{ii} x_t + b_{ii} + W_hi h_{(t-1)} + b_{hi}) \\
n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\
h_t = (1 - i_t) * n_t + i_t * h_{(t-1)} \\
\end{array}\end{split}\]</div>
<p>where <span class="math">\(h_t\)</span> is the hidden state at time <cite>t</cite>, <span class="math">\(x_t\)</span> is the hidden
state of the previous layer at time <cite>t</cite> or <span class="math">\(input_t\)</span> for the first layer,
and <span class="math">\(r_t\)</span>, <span class="math">\(i_t\)</span>, <span class="math">\(n_t\)</span> are the reset, input, and new gates, respectively.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hidden_size</strong> (<em>int</em>) – Number of units in output symbol.</li>
<li><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the input weights matrix, used for the linear
transformation of the inputs.</li>
<li><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</li>
<li><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the bias vector.</li>
<li><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the bias vector.</li>
<li><strong>prefix</strong> (str, default ‘<a href="#id1"><span class="problematic" id="id2">gru_</span></a>‘) – prefix for name of <cite>Block`s
(and name of weight if params is `None</cite>).</li>
<li><strong>params</strong> (<a class="reference internal" href="gluon.html#mxnet.gluon.Parameter" title="mxnet.gluon.Parameter"><em>Parameter</em></a><em> or </em><em>None</em>) – Container for weight sharing between cells.
Created if <cite>None</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs:</dt>
<dd><ul class="first last simple">
<li><strong>data</strong>: input tensor with shape <cite>(batch_size, input_size)</cite>.</li>
<li><strong>states</strong>: a list of one initial recurrent state tensor with shape
<cite>(batch_size, num_hidden)</cite>.</li>
</ul>
</dd>
<dt>Outputs:</dt>
<dd><ul class="first last simple">
<li><strong>out</strong>: output tensor with shape <cite>(batch_size, num_hidden)</cite>.</li>
<li><strong>next_states</strong>: a list of one output recurrent state tensor with the
same shape as <cite>states</cite>.</li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">HybridRecurrentCell</code><span class="sig-paren">(</span><em>prefix=None</em>, <em>params=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#HybridRecurrentCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell" title="Permalink to this definition">¶</a></dt>
<dd><p>HybridRecurrentCell supports hybridize.</p>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.LSTM">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">LSTM</code><span class="sig-paren">(</span><em>hidden_size</em>, <em>num_layers=1</em>, <em>layout='TNC'</em>, <em>dropout=0</em>, <em>bidirectional=False</em>, <em>input_size=0</em>, <em>i2h_weight_initializer=None</em>, <em>h2h_weight_initializer=None</em>, <em>i2h_bias_initializer='zeros'</em>, <em>h2h_bias_initializer='zeros'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_layer.html#LSTM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.LSTM" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.</p>
<p>For each element in the input sequence, each layer computes the following
function:</p>
<div class="math">
\[\begin{split}\begin{array}{ll}
i_t = sigmoid(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\
f_t = sigmoid(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\
g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hc} h_{(t-1)} + b_{hg}) \\
o_t = sigmoid(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\
c_t = f_t * c_{(t-1)} + i_t * g_t \\
h_t = o_t * \tanh(c_t)
\end{array}\end{split}\]</div>
<p>where <span class="math">\(h_t\)</span> is the hidden state at time <cite>t</cite>, <span class="math">\(c_t\)</span> is the
cell state at time <cite>t</cite>, <span class="math">\(x_t\)</span> is the hidden state of the previous
layer at time <cite>t</cite> or <span class="math">\(input_t\)</span> for the first layer, and <span class="math">\(i_t\)</span>,
<span class="math">\(f_t\)</span>, <span class="math">\(g_t\)</span>, <span class="math">\(o_t\)</span> are the input, forget, cell, and
out gates, respectively.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hidden_size</strong> (<em>int</em>) – The number of features in the hidden state h.</li>
<li><strong>num_layers</strong> (<em>int</em><em>, </em><em>default 1</em>) – Number of recurrent layers.</li>
<li><strong>layout</strong> (<em>str</em><em>, </em><em>default 'TNC'</em>) – The format of input and output tensors. T, N and C stand for
sequence length, batch size, and feature dimensions respectively.</li>
<li><strong>dropout</strong> (<em>float</em><em>, </em><em>default 0</em>) – If non-zero, introduces a dropout layer on the outputs of each
RNN layer except the last layer.</li>
<li><strong>bidirectional</strong> (<em>bool</em><em>, </em><em>default False</em>) – If <cite>True</cite>, becomes a bidirectional RNN.</li>
<li><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the input weights matrix, used for the linear
transformation of the inputs.</li>
<li><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</li>
<li><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default 'lstmbias'</em>) – Initializer for the bias vector. By default, bias for the forget
gate is initialized to 1 while all other biases are initialized
to zero.</li>
<li><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the bias vector.</li>
<li><strong>input_size</strong> (<em>int</em><em>, </em><em>default 0</em>) – The number of expected features in the input x.
If not specified, it will be inferred from input.</li>
<li><strong>prefix</strong> (<em>str</em><em> or </em><em>None</em>) – Prefix of this <cite>Block</cite>.</li>
<li><strong>params</strong> (<cite>ParameterDict</cite> or <cite>None</cite>) – Shared Parameters for this <cite>Block</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs:</dt>
<dd><ul class="first last simple">
<li><strong>data</strong>: input tensor with shape <cite>(sequence_length, batch_size, input_size)</cite>
when <cite>layout</cite> is “TNC”. For other layouts dimensions are permuted accordingly.</li>
<li><strong>states</strong>: a list of two initial recurrent state tensors. Each has shape
<cite>(num_layers, batch_size, num_hidden)</cite>. If <cite>bidirectional</cite> is True,
shape will instead be <cite>(2*num_layers, batch_size, num_hidden)</cite>. If
<cite>states</cite> is None, zeros will be used as default begin states.</li>
</ul>
</dd>
<dt>Outputs:</dt>
<dd><ul class="first last simple">
<li><strong>out</strong>: output tensor with shape <cite>(sequence_length, batch_size, num_hidden)</cite>
when <cite>layout</cite> is “TNC”. If <cite>bidirectional</cite> is True, output shape will instead
be <cite>(sequence_length, batch_size, 2*num_hidden)</cite></li>
<li><strong>out_states</strong>: a list of two output recurrent state tensors with the same
shape as in <cite>states</cite>. If <cite>states</cite> is None <cite>out_states</cite> will not be returned.</li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">>>> </span><span class="n">layer</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">>>> </span><span class="n">layer</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
<span class="gp">>>> </span><span class="nb">input</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">>>> </span><span class="c1"># by default zeros are used as begin state</span>
<span class="gp">>>> </span><span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">>>> </span><span class="c1"># manually specify begin state.</span>
<span class="gp">>>> </span><span class="n">h0</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">>>> </span><span class="n">c0</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">>>> </span><span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">[</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.LSTMCell">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">LSTMCell</code><span class="sig-paren">(</span><em>hidden_size</em>, <em>i2h_weight_initializer=None</em>, <em>h2h_weight_initializer=None</em>, <em>i2h_bias_initializer='zeros'</em>, <em>h2h_bias_initializer='zeros'</em>, <em>input_size=0</em>, <em>prefix=None</em>, <em>params=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#LSTMCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Long-Short Term Memory (LSTM) network cell.</p>
<p>Each call computes the following function:</p>
<div class="math">
\[\begin{split}\begin{array}{ll}
i_t = sigmoid(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\
f_t = sigmoid(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\
g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hc} h_{(t-1)} + b_{hg}) \\
o_t = sigmoid(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\
c_t = f_t * c_{(t-1)} + i_t * g_t \\
h_t = o_t * \tanh(c_t)
\end{array}\end{split}\]</div>
<p>where <span class="math">\(h_t\)</span> is the hidden state at time <cite>t</cite>, <span class="math">\(c_t\)</span> is the
cell state at time <cite>t</cite>, <span class="math">\(x_t\)</span> is the hidden state of the previous
layer at time <cite>t</cite> or <span class="math">\(input_t\)</span> for the first layer, and <span class="math">\(i_t\)</span>,
<span class="math">\(f_t\)</span>, <span class="math">\(g_t\)</span>, <span class="math">\(o_t\)</span> are the input, forget, cell, and
out gates, respectively.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hidden_size</strong> (<em>int</em>) – Number of units in output symbol.</li>
<li><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the input weights matrix, used for the linear
transformation of the inputs.</li>
<li><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</li>
<li><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default 'lstmbias'</em>) – Initializer for the bias vector. By default, bias for the forget
gate is initialized to 1 while all other biases are initialized
to zero.</li>
<li><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the bias vector.</li>
<li><strong>prefix</strong> (str, default ‘<a href="#id3"><span class="problematic" id="id4">lstm_</span></a>‘) – Prefix for name of <cite>Block`s
(and name of weight if params is `None</cite>).</li>
<li><strong>params</strong> (<a class="reference internal" href="gluon.html#mxnet.gluon.Parameter" title="mxnet.gluon.Parameter"><em>Parameter</em></a><em> or </em><em>None</em>) – Container for weight sharing between cells.
Created if <cite>None</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs:</dt>
<dd><ul class="first last simple">
<li><strong>data</strong>: input tensor with shape <cite>(batch_size, input_size)</cite>.</li>
<li><strong>states</strong>: a list of two initial recurrent state tensors. Each has shape
<cite>(batch_size, num_hidden)</cite>.</li>
</ul>
</dd>
<dt>Outputs:</dt>
<dd><ul class="first last simple">
<li><strong>out</strong>: output tensor with shape <cite>(batch_size, num_hidden)</cite>.</li>
<li><strong>next_states</strong>: a list of two output recurrent state tensors. Each has
the same shape as <cite>states</cite>.</li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.ModifierCell">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">ModifierCell</code><span class="sig-paren">(</span><em>base_cell</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ModifierCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for modifier cells. A modifier
cell takes a base cell, apply modifications
on it (e.g. Zoneout), and returns a new cell.</p>
<p>After applying modifiers the base cell should
no longer be called directly. The modifier cell
should be used instead.</p>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.RNN">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">RNN</code><span class="sig-paren">(</span><em>hidden_size</em>, <em>num_layers=1</em>, <em>activation='relu'</em>, <em>layout='TNC'</em>, <em>dropout=0</em>, <em>bidirectional=False</em>, <em>i2h_weight_initializer=None</em>, <em>h2h_weight_initializer=None</em>, <em>i2h_bias_initializer='zeros'</em>, <em>h2h_bias_initializer='zeros'</em>, <em>input_size=0</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_layer.html#RNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a multi-layer Elman RNN with <cite>tanh</cite> or <cite>ReLU</cite> non-linearity to an input sequence.</p>
<p>For each element in the input sequence, each layer computes the following
function:</p>
<div class="math">
\[h_t = \tanh(w_{ih} * x_t + b_{ih}  +  w_{hh} * h_{(t-1)} + b_{hh})\]</div>
<p>where <span class="math">\(h_t\)</span> is the hidden state at time <cite>t</cite>, and <span class="math">\(x_t\)</span> is the hidden
state of the previous layer at time <cite>t</cite> or <span class="math">\(input_t\)</span> for the first layer.
If nonlinearity=’relu’, then <cite>ReLU</cite> is used instead of <cite>tanh</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hidden_size</strong> (<em>int</em>) – The number of features in the hidden state h.</li>
<li><strong>num_layers</strong> (<em>int</em><em>, </em><em>default 1</em>) – Number of recurrent layers.</li>
<li><strong>activation</strong> (<em>{'relu'</em><em> or </em><em>'tanh'}</em><em>, </em><em>default 'tanh'</em>) – The activation function to use.</li>
<li><strong>layout</strong> (<em>str</em><em>, </em><em>default 'TNC'</em>) – The format of input and output tensors. T, N and C stand for
sequence length, batch size, and feature dimensions respectively.</li>
<li><strong>dropout</strong> (<em>float</em><em>, </em><em>default 0</em>) – If non-zero, introduces a dropout layer on the outputs of each
RNN layer except the last layer.</li>
<li><strong>bidirectional</strong> (<em>bool</em><em>, </em><em>default False</em>) – If <cite>True</cite>, becomes a bidirectional RNN.</li>
<li><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the input weights matrix, used for the linear
transformation of the inputs.</li>
<li><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</li>
<li><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the bias vector.</li>
<li><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the bias vector.</li>
<li><strong>input_size</strong> (<em>int</em><em>, </em><em>default 0</em>) – The number of expected features in the input x.
If not specified, it will be inferred from input.</li>
<li><strong>prefix</strong> (<em>str</em><em> or </em><em>None</em>) – Prefix of this <cite>Block</cite>.</li>
<li><strong>params</strong> (<a class="reference internal" href="gluon.html#mxnet.gluon.ParameterDict" title="mxnet.gluon.ParameterDict"><em>ParameterDict</em></a><em> or </em><em>None</em>) – Shared Parameters for this <cite>Block</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs:</dt>
<dd><ul class="first last simple">
<li><strong>data</strong>: input tensor with shape <cite>(sequence_length, batch_size, input_size)</cite>
when <cite>layout</cite> is “TNC”. For other layouts dimensions are permuted accordingly.</li>
<li><strong>states</strong>: initial recurrent state tensor with shape
<cite>(num_layers, batch_size, num_hidden)</cite>. If <cite>bidirectional</cite> is True,
shape will instead be <cite>(2*num_layers, batch_size, num_hidden)</cite>. If
<cite>states</cite> is None, zeros will be used as default begin states.</li>
</ul>
</dd>
<dt>Outputs:</dt>
<dd><ul class="first last simple">
<li><strong>out</strong>: output tensor with shape <cite>(sequence_length, batch_size, num_hidden)</cite>
when <cite>layout</cite> is “TNC”. If <cite>bidirectional</cite> is True, output shape will instead
be <cite>(sequence_length, batch_size, 2*num_hidden)</cite></li>
<li><strong>out_states</strong>: output recurrent state tensor with the same shape as <cite>states</cite>.
If <cite>states</cite> is None <cite>out_states</cite> will not be returned.</li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">>>> </span><span class="n">layer</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">>>> </span><span class="n">layer</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
<span class="gp">>>> </span><span class="nb">input</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">>>> </span><span class="c1"># by default zeros are used as begin state</span>
<span class="gp">>>> </span><span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">>>> </span><span class="c1"># manually specify begin state.</span>
<span class="gp">>>> </span><span class="n">h0</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">>>> </span><span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.RNNCell">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">RNNCell</code><span class="sig-paren">(</span><em>hidden_size</em>, <em>activation='tanh'</em>, <em>i2h_weight_initializer=None</em>, <em>h2h_weight_initializer=None</em>, <em>i2h_bias_initializer='zeros'</em>, <em>h2h_bias_initializer='zeros'</em>, <em>input_size=0</em>, <em>prefix=None</em>, <em>params=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RNNCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Elman RNN recurrent neural network cell.</p>
<p>Each call computes the following function:</p>
<div class="math">
\[h_t = \tanh(w_{ih} * x_t + b_{ih}  +  w_{hh} * h_{(t-1)} + b_{hh})\]</div>
<p>where <span class="math">\(h_t\)</span> is the hidden state at time <cite>t</cite>, and <span class="math">\(x_t\)</span> is the hidden
state of the previous layer at time <cite>t</cite> or <span class="math">\(input_t\)</span> for the first layer.
If nonlinearity=’relu’, then <cite>ReLU</cite> is used instead of <cite>tanh</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hidden_size</strong> (<em>int</em>) – Number of units in output symbol</li>
<li><strong>activation</strong> (<em>str</em><em> or </em><a class="reference internal" href="../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>default 'tanh'</em>) – Type of activation function.</li>
<li><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the input weights matrix, used for the linear
transformation of the inputs.</li>
<li><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</li>
<li><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the bias vector.</li>
<li><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../optimization/optimization.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) – Initializer for the bias vector.</li>
<li><strong>prefix</strong> (str, default ‘<a href="#id5"><span class="problematic" id="id6">rnn_</span></a>‘) – Prefix for name of <cite>Block`s
(and name of weight if params is `None</cite>).</li>
<li><strong>params</strong> (<a class="reference internal" href="gluon.html#mxnet.gluon.Parameter" title="mxnet.gluon.Parameter"><em>Parameter</em></a><em> or </em><em>None</em>) – Container for weight sharing between cells.
Created if <cite>None</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Inputs:</dt>
<dd><ul class="first last simple">
<li><strong>data</strong>: input tensor with shape <cite>(batch_size, input_size)</cite>.</li>
<li><strong>states</strong>: a list of one initial recurrent state tensor with shape
<cite>(batch_size, num_hidden)</cite>.</li>
</ul>
</dd>
<dt>Outputs:</dt>
<dd><ul class="first last simple">
<li><strong>out</strong>: output tensor with shape <cite>(batch_size, num_hidden)</cite>.</li>
<li><strong>next_states</strong>: a list of one output recurrent state tensor with the
same shape as <cite>states</cite>.</li>
</ul>
</dd>
</dl>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.RecurrentCell">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">RecurrentCell</code><span class="sig-paren">(</span><em>prefix=None</em>, <em>params=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract base class for RNN cells</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>prefix</strong> (<em>str</em><em>, </em><em>optional</em>) – Prefix for names of <cite>Block`s
(this prefix is also used for names of weights if `params</cite> is <cite>None</cite>
i.e. if <cite>params</cite> are being created and not reused)</li>
<li><strong>params</strong> (<a class="reference internal" href="gluon.html#mxnet.gluon.Parameter" title="mxnet.gluon.Parameter"><em>Parameter</em></a><em> or </em><em>None</em><em>, </em><em>optional</em>) – Container for weight sharing between cells.
A new Parameter container is created if <cite>params</cite> is <cite>None</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.begin_state">
<code class="descname">begin_state</code><span class="sig-paren">(</span><em>batch_size=0</em>, <em>func=<function zeros></em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell.begin_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.begin_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initial state for this cell.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) – <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</li>
<li><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) – Only required for NDArray API. Size of the batch (‘N’ in layout)
dimension of input.</li>
<li><strong>**kwargs</strong> – Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>states</strong> – Starting states for the first RNN step.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">nested list of Symbol</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>
<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>inputs</em>, <em>states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>inputs</strong> (<em>sym.Variable</em>) – Input symbol, 2D, of shape (batch_size * num_units).</li>
<li><strong>states</strong> (<em>list of sym.Variable</em>) – RNN state from previous step or the output of begin_state().</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>output</strong> (<em>Symbol</em>) – Symbol corresponding to the output from the RNN when unrolling
for a single time step.</li>
<li><strong>states</strong> (<em>list of Symbol</em>) – The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.begin_state" title="mxnet.gluon.rnn.RecurrentCell.begin_state"><code class="xref py py-meth docutils literal"><span class="pre">begin_state()</span></code></a></dt>
<dd>This function can provide the states for the first time step.</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.unroll" title="mxnet.gluon.rnn.RecurrentCell.unroll"><code class="xref py py-meth docutils literal"><span class="pre">unroll()</span></code></a></dt>
<dd>This function unrolls an RNN for a given number of (>=1) time steps.</dd>
</dl>
</div>
</dd></dl>
<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>
<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.state_info">
<code class="descname">state_info</code><span class="sig-paren">(</span><em>batch_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell.state_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.state_info" title="Permalink to this definition">¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>
<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.unroll">
<code class="descname">unroll</code><span class="sig-paren">(</span><em>length</em>, <em>inputs</em>, <em>begin_state=None</em>, <em>layout='NTC'</em>, <em>merge_outputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell.unroll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.unroll" title="Permalink to this definition">¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>length</strong> (<em>int</em>) – Number of steps to unroll.</li>
<li><strong>inputs</strong> (<a class="reference internal" href="../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) – <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, ...) if <cite>layout</cite> is ‘NTC’,
or (length, batch_size, ...) if <cite>layout</cite> is ‘TNC’.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, ...).</p>
</li>
<li><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) – Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</li>
<li><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) – <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</li>
<li><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) – If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, ...) if layout is ‘NTC’,
or (length, batch_size, ...) if layout is ‘TNC’.
If <cite>None</cite>, output whatever is faster.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><ul class="simple">
<li><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) – Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</li>
<li><strong>states</strong> (<em>list of Symbol</em>) – The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</li>
</ul>
</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.ResidualCell">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">ResidualCell</code><span class="sig-paren">(</span><em>base_cell</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ResidualCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds residual connection as described in Wu et al, 2016
(<a class="reference external" href="https://arxiv.org/abs/1609.08144">https://arxiv.org/abs/1609.08144</a>).
Output of the cell is output of the base cell plus input.</p>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.SequentialRNNCell">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">SequentialRNNCell</code><span class="sig-paren">(</span><em>prefix=None</em>, <em>params=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#SequentialRNNCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Sequentially stacking multiple RNN cells.</p>
<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.add">
<code class="descname">add</code><span class="sig-paren">(</span><em>cell</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#SequentialRNNCell.add"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.add" title="Permalink to this definition">¶</a></dt>
<dd><p>Appends a cell into the stack.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"/>
<col class="field-body"/>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>cell</strong> (<a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell" title="mxnet.gluon.rnn.RecurrentCell"><em>RecurrentCell</em></a>) – The cell to add.</td>
</tr>
</tbody>
</table>
</dd></dl>
</dd></dl>
<dl class="class">
<dt id="mxnet.gluon.rnn.ZoneoutCell">
<em class="property">class </em><code class="descclassname">mxnet.gluon.rnn.</code><code class="descname">ZoneoutCell</code><span class="sig-paren">(</span><em>base_cell</em>, <em>zoneout_outputs=0.0</em>, <em>zoneout_states=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ZoneoutCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Zoneout on base cell.</p>
</dd></dl>
<script>auto_index("api-reference");</script></div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar rightsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h3><a href="../../../index.html">Table Of Contents</a></h3>
<ul>
<li><a class="reference internal" href="#">Gluon Recurrent Neural Network API</a><ul>
<li><a class="reference internal" href="#overview">Overview</a><ul>
<li><a class="reference internal" href="#recurrent-layers">Recurrent Layers</a></li>
<li><a class="reference internal" href="#recurrent-cells">Recurrent Cells</a></li>
</ul>
</li>
<li><a class="reference internal" href="#api-reference">API Reference</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div><div class="footer">
<div class="section-disclaimer">
<div class="container">
<div>
<img height="60" src="https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/image/apache_incubator_logo.png"/>
<p>
            Apache MXNet is an effort undergoing incubation at The Apache Software Foundation (ASF), <strong>sponsored by the <i>Apache Incubator</i></strong>. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
        </p>
<p>
            "Copyright © 2017-2018, The Apache Software Foundation
            Apache MXNet, MXNet, Apache, the Apache feather, and the Apache MXNet project logo are either registered trademarks or trademarks of the Apache Software Foundation."
        </p>
</div>
</div>
</div>
</div> <!-- pagename != index -->
</div>
<script crossorigin="anonymous" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
<script src="../../../_static/js/sidebar.js" type="text/javascript"></script>
<script src="../../../_static/js/search.js" type="text/javascript"></script>
<script src="../../../_static/js/navbar.js" type="text/javascript"></script>
<script src="../../../_static/js/clipboard.min.js" type="text/javascript"></script>
<script src="../../../_static/js/copycode.js" type="text/javascript"></script>
<script src="../../../_static/js/page.js" type="text/javascript"></script>
<script src="../../../_static/js/docversion.js" type="text/javascript"></script>
<script type="text/javascript">
        $('body').ready(function () {
            $('body').css('visibility', 'visible');
        });
    </script>
</body>
</html>