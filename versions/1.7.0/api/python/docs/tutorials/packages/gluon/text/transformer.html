<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <style>
    .dropdown {
        position: relative;
        display: inline-block;
    }

    .dropdown-content {
        display: none;
        position: absolute;
        background-color: #f9f9f9;
        min-width: 160px;
        box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
        padding: 12px 16px;
        z-index: 1;
        text-align: left;
    }

    .dropdown:hover .dropdown-content {
        display: block;
    }

    .dropdown-option:hover {
        color: #FF4500;
    }

    .dropdown-option-active {
        color: #FF4500;
        font-weight: lighter;
    }

    .dropdown-option {
        color: #000000;
        font-weight: lighter;
    }

    .dropdown-header {
        color: #FFFFFF;
        display: inline-flex;
    }

    .dropdown-caret {
        width: 18px;
    }

    .dropdown-caret-path {
        fill: #FFFFFF;
    }
    </style>
    
    <title>Machine Translation with Transformer &#8212; Apache MXNet  documentation</title>

    <link rel="stylesheet" href="../../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mxnet.css" />
    <link rel="stylesheet" href="../../../../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/feedback.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/language_data.js"></script>
    <script src="../../../../_static/google_analytics.js"></script>
    <script src="../../../../_static/autodoc.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../../../_static/mxnet-icon.png"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Training" href="../training/index.html" />
    <link rel="prev" title="Google Neural Machine Translation" href="gnmt.html" /> 
  </head>
<body><header class="site-header" role="banner">
  <div class="wrapper">
      <a class="site-title" rel="author" href="/versions/1.7.0/"><img
            src="../../../../_static/mxnet_logo.png" class="site-header-logo"></a>
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger"/>
      <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
      </label>

      <div class="trigger">
        <a class="page-link" href="/versions/1.7.0/get_started">Get Started</a>
        <a class="page-link" href="/versions/1.7.0/blog">Blog</a>
        <a class="page-link" href="/versions/1.7.0/features">Features</a>
        <a class="page-link" href="/versions/1.7.0/ecosystem">Ecosystem</a>
        <a class="page-link page-current" href="/versions/1.7.0/api">Docs & Tutorials</a>
        <a class="page-link" href="https://github.com/apache/incubator-mxnet">GitHub</a>
        <div class="dropdown">
          <span class="dropdown-header">1.7.0
            <svg class="dropdown-caret" viewBox="0 0 32 32" class="icon icon-caret-bottom" aria-hidden="true"><path class="dropdown-caret-path" d="M24 11.305l-7.997 11.39L8 11.305z"></path></svg>
          </span>
          <div class="dropdown-content">
            <a class="dropdown-option" href="/">master</a><br>
            <a class="dropdown-option-active" href="/versions/1.7.0/">1.7.0</a><br>
            <a class="dropdown-option" href="/versions/1.6.0/">1.6.0</a><br>
            <a class="dropdown-option" href="/versions/1.5.0/">1.5.0</a><br>
            <a class="dropdown-option" href="/versions/1.4.1/">1.4.1</a><br>
            <a class="dropdown-option" href="/versions/1.3.1/">1.3.1</a><br>
            <a class="dropdown-option" href="/versions/1.2.1/">1.2.1</a><br>
            <a class="dropdown-option" href="/versions/1.1.0/">1.1.0</a><br>
            <a class="dropdown-option" href="/versions/1.0.0/">1.0.0</a><br>
            <a class="dropdown-option" href="/versions/0.12.1/">0.12.1</a><br>
            <a class="dropdown-option" href="/versions/0.11.0/">0.11.0</a>
          </div>
        </div>
      </div>
    </nav>
  </div>
</header>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="../../../index.html">Python Tutorials</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link" href="../../index.html">Packages</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link" href="../index.html">Gluon</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link" href="index.html">Text Tutorials</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active">Machine Translation with Transformer</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../../../../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../../../../_sources/tutorials/packages/gluon/text/transformer.rst" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
      </nav>
    </div>
</header><header class="mdl-layout__drawer">      
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../index.html">Python Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../getting-started/index.html">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/crash-course/index.html">Crash Course</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/1-ndarray.html">Manipulate data with <code class="docutils literal notranslate"><span class="pre">ndarray</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/2-nn.html">Create a neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/3-autograd.html">Automatic differentiation with <code class="docutils literal notranslate"><span class="pre">autograd</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/4-train.html">Train the neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/5-predict.html">Predict with a pre-trained model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/6-use_gpus.html">Use GPUs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/to-mxnet/index.html">Moving to MXNet from Other Frameworks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/to-mxnet/pytorch.html">PyTorch vs Apache MXNet</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/gluon_from_experiment_to_deployment.html">Gluon: from experiment to deployment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/logistic_regression_explained.html">Logistic regression explained</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html">MNIST</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html">Packages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../../autograd/index.html">Automatic Differentiation</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">Gluon</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../blocks/index.html">Blocks</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../blocks/custom-layer.html">Custom Layers</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/custom_layer_beginners.html">Customer Layers (Beginners)</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/hybridize.html">Hybridize</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/init.html">Initialization</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/naming.html">Parameter and Block Naming</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/nn.html">Layers and Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/parameters.html">Parameter Management</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/save_load_params.html">Saving and Loading Gluon Models</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/activations/activations.html">Activation Blocks</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../data/index.html">Data Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../data/data_augmentation.html">Image Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/data_augmentation.html#Spatial-Augmentation">Spatial Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/data_augmentation.html#Color-Augmentation">Color Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/data_augmentation.html#Composed-Augmentations">Composed Augmentations</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/datasets.html">Gluon <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/datasets.html#Using-own-data-with-included-Datasets">Using own data with included <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/datasets.html#Using-own-data-with-custom-Datasets">Using own data with custom <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/datasets.html#Appendix:-Upgrading-from-Module-DataIter-to-Gluon-DataLoader">Appendix: Upgrading from Module <code class="docutils literal notranslate"><span class="pre">DataIter</span></code> to Gluon <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../image/index.html">Image Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../image/image-augmentation.html">Image Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../image/info_gan.html">Image similarity search with InfoGAN</a></li>
<li class="toctree-l5"><a class="reference internal" href="../image/mnist.html">Handwritten Digit Recognition</a></li>
<li class="toctree-l5"><a class="reference internal" href="../image/pretrained_models.html">Using pre-trained models in MXNet</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../loss/index.html">Losses</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../loss/custom-loss.html">Custom Loss Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../loss/kl_divergence.html">Kullback-Leibler (KL) Divergence</a></li>
<li class="toctree-l5"><a class="reference internal" href="../loss/loss.html">Loss functions</a></li>
</ul>
</li>
<li class="toctree-l4 current"><a class="reference internal" href="index.html">Text Tutorials</a><ul class="current">
<li class="toctree-l5"><a class="reference internal" href="gnmt.html">Google Neural Machine Translation</a></li>
<li class="toctree-l5 current"><a class="current reference internal" href="#">Machine Translation with Transformer</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../training/index.html">Training</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../training/fit_api_tutorial.html">MXNet Gluon Fit API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../training/trainer.html">Trainer</a></li>
<li class="toctree-l5"><a class="reference internal" href="../training/learning_rates/index.html">Learning Rates</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../training/learning_rates/learning_rate_finder.html">Learning Rate Finder</a></li>
<li class="toctree-l6"><a class="reference internal" href="../training/learning_rates/learning_rate_schedules.html">Learning Rate Schedules</a></li>
<li class="toctree-l6"><a class="reference internal" href="../training/learning_rates/learning_rate_schedules_advanced.html">Advanced Learning Rate Schedules</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../training/normalization/index.html">Normalization Blocks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/index.html">KVStore</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../kvstore/kvstore.html">Distributed Key-Value Store</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/index.html">NDArray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../ndarray/01-ndarray-intro.html">An Intro: Manipulate Data the MXNet Way with NDArray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../ndarray/02-ndarray-operations.html">NDArray Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../ndarray/03-ndarray-contexts.html">NDArray Contexts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../ndarray/gotchas_numpy_in_mxnet.html">Gotchas using NumPy in Apache MXNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../ndarray/sparse/index.html">Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../ndarray/sparse/csr.html">CSRNDArray - NDArray in Compressed Sparse Row Storage Format</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../ndarray/sparse/row_sparse.html">RowSparseNDArray - NDArray for Sparse Gradient Updates</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../ndarray/sparse/train.html">Train a Linear Regression Model with Sparse Symbols</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../ndarray/sparse/train_gluon.html">Sparse NDArrays with Gluon</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../onnx/index.html">ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../onnx/fine_tuning_gluon.html">Fine-tuning an ONNX model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../onnx/inference_on_onnx_model.html">Running inference on MXNet/Gluon from an ONNX model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../onnx/super_resolution.html">Importing an ONNX model into MXNet</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/deploy/export/onnx.html">Export ONNX Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../optimizer/index.html">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../viz/index.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/visualize_graph">Visualize networks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../performance/index.html">Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../performance/compression/index.html">Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/compression/int8.html">Deploy with int-8</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/float16">Float16</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/gradient_compression">Gradient Compression</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/int8_inference.html">GluonCV with Quantized Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../performance/backend/index.html">Accelerated Backend Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/backend/mkldnn/index.html">Intel MKL-DNN</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../performance/backend/mkldnn/mkldnn_quantization.html">Quantize with MKL-DNN backend</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../performance/backend/mkldnn/mkldnn_readme.html">Install MXNet with MKL-DNN</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/backend/tensorrt/index.html">TensorRT</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../performance/backend/tensorrt/tensorrt.html">Optimizing Deep Learning Computation Graphs with TensorRT</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/backend/tvm.html">Use TVM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/backend/profiler.html">Profiling MXNet Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/backend/amp.html">Using AMP: Automatic Mixed Precision</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../deploy/index.html">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/export/index.html">Export</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/export/onnx.html">Exporting to ONNX format</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/export_network.html">Export Gluon CV Models</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Save / Load Parameters</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/inference/index.html">Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/inference/cpp.html">Deploy into C++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/inference/image_classification_jetson.html">Image Classication using pretrained ResNet-50 model on Jetson module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/inference/scala.html">Deploy into a Java or Scala Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/inference/wine_detector.html">Real-time Object Detection with MXNet On The Raspberry Pi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/run-on-aws/index.html">Run on AWS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/run-on-aws/use_ec2.html">Run on an EC2 Instance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/run-on-aws/use_sagemaker.html">Run on Amazon SageMaker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/run-on-aws/cloud.html">MXNet on the Cloud</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../extend/index.html">Extend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../extend/custom_layer.html">Custom Layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../extend/customop.html">Custom Numpy Operators</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/new_op">New Operator Creation</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/add_op_in_backend">New Operator in MXNet Backend</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/index.html">Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/ndarray/index.html">mxnet.ndarray</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/ndarray.html">ndarray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/contrib/index.html">ndarray.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/image/index.html">ndarray.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/linalg/index.html">ndarray.linalg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/op/index.html">ndarray.op</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/random/index.html">ndarray.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/register/index.html">ndarray.register</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/sparse/index.html">ndarray.sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/utils/index.html">ndarray.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/gluon/index.html">mxnet.gluon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/block.html">gluon.Block</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/hybrid_block.html">gluon.HybridBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/symbol_block.html">gluon.SymbolBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/constant.html">gluon.Constant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/parameter.html">gluon.Parameter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/parameter_dict.html">gluon.ParameterDict</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/trainer.html">gluon.Trainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/contrib/index.html">gluon.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/data/index.html">gluon.data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../api/gluon/data/vision/index.html">data.vision</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../../api/gluon/data/vision/datasets/index.html">vision.datasets</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../../api/gluon/data/vision/transforms/index.html">vision.transforms</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/loss/index.html">gluon.loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/model_zoo/index.html">gluon.model_zoo.vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/nn/index.html">gluon.nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/rnn/index.html">gluon.rnn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/utils/index.html">gluon.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/autograd/index.html">mxnet.autograd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/initializer/index.html">mxnet.initializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/optimizer/index.html">mxnet.optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/lr_scheduler/index.html">mxnet.lr_scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/metric/index.html">mxnet.metric</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/kvstore/index.html">mxnet.kvstore</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/symbol/index.html">mxnet.symbol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/symbol.html">symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/contrib/index.html">symbol.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/image/index.html">symbol.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/linalg/index.html">symbol.linalg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/op/index.html">symbol.op</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/random/index.html">symbol.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/register/index.html">symbol.register</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/sparse/index.html">symbol.sparse</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/module/index.html">mxnet.module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/contrib/index.html">mxnet.contrib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/autograd/index.html">contrib.autograd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/io/index.html">contrib.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/ndarray/index.html">contrib.ndarray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/onnx/index.html">contrib.onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/quantization/index.html">contrib.quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/symbol/index.html">contrib.symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/tensorboard/index.html">contrib.tensorboard</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/tensorrt/index.html">contrib.tensorrt</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/text/index.html">contrib.text</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/mxnet/index.html">mxnet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/attribute/index.html">mxnet.attribute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/base/index.html">mxnet.base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/callback/index.html">mxnet.callback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/context/index.html">mxnet.context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/engine/index.html">mxnet.engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/executor/index.html">mxnet.executor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/executor_manager/index.html">mxnet.executor_manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/image/index.html">mxnet.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/io/index.html">mxnet.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/kvstore_server/index.html">mxnet.kvstore_server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/libinfo/index.html">mxnet.libinfo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/log/index.html">mxnet.log</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/model/index.html">mxnet.model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/monitor/index.html">mxnet.monitor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/name/index.html">mxnet.name</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/notebook/index.html">mxnet.notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/operator/index.html">mxnet.operator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/profiler/index.html">mxnet.profiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/random/index.html">mxnet.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/recordio/index.html">mxnet.recordio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/registry/index.html">mxnet.registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/rtc/index.html">mxnet.rtc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/runtime/index.html">mxnet.runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/test_utils/index.html">mxnet.test_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/torch/index.html">mxnet.torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/util/index.html">mxnet.util</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/visualization/index.html">mxnet.visualization</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

        <script type="text/javascript" src="../../../../_static/sphinx_materialdesign_theme.js "></script>
        <script type="text/javascript" src="../../../../_static/feedback.js"></script>
    <header class="mdl-layout__drawer">      
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../index.html">Python Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../getting-started/index.html">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/crash-course/index.html">Crash Course</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/1-ndarray.html">Manipulate data with <code class="docutils literal notranslate"><span class="pre">ndarray</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/2-nn.html">Create a neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/3-autograd.html">Automatic differentiation with <code class="docutils literal notranslate"><span class="pre">autograd</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/4-train.html">Train the neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/5-predict.html">Predict with a pre-trained model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/crash-course/6-use_gpus.html">Use GPUs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/to-mxnet/index.html">Moving to MXNet from Other Frameworks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../getting-started/to-mxnet/pytorch.html">PyTorch vs Apache MXNet</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/gluon_from_experiment_to_deployment.html">Gluon: from experiment to deployment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../getting-started/logistic_regression_explained.html">Logistic regression explained</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html">MNIST</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html">Packages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../../autograd/index.html">Automatic Differentiation</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">Gluon</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../blocks/index.html">Blocks</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../blocks/custom-layer.html">Custom Layers</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/custom_layer_beginners.html">Customer Layers (Beginners)</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/hybridize.html">Hybridize</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/init.html">Initialization</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/naming.html">Parameter and Block Naming</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/nn.html">Layers and Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/parameters.html">Parameter Management</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/save_load_params.html">Saving and Loading Gluon Models</a></li>
<li class="toctree-l5"><a class="reference internal" href="../blocks/activations/activations.html">Activation Blocks</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../data/index.html">Data Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../data/data_augmentation.html">Image Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/data_augmentation.html#Spatial-Augmentation">Spatial Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/data_augmentation.html#Color-Augmentation">Color Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/data_augmentation.html#Composed-Augmentations">Composed Augmentations</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/datasets.html">Gluon <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/datasets.html#Using-own-data-with-included-Datasets">Using own data with included <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/datasets.html#Using-own-data-with-custom-Datasets">Using own data with custom <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/datasets.html#Appendix:-Upgrading-from-Module-DataIter-to-Gluon-DataLoader">Appendix: Upgrading from Module <code class="docutils literal notranslate"><span class="pre">DataIter</span></code> to Gluon <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../image/index.html">Image Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../image/image-augmentation.html">Image Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../image/info_gan.html">Image similarity search with InfoGAN</a></li>
<li class="toctree-l5"><a class="reference internal" href="../image/mnist.html">Handwritten Digit Recognition</a></li>
<li class="toctree-l5"><a class="reference internal" href="../image/pretrained_models.html">Using pre-trained models in MXNet</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../loss/index.html">Losses</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../loss/custom-loss.html">Custom Loss Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../loss/kl_divergence.html">Kullback-Leibler (KL) Divergence</a></li>
<li class="toctree-l5"><a class="reference internal" href="../loss/loss.html">Loss functions</a></li>
</ul>
</li>
<li class="toctree-l4 current"><a class="reference internal" href="index.html">Text Tutorials</a><ul class="current">
<li class="toctree-l5"><a class="reference internal" href="gnmt.html">Google Neural Machine Translation</a></li>
<li class="toctree-l5 current"><a class="current reference internal" href="#">Machine Translation with Transformer</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../training/index.html">Training</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../training/fit_api_tutorial.html">MXNet Gluon Fit API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../training/trainer.html">Trainer</a></li>
<li class="toctree-l5"><a class="reference internal" href="../training/learning_rates/index.html">Learning Rates</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../training/learning_rates/learning_rate_finder.html">Learning Rate Finder</a></li>
<li class="toctree-l6"><a class="reference internal" href="../training/learning_rates/learning_rate_schedules.html">Learning Rate Schedules</a></li>
<li class="toctree-l6"><a class="reference internal" href="../training/learning_rates/learning_rate_schedules_advanced.html">Advanced Learning Rate Schedules</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../training/normalization/index.html">Normalization Blocks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/index.html">KVStore</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../kvstore/kvstore.html">Distributed Key-Value Store</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/index.html">NDArray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../ndarray/01-ndarray-intro.html">An Intro: Manipulate Data the MXNet Way with NDArray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../ndarray/02-ndarray-operations.html">NDArray Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../ndarray/03-ndarray-contexts.html">NDArray Contexts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../ndarray/gotchas_numpy_in_mxnet.html">Gotchas using NumPy in Apache MXNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../ndarray/sparse/index.html">Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../ndarray/sparse/csr.html">CSRNDArray - NDArray in Compressed Sparse Row Storage Format</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../ndarray/sparse/row_sparse.html">RowSparseNDArray - NDArray for Sparse Gradient Updates</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../ndarray/sparse/train.html">Train a Linear Regression Model with Sparse Symbols</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../ndarray/sparse/train_gluon.html">Sparse NDArrays with Gluon</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../onnx/index.html">ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../onnx/fine_tuning_gluon.html">Fine-tuning an ONNX model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../onnx/inference_on_onnx_model.html">Running inference on MXNet/Gluon from an ONNX model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../onnx/super_resolution.html">Importing an ONNX model into MXNet</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/deploy/export/onnx.html">Export ONNX Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../optimizer/index.html">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../viz/index.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/visualize_graph">Visualize networks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../performance/index.html">Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../performance/compression/index.html">Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/compression/int8.html">Deploy with int-8</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/float16">Float16</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/gradient_compression">Gradient Compression</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/int8_inference.html">GluonCV with Quantized Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../performance/backend/index.html">Accelerated Backend Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/backend/mkldnn/index.html">Intel MKL-DNN</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../performance/backend/mkldnn/mkldnn_quantization.html">Quantize with MKL-DNN backend</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../performance/backend/mkldnn/mkldnn_readme.html">Install MXNet with MKL-DNN</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/backend/tensorrt/index.html">TensorRT</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../performance/backend/tensorrt/tensorrt.html">Optimizing Deep Learning Computation Graphs with TensorRT</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/backend/tvm.html">Use TVM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/backend/profiler.html">Profiling MXNet Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../performance/backend/amp.html">Using AMP: Automatic Mixed Precision</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../deploy/index.html">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/export/index.html">Export</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/export/onnx.html">Exporting to ONNX format</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/export_network.html">Export Gluon CV Models</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Save / Load Parameters</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/inference/index.html">Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/inference/cpp.html">Deploy into C++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/inference/image_classification_jetson.html">Image Classication using pretrained ResNet-50 model on Jetson module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/inference/scala.html">Deploy into a Java or Scala Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/inference/wine_detector.html">Real-time Object Detection with MXNet On The Raspberry Pi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../deploy/run-on-aws/index.html">Run on AWS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/run-on-aws/use_ec2.html">Run on an EC2 Instance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/run-on-aws/use_sagemaker.html">Run on Amazon SageMaker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../deploy/run-on-aws/cloud.html">MXNet on the Cloud</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../extend/index.html">Extend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../extend/custom_layer.html">Custom Layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../extend/customop.html">Custom Numpy Operators</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/new_op">New Operator Creation</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/add_op_in_backend">New Operator in MXNet Backend</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/index.html">Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/ndarray/index.html">mxnet.ndarray</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/ndarray.html">ndarray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/contrib/index.html">ndarray.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/image/index.html">ndarray.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/linalg/index.html">ndarray.linalg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/op/index.html">ndarray.op</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/random/index.html">ndarray.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/register/index.html">ndarray.register</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/sparse/index.html">ndarray.sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/ndarray/utils/index.html">ndarray.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/gluon/index.html">mxnet.gluon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/block.html">gluon.Block</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/hybrid_block.html">gluon.HybridBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/symbol_block.html">gluon.SymbolBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/constant.html">gluon.Constant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/parameter.html">gluon.Parameter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/parameter_dict.html">gluon.ParameterDict</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/trainer.html">gluon.Trainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/contrib/index.html">gluon.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/data/index.html">gluon.data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../api/gluon/data/vision/index.html">data.vision</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../../api/gluon/data/vision/datasets/index.html">vision.datasets</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../../api/gluon/data/vision/transforms/index.html">vision.transforms</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/loss/index.html">gluon.loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/model_zoo/index.html">gluon.model_zoo.vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/nn/index.html">gluon.nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/rnn/index.html">gluon.rnn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/gluon/utils/index.html">gluon.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/autograd/index.html">mxnet.autograd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/initializer/index.html">mxnet.initializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/optimizer/index.html">mxnet.optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/lr_scheduler/index.html">mxnet.lr_scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/metric/index.html">mxnet.metric</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/kvstore/index.html">mxnet.kvstore</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/symbol/index.html">mxnet.symbol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/symbol.html">symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/contrib/index.html">symbol.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/image/index.html">symbol.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/linalg/index.html">symbol.linalg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/op/index.html">symbol.op</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/random/index.html">symbol.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/register/index.html">symbol.register</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/symbol/sparse/index.html">symbol.sparse</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/module/index.html">mxnet.module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/contrib/index.html">mxnet.contrib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/autograd/index.html">contrib.autograd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/io/index.html">contrib.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/ndarray/index.html">contrib.ndarray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/onnx/index.html">contrib.onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/quantization/index.html">contrib.quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/symbol/index.html">contrib.symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/tensorboard/index.html">contrib.tensorboard</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/tensorrt/index.html">contrib.tensorrt</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/contrib/text/index.html">contrib.text</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../api/mxnet/index.html">mxnet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/attribute/index.html">mxnet.attribute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/base/index.html">mxnet.base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/callback/index.html">mxnet.callback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/context/index.html">mxnet.context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/engine/index.html">mxnet.engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/executor/index.html">mxnet.executor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/executor_manager/index.html">mxnet.executor_manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/image/index.html">mxnet.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/io/index.html">mxnet.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/kvstore_server/index.html">mxnet.kvstore_server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/libinfo/index.html">mxnet.libinfo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/log/index.html">mxnet.log</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/model/index.html">mxnet.model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/monitor/index.html">mxnet.monitor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/name/index.html">mxnet.name</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/notebook/index.html">mxnet.notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/operator/index.html">mxnet.operator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/profiler/index.html">mxnet.profiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/random/index.html">mxnet.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/recordio/index.html">mxnet.recordio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/registry/index.html">mxnet.registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/rtc/index.html">mxnet.rtc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/runtime/index.html">mxnet.runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/test_utils/index.html">mxnet.test_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/torch/index.html">mxnet.torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/util/index.html">mxnet.util</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../api/mxnet/visualization/index.html">mxnet.visualization</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="machine-translation-with-transformer">
<h1>Machine Translation with Transformer<a class="headerlink" href="#machine-translation-with-transformer" title="Permalink to this headline"></a></h1>
<p>In this notebook, we will show how to train Transformer introduced in
[1] and evaluate the pretrained model using GluonNLP. The model is both
more accurate and lighter to train than previous seq2seq models. We will
together go through:</p>
<ol class="arabic simple">
<li><p>Use the state-of-the-art pretrained Transformer model: we will
evaluate the pretrained SOTA Transformer model and translate a few
sentences ourselves with the <code class="docutils literal notranslate"><span class="pre">BeamSearchTranslator</span></code> using the SOTA
model;</p></li>
<li><p>Train the Transformer yourself: including loading and processing
dataset, define the Transformer model, write train script and
evaluate the trained model. Note that in order to obtain the
state-of-the-art results on WMT 2014 English-German dataset, it will
take around 1 day to have the model. In order to let you run through
the Transformer quickly, we suggest you to start with the <code class="docutils literal notranslate"><span class="pre">TOY</span></code>
dataset sampled from the WMT dataset (by default in this notebook).</p></li>
</ol>
<div class="section" id="preparation">
<h2>Preparation<a class="headerlink" href="#preparation" title="Permalink to this headline"></a></h2>
<div class="section" id="load-mxnet-and-gluonnlp">
<h3>Load MXNet and GluonNLP<a class="headerlink" href="#load-mxnet-and-gluonnlp" title="Permalink to this headline"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mxnet</span> <span class="k">as</span> <span class="nn">mx</span>
<span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">gluon</span>
<span class="kn">import</span> <span class="nn">gluonnlp</span> <span class="k">as</span> <span class="nn">nlp</span>
</pre></div>
</div>
</div>
<div class="section" id="set-environment">
<h3>Set Environment<a class="headerlink" href="#set-environment" title="Permalink to this headline"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">mx</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="use-the-sota-pretrained-transformer-model">
<h2>Use the SOTA Pretrained Transformer model<a class="headerlink" href="#use-the-sota-pretrained-transformer-model" title="Permalink to this headline"></a></h2>
<p>In this subsection, we first load the SOTA Transformer model in GluonNLP
model zoo; and secondly we load the full WMT 2014 English-German test
dataset; and finally evaluate the model.</p>
<div class="section" id="get-the-sota-transformer">
<h3>Get the SOTA Transformer<a class="headerlink" href="#get-the-sota-transformer" title="Permalink to this headline"></a></h3>
<p>Next, we load the pretrained SOTA Transformer using the model API in
GluonNLP. In this way, we can easily get access to the SOTA machine
translation model and use it in your own application.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nmt</span>

<span class="n">wmt_model_name</span> <span class="o">=</span> <span class="s1">&#39;transformer_en_de_512&#39;</span>

<span class="n">wmt_transformer_model</span><span class="p">,</span> <span class="n">wmt_src_vocab</span><span class="p">,</span> <span class="n">wmt_tgt_vocab</span> <span class="o">=</span> \
    <span class="n">nmt</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="n">wmt_model_name</span><span class="p">,</span>
                              <span class="n">dataset_name</span><span class="o">=</span><span class="s1">&#39;WMT2014&#39;</span><span class="p">,</span>
                              <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">wmt_src_vocab</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">wmt_tgt_vocab</span><span class="p">)</span>
</pre></div>
</div>
<p>The Transformer model architecture is shown as below:</p>
<div style="width: 500px;"><p><img alt="transformer" src="tutorials/packages/gluon/text/transformer.png" /></p>
</div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">wmt_transformer_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="load-and-preprocess-wmt-2014-dataset">
<h3>Load and Preprocess WMT 2014 Dataset<a class="headerlink" href="#load-and-preprocess-wmt-2014-dataset" title="Permalink to this headline"></a></h3>
<p>We then load the WMT 2014 English-German test dataset for evaluation
purpose.</p>
<p>The following shows how to process the dataset and cache the processed
dataset for the future use. The processing steps include:</p>
<ul class="simple">
<li><ol class="arabic simple">
<li><p>clip the source and target sequences</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="2">
<li><p>split the string input to a list of tokens</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="3">
<li><p>map the string token into its index in the vocabulary</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="4">
<li><p>append EOS token to source sentence and add BOS and EOS tokens to
target sentence.</p></li>
</ol>
</li>
</ul>
<p>Lets first look at the WMT 2014 corpus.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">hyperparameters</span> <span class="k">as</span> <span class="nn">hparams</span>

<span class="n">wmt_data_test</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">WMT2014BPE</span><span class="p">(</span><span class="s1">&#39;newstest2014&#39;</span><span class="p">,</span>
                                    <span class="n">src_lang</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">src_lang</span><span class="p">,</span>
                                    <span class="n">tgt_lang</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">tgt_lang</span><span class="p">,</span>
                                    <span class="n">full</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Source language </span><span class="si">%s</span><span class="s1">, Target language </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">src_lang</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">tgt_lang</span><span class="p">))</span>

<span class="n">wmt_data_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wmt_test_text</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">WMT2014</span><span class="p">(</span><span class="s1">&#39;newstest2014&#39;</span><span class="p">,</span>
                                 <span class="n">src_lang</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">src_lang</span><span class="p">,</span>
                                 <span class="n">tgt_lang</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">tgt_lang</span><span class="p">,</span>
                                 <span class="n">full</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">wmt_test_text</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>We then generate the target gold translations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wmt_test_tgt_sentences</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">wmt_test_text</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="k">lambda</span> <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">:</span> <span class="n">tgt</span><span class="p">))</span>
<span class="n">wmt_test_tgt_sentences</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dataprocessor</span>

<span class="nb">print</span><span class="p">(</span><span class="n">dataprocessor</span><span class="o">.</span><span class="n">TrainValDataTransform</span><span class="o">.</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wmt_transform_fn</span> <span class="o">=</span> <span class="n">dataprocessor</span><span class="o">.</span><span class="n">TrainValDataTransform</span><span class="p">(</span><span class="n">wmt_src_vocab</span><span class="p">,</span> <span class="n">wmt_tgt_vocab</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">wmt_dataset_processed</span> <span class="o">=</span> <span class="n">wmt_data_test</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">wmt_transform_fn</span><span class="p">,</span> <span class="n">lazy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">wmt_dataset_processed</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="create-sampler-and-dataloader-for-wmt-2014-dataset">
<h3>Create Sampler and DataLoader for WMT 2014 Dataset<a class="headerlink" href="#create-sampler-and-dataloader-for-wmt-2014-dataset" title="Permalink to this headline"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wmt_data_test_with_len</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">SimpleDataset</span><span class="p">([(</span><span class="n">ele</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ele</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span>
    <span class="n">ele</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ele</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ele</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wmt_dataset_processed</span><span class="p">)])</span>
</pre></div>
</div>
<p>Now, we have obtained data_train, data_val, and data_test. The next
step is to construct sampler and DataLoader. The first step is to
construct batchify function, which pads and stacks sequences to form
mini-batch.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wmt_test_batchify_fn</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Pad</span><span class="p">(),</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Pad</span><span class="p">(),</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Stack</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">),</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Stack</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">),</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Stack</span><span class="p">())</span>
</pre></div>
</div>
<p>We can then construct bucketing samplers, which generate batches by
grouping sequences with similar lengths.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wmt_bucket_scheme</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ExpWidthBucket</span><span class="p">(</span><span class="n">bucket_len_step</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wmt_test_batch_sampler</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">FixedBucketSampler</span><span class="p">(</span>
    <span class="n">lengths</span><span class="o">=</span><span class="n">wmt_dataset_processed</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="k">lambda</span> <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">tgt</span><span class="p">)),</span>
    <span class="n">use_average_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">bucket_scheme</span><span class="o">=</span><span class="n">wmt_bucket_scheme</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">wmt_test_batch_sampler</span><span class="o">.</span><span class="n">stats</span><span class="p">())</span>
</pre></div>
</div>
<p>Given the samplers, we can create DataLoader, which is iterable.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wmt_test_data_loader</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">wmt_data_test_with_len</span><span class="p">,</span>
    <span class="n">batch_sampler</span><span class="o">=</span><span class="n">wmt_test_batch_sampler</span><span class="p">,</span>
    <span class="n">batchify_fn</span><span class="o">=</span><span class="n">wmt_test_batchify_fn</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">wmt_test_data_loader</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="evaluate-transformer">
<h3>Evaluate Transformer<a class="headerlink" href="#evaluate-transformer" title="Permalink to this headline"></a></h3>
<p>Next, we generate the SOTA results on the WMT test dataset. As we can
see from the result, we are able to achieve the SOTA number 27.35 as the
BLEU score.</p>
<p>We first define the <code class="docutils literal notranslate"><span class="pre">BeamSearchTranslator</span></code> to generate the actual
translations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">wmt_translator</span> <span class="o">=</span> <span class="n">nmt</span><span class="o">.</span><span class="n">translation</span><span class="o">.</span><span class="n">BeamSearchTranslator</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">wmt_transformer_model</span><span class="p">,</span>
    <span class="n">beam_size</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">beam_size</span><span class="p">,</span>
    <span class="n">scorer</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">BeamSearchScorer</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">lp_alpha</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">lp_k</span><span class="p">),</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
<p>Then we caculate the <code class="docutils literal notranslate"><span class="pre">loss</span></code> as well as the <code class="docutils literal notranslate"><span class="pre">bleu</span></code> score on the WMT
2014 English-German test dataset. Note that the following evalution
process will take ~13 mins to complete.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">utils</span>

<span class="n">eval_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="n">wmt_test_loss_function</span> <span class="o">=</span> <span class="n">nmt</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">SoftmaxCEMaskedLoss</span><span class="p">()</span>
<span class="n">wmt_test_loss_function</span><span class="o">.</span><span class="n">hybridize</span><span class="p">()</span>

<span class="n">wmt_detokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">SacreMosesDetokenizer</span><span class="p">()</span>

<span class="n">wmt_test_loss</span><span class="p">,</span> <span class="n">wmt_test_translation_out</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">wmt_transformer_model</span><span class="p">,</span>
                                                         <span class="n">wmt_test_data_loader</span><span class="p">,</span>
                                                         <span class="n">wmt_test_loss_function</span><span class="p">,</span>
                                                         <span class="n">wmt_translator</span><span class="p">,</span>
                                                         <span class="n">wmt_tgt_vocab</span><span class="p">,</span>
                                                         <span class="n">wmt_detokenizer</span><span class="p">,</span>
                                                         <span class="n">ctx</span><span class="p">)</span>

<span class="n">wmt_test_bleu_score</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nmt</span><span class="o">.</span><span class="n">bleu</span><span class="o">.</span><span class="n">compute_bleu</span><span class="p">([</span><span class="n">wmt_test_tgt_sentences</span><span class="p">],</span>
                                                        <span class="n">wmt_test_translation_out</span><span class="p">,</span>
                                                        <span class="n">tokenized</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                        <span class="n">tokenizer</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">bleu</span><span class="p">,</span>
                                                        <span class="n">split_compound_word</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                        <span class="n">bpe</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;WMT14 EN-DE SOTA model test loss: </span><span class="si">%.2f</span><span class="s1">; test bleu score: </span><span class="si">%.2f</span><span class="s1">; time cost </span><span class="si">%.2f</span><span class="s1">s&#39;</span>
      <span class="o">%</span><span class="p">(</span><span class="n">wmt_test_loss</span><span class="p">,</span> <span class="n">wmt_test_bleu_score</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">eval_start_time</span><span class="p">)))</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sample translations:&#39;</span><span class="p">)</span>
<span class="n">num_pairs</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_pairs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;EN:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">wmt_test_text</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;DE-Candidate:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">wmt_test_translation_out</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;DE-Reference:&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">wmt_test_tgt_sentences</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;========&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="translation-inference">
<h3>Translation Inference<a class="headerlink" href="#translation-inference" title="Permalink to this headline"></a></h3>
<p>We herein show the actual translation example (EN-DE) when given a
source language using the SOTA Transformer model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">utils</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Translate the following English sentence into German:&#39;</span><span class="p">)</span>

<span class="n">sample_src_seq</span> <span class="o">=</span> <span class="s1">&#39;We love each other&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[</span><span class="se">\&#39;</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">sample_src_seq</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\&#39;</span><span class="s1">]&#39;</span><span class="p">)</span>

<span class="n">sample_tgt_seq</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">wmt_translator</span><span class="p">,</span>
                                 <span class="n">sample_src_seq</span><span class="p">,</span>
                                 <span class="n">wmt_src_vocab</span><span class="p">,</span>
                                 <span class="n">wmt_tgt_vocab</span><span class="p">,</span>
                                 <span class="n">wmt_detokenizer</span><span class="p">,</span>
                                 <span class="n">ctx</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The German translation is:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample_tgt_seq</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="train-your-own-transformer">
<h2>Train Your Own Transformer<a class="headerlink" href="#train-your-own-transformer" title="Permalink to this headline"></a></h2>
<p>In this subsection, we will go though the whole process about loading
translation dataset in a more unified way, and create data sampler and
loader, as well as define the Transformer model, finally writing
training script to train the model yourself.</p>
<div class="section" id="load-and-preprocess-toy-dataset">
<h3>Load and Preprocess TOY Dataset<a class="headerlink" href="#load-and-preprocess-toy-dataset" title="Permalink to this headline"></a></h3>
<p>Note that we use demo mode (<code class="docutils literal notranslate"><span class="pre">TOY</span></code> dataset) by default, since loading
the whole WMT 2014 English-German dataset <code class="docutils literal notranslate"><span class="pre">WMT2014BPE</span></code> for the later
training will be slow (~1 day). But if you really want to train to have
the SOTA result, please set <code class="docutils literal notranslate"><span class="pre">demo</span> <span class="pre">=</span> <span class="pre">False</span></code>. In order to make the data
processing blocks execute in a more efficient way, we package them in
the <code class="docutils literal notranslate"><span class="pre">load_translation_data</span></code> (<code class="docutils literal notranslate"><span class="pre">transform</span></code> etc.) function used as
below. The function also returns the gold target sentences as well as
the vocabularies.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">demo</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">demo</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="s1">&#39;TOY&#39;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="s1">&#39;WMT2014BPE&#39;</span>

<span class="n">data_train</span><span class="p">,</span> <span class="n">data_val</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">val_tgt_sentences</span><span class="p">,</span> <span class="n">test_tgt_sentences</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span> <span class="o">=</span> \
    <span class="n">dataprocessor</span><span class="o">.</span><span class="n">load_translation_data</span><span class="p">(</span>
        <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
        <span class="n">src_lang</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">src_lang</span><span class="p">,</span>
        <span class="n">tgt_lang</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">tgt_lang</span><span class="p">)</span>

<span class="n">data_train_lengths</span> <span class="o">=</span> <span class="n">dataprocessor</span><span class="o">.</span><span class="n">get_data_lengths</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>
<span class="n">data_val_lengths</span> <span class="o">=</span> <span class="n">dataprocessor</span><span class="o">.</span><span class="n">get_data_lengths</span><span class="p">(</span><span class="n">data_val</span><span class="p">)</span>
<span class="n">data_test_lengths</span> <span class="o">=</span> <span class="n">dataprocessor</span><span class="o">.</span><span class="n">get_data_lengths</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>

<span class="n">data_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="k">lambda</span> <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">:</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">src</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">tgt</span><span class="p">)),</span> <span class="n">lazy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">data_val</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">SimpleDataset</span><span class="p">([(</span><span class="n">ele</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ele</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">ele</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ele</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">i</span><span class="p">)</span>
                          <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ele</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_val</span><span class="p">)])</span>
<span class="n">data_test</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">SimpleDataset</span><span class="p">([(</span><span class="n">ele</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ele</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">ele</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ele</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">i</span><span class="p">)</span>
                           <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ele</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_test</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="section" id="create-sampler-and-dataloader-for-toy-dataset">
<h3>Create Sampler and DataLoader for TOY Dataset<a class="headerlink" href="#create-sampler-and-dataloader-for-toy-dataset" title="Permalink to this headline"></a></h3>
<p>Now, we have obtained <code class="docutils literal notranslate"><span class="pre">data_train</span></code>, <code class="docutils literal notranslate"><span class="pre">data_val</span></code>, and <code class="docutils literal notranslate"><span class="pre">data_test</span></code>.
The next step is to construct sampler and DataLoader. The first step is
to construct batchify function, which pads and stacks sequences to form
mini-batch.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_batchify_fn</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Pad</span><span class="p">(),</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Pad</span><span class="p">(),</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Stack</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">),</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Stack</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">))</span>
<span class="n">test_batchify_fn</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Tuple</span><span class="p">(</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Pad</span><span class="p">(),</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Pad</span><span class="p">(),</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Stack</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">),</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Stack</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">),</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">batchify</span><span class="o">.</span><span class="n">Stack</span><span class="p">())</span>

<span class="n">target_val_lengths</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">data_val_lengths</span><span class="p">))</span>
<span class="n">target_test_lengths</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">data_test_lengths</span><span class="p">))</span>
</pre></div>
</div>
<p>We can then construct bucketing samplers, which generate batches by
grouping sequences with similar lengths.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bucket_scheme</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ExpWidthBucket</span><span class="p">(</span><span class="n">bucket_len_step</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">train_batch_sampler</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">FixedBucketSampler</span><span class="p">(</span><span class="n">lengths</span><span class="o">=</span><span class="n">data_train_lengths</span><span class="p">,</span>
                                             <span class="n">batch_size</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                                             <span class="n">num_buckets</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">num_buckets</span><span class="p">,</span>
                                             <span class="n">ratio</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                             <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                             <span class="n">use_average_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                             <span class="n">num_shards</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                             <span class="n">bucket_scheme</span><span class="o">=</span><span class="n">bucket_scheme</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Train Batch Sampler:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_batch_sampler</span><span class="o">.</span><span class="n">stats</span><span class="p">())</span>


<span class="n">val_batch_sampler</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">FixedBucketSampler</span><span class="p">(</span><span class="n">lengths</span><span class="o">=</span><span class="n">target_val_lengths</span><span class="p">,</span>
                                       <span class="n">batch_size</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">test_batch_size</span><span class="p">,</span>
                                       <span class="n">num_buckets</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">num_buckets</span><span class="p">,</span>
                                       <span class="n">ratio</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                       <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                       <span class="n">use_average_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                       <span class="n">bucket_scheme</span><span class="o">=</span><span class="n">bucket_scheme</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation Batch Sampler:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">val_batch_sampler</span><span class="o">.</span><span class="n">stats</span><span class="p">())</span>

<span class="n">test_batch_sampler</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">FixedBucketSampler</span><span class="p">(</span><span class="n">lengths</span><span class="o">=</span><span class="n">target_test_lengths</span><span class="p">,</span>
                                        <span class="n">batch_size</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">test_batch_size</span><span class="p">,</span>
                                        <span class="n">num_buckets</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">num_buckets</span><span class="p">,</span>
                                        <span class="n">ratio</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                        <span class="n">use_average_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                        <span class="n">bucket_scheme</span><span class="o">=</span><span class="n">bucket_scheme</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test Batch Sampler:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_batch_sampler</span><span class="o">.</span><span class="n">stats</span><span class="p">())</span>
</pre></div>
</div>
<p>Given the samplers, we can create DataLoader, which is iterable. Note
that the data loader of validation and test dataset share the same
batchifying function <code class="docutils literal notranslate"><span class="pre">test_batchify_fn</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_data_loader</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ShardedDataLoader</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span>
                                      <span class="n">batch_sampler</span><span class="o">=</span><span class="n">train_batch_sampler</span><span class="p">,</span>
                                      <span class="n">batchify_fn</span><span class="o">=</span><span class="n">train_batchify_fn</span><span class="p">,</span>
                                      <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Length of train_data_loader: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data_loader</span><span class="p">))</span>
<span class="n">val_data_loader</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data_val</span><span class="p">,</span>
                             <span class="n">batch_sampler</span><span class="o">=</span><span class="n">val_batch_sampler</span><span class="p">,</span>
                             <span class="n">batchify_fn</span><span class="o">=</span><span class="n">test_batchify_fn</span><span class="p">,</span>
                             <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Length of val_data_loader: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_data_loader</span><span class="p">))</span>
<span class="n">test_data_loader</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data_test</span><span class="p">,</span>
                              <span class="n">batch_sampler</span><span class="o">=</span><span class="n">test_batch_sampler</span><span class="p">,</span>
                              <span class="n">batchify_fn</span><span class="o">=</span><span class="n">test_batchify_fn</span><span class="p">,</span>
                              <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Length of test_data_loader: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data_loader</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="define-transformer-model">
<h3>Define Transformer Model<a class="headerlink" href="#define-transformer-model" title="Permalink to this headline"></a></h3>
<p>After obtaining DataLoader, we then start to define the Transformer. The
encoder and decoder of the Transformer can be easily obtained by calling
<code class="docutils literal notranslate"><span class="pre">get_transformer_encoder_decoder</span></code> function. Then, we use the encoder
and decoder in <code class="docutils literal notranslate"><span class="pre">NMTModel</span></code> to construct the Transformer model.
<code class="docutils literal notranslate"><span class="pre">model.hybridize</span></code> allows computation to be done using symbolic
backend. We also use <code class="docutils literal notranslate"><span class="pre">label_smoothing</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span> <span class="o">=</span> <span class="n">nmt</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">get_transformer_encoder_decoder</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">num_units</span><span class="p">,</span>
                                                   <span class="n">hidden_size</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
                                                   <span class="n">dropout</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
                                                   <span class="n">num_layers</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span>
                                                   <span class="n">num_heads</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span>
                                                   <span class="n">max_src_length</span><span class="o">=</span><span class="mi">530</span><span class="p">,</span>
                                                   <span class="n">max_tgt_length</span><span class="o">=</span><span class="mi">549</span><span class="p">,</span>
                                                   <span class="n">scaled</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">scaled</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nmt</span><span class="o">.</span><span class="n">translation</span><span class="o">.</span><span class="n">NMTModel</span><span class="p">(</span><span class="n">src_vocab</span><span class="o">=</span><span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="o">=</span><span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
                 <span class="n">share_embed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">num_units</span><span class="p">,</span> <span class="n">tie_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">embed_initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;transformer_&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="n">mx</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">Xavier</span><span class="p">(</span><span class="n">magnitude</span><span class="o">=</span><span class="mf">3.0</span><span class="p">),</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">hybridize</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">label_smoothing</span> <span class="o">=</span> <span class="n">nmt</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">LabelSmoothing</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">tgt_vocab</span><span class="p">))</span>
<span class="n">label_smoothing</span><span class="o">.</span><span class="n">hybridize</span><span class="p">()</span>

<span class="n">loss_function</span> <span class="o">=</span> <span class="n">nmt</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">SoftmaxCEMaskedLoss</span><span class="p">(</span><span class="n">sparse_label</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">loss_function</span><span class="o">.</span><span class="n">hybridize</span><span class="p">()</span>

<span class="n">test_loss_function</span> <span class="o">=</span> <span class="n">nmt</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">SoftmaxCEMaskedLoss</span><span class="p">()</span>
<span class="n">test_loss_function</span><span class="o">.</span><span class="n">hybridize</span><span class="p">()</span>

<span class="n">detokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">SacreMosesDetokenizer</span><span class="p">()</span>
</pre></div>
</div>
<p>Here, we build the translator using the beam search</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">translator</span> <span class="o">=</span> <span class="n">nmt</span><span class="o">.</span><span class="n">translation</span><span class="o">.</span><span class="n">BeamSearchTranslator</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                                                  <span class="n">beam_size</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">beam_size</span><span class="p">,</span>
                                                  <span class="n">scorer</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">BeamSearchScorer</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">lp_alpha</span><span class="p">,</span>
                                                                                    <span class="n">K</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">lp_k</span><span class="p">),</span>
                                                  <span class="n">max_length</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Use beam_size=</span><span class="si">%d</span><span class="s1">, alpha=</span><span class="si">%.2f</span><span class="s1">, K=</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">beam_size</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">lp_alpha</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">lp_k</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="training-loop">
<h3>Training Loop<a class="headerlink" href="#training-loop" title="Permalink to this headline"></a></h3>
<p>Before conducting training, we need to create trainer for updating the
parameter. In the following example, we create a trainer that uses ADAM
optimzier.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(),</span> <span class="n">hparams</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                        <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">hparams</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="s1">&#39;beta2&#39;</span><span class="p">:</span> <span class="mf">0.98</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="mf">1e-9</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Use learning_rate=</span><span class="si">%.2f</span><span class="s1">&#39;</span>
      <span class="o">%</span> <span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">))</span>
</pre></div>
</div>
<p>We can then write the training loop. During the training, we perform the
evaluation on validation and testing dataset every epoch, and record the
parameters that give the hightest BLEU score on validation dataset.
Before performing forward and backward, we first use <code class="docutils literal notranslate"><span class="pre">as_in_context</span></code>
function to copy the mini-batch to GPU. The statement
<code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">mx.autograd.record()</span></code> will locate Gluon backend to compute the
gradients for the part inside the block. For ease of observing the
convergence of the update of the <code class="docutils literal notranslate"><span class="pre">Loss</span></code> in a quick fashion, we set the
<code class="docutils literal notranslate"><span class="pre">epochs</span> <span class="pre">=</span> <span class="pre">3</span></code>. Notice that, in order to obtain the best BLEU score, we
will need more epochs and large warmup steps following the original
paper as you can find the SOTA results in the first subsection. Besides,
we use Averaging SGD [2] to update the parameters, since it is more
robust for the machine translation task.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">best_valid_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;Inf&#39;</span><span class="p">)</span>
<span class="n">step_num</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1">#We use warmup steps as introduced in [1].</span>
<span class="n">warmup_steps</span> <span class="o">=</span> <span class="n">hparams</span><span class="o">.</span><span class="n">warmup_steps</span>
<span class="n">grad_interval</span> <span class="o">=</span> <span class="n">hparams</span><span class="o">.</span><span class="n">num_accumulated</span>
<span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">()</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;add&#39;</span><span class="p">)</span>
<span class="c1">#We use Averaging SGD [2] to update the parameters.</span>
<span class="n">average_start</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data_loader</span><span class="p">)</span> <span class="o">//</span> <span class="n">grad_interval</span><span class="p">)</span> <span class="o">*</span> \
    <span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">epochs</span> <span class="o">-</span> <span class="n">hparams</span><span class="o">.</span><span class="n">average_start</span><span class="p">)</span>
<span class="n">average_param_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span>
                                      <span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">update_average_param_dict</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">()</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">utils</span><span class="o">.</span><span class="n">train_one_epoch</span><span class="p">(</span><span class="n">epoch_id</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_data_loader</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span>
                          <span class="n">label_smoothing</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">,</span> <span class="n">grad_interval</span><span class="p">,</span>
                          <span class="n">average_param_dict</span><span class="p">,</span> <span class="n">update_average_param_dict</span><span class="p">,</span>
                          <span class="n">step_num</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>
    <span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">waitall</span><span class="p">()</span>
    <span class="c1"># We define evaluation function as follows. The `evaluate` function use beam search translator</span>
    <span class="c1"># to generate outputs for the validation and testing datasets.</span>
    <span class="n">valid_loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_data_loader</span><span class="p">,</span>
                                   <span class="n">test_loss_function</span><span class="p">,</span> <span class="n">translator</span><span class="p">,</span>
                                   <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">detokenizer</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">%d</span><span class="s1">, valid Loss=</span><span class="si">%.4f</span><span class="s1">, valid ppl=</span><span class="si">%.4f</span><span class="s1">&#39;</span>
          <span class="o">%</span> <span class="p">(</span><span class="n">epoch_id</span><span class="p">,</span> <span class="n">valid_loss</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">valid_loss</span><span class="p">)))</span>
    <span class="n">test_loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_data_loader</span><span class="p">,</span>
                                  <span class="n">test_loss_function</span><span class="p">,</span> <span class="n">translator</span><span class="p">,</span>
                                  <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">detokenizer</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">%d</span><span class="s1">, test Loss=</span><span class="si">%.4f</span><span class="s1">, test ppl=</span><span class="si">%.4f</span><span class="s1">&#39;</span>
          <span class="o">%</span> <span class="p">(</span><span class="n">epoch_id</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)))</span>
    <span class="k">if</span> <span class="n">valid_loss</span> <span class="o">&lt;</span> <span class="n">best_valid_loss</span><span class="p">:</span>
        <span class="n">best_valid_loss</span> <span class="o">=</span> <span class="n">valid_loss</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save_parameters</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">.</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span> <span class="s1">&#39;valid_best.params&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save_parameters</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">.epoch</span><span class="si">{:d}</span><span class="s1">.params&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">epoch_id</span><span class="p">))</span>
<span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">.</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span> <span class="s1">&#39;average.params&#39;</span><span class="p">),</span> <span class="n">average_param_dict</span><span class="p">)</span>

<span class="k">if</span> <span class="n">hparams</span><span class="o">.</span><span class="n">average_start</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">v</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">average_param_dict</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_parameters</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">.</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">save_dir</span><span class="p">,</span> <span class="s1">&#39;valid_best.params&#39;</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
<span class="n">valid_loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_data_loader</span><span class="p">,</span>
                               <span class="n">test_loss_function</span><span class="p">,</span> <span class="n">translator</span><span class="p">,</span>
                               <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">detokenizer</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best model valid Loss=</span><span class="si">%.4f</span><span class="s1">, valid ppl=</span><span class="si">%.4f</span><span class="s1">&#39;</span>
      <span class="o">%</span> <span class="p">(</span><span class="n">valid_loss</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">valid_loss</span><span class="p">)))</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_data_loader</span><span class="p">,</span>
                              <span class="n">test_loss_function</span><span class="p">,</span> <span class="n">translator</span><span class="p">,</span>
                              <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">detokenizer</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best model test Loss=</span><span class="si">%.4f</span><span class="s1">, test ppl=</span><span class="si">%.4f</span><span class="s1">&#39;</span>
      <span class="o">%</span> <span class="p">(</span><span class="n">test_loss</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>Showcase with Transformer, we are able to support the deep neural
networks for seq2seq task. We have already achieved SOTA results on
the WMT 2014 English-German task.</p></li>
<li><p>Gluon NLP Toolkit provides high-level APIs that could drastically
simplify the development process of modeling for NLP tasks sharing
the encoder-decoder structure.</p></li>
<li><p>Low-level APIs in NLP Toolkit enables easy customization.</p></li>
</ul>
<p>Documentation can be found at <a class="reference external" href="https://gluon-nlp.mxnet.io/index.html">https://gluon-nlp.mxnet.io/index.html</a></p>
<p>Code is here <a class="reference external" href="https://github.com/dmlc/gluon-nlp">https://github.com/dmlc/gluon-nlp</a></p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline"></a></h2>
<p>[1] Vaswani, Ashish, et al. Attention is all you need. Advances in
Neural Information Processing Systems. 2017.</p>
<p>[2] Polyak, Boris T, and Anatoli B. Juditsky. Acceleration of
stochastic approximation by averaging. SIAM Journal on Control and
Optimization. 1992.</p>
</div>
</div>


        <hr class="feedback-hr-top" />
<div class="feedback-container">
    <div class="feedback-question">Did this page help you?</div>
    <div class="feedback-answer-container">
        <div class="feedback-answer yes-link" data-response="yes">Yes</div>
        <div class="feedback-answer no-link" data-response="no">No</div>
    </div>
    <div class="feedback-thank-you">Thanks for your feedback!</div>
</div>
<hr class="feedback-hr-bottom" />
        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">Machine Translation with Transformer</a><ul>
<li><a class="reference internal" href="#preparation">Preparation</a><ul>
<li><a class="reference internal" href="#load-mxnet-and-gluonnlp">Load MXNet and GluonNLP</a></li>
<li><a class="reference internal" href="#set-environment">Set Environment</a></li>
</ul>
</li>
<li><a class="reference internal" href="#use-the-sota-pretrained-transformer-model">Use the SOTA Pretrained Transformer model</a><ul>
<li><a class="reference internal" href="#get-the-sota-transformer">Get the SOTA Transformer</a></li>
<li><a class="reference internal" href="#load-and-preprocess-wmt-2014-dataset">Load and Preprocess WMT 2014 Dataset</a></li>
<li><a class="reference internal" href="#create-sampler-and-dataloader-for-wmt-2014-dataset">Create Sampler and DataLoader for WMT 2014 Dataset</a></li>
<li><a class="reference internal" href="#evaluate-transformer">Evaluate Transformer</a></li>
<li><a class="reference internal" href="#translation-inference">Translation Inference</a></li>
</ul>
</li>
<li><a class="reference internal" href="#train-your-own-transformer">Train Your Own Transformer</a><ul>
<li><a class="reference internal" href="#load-and-preprocess-toy-dataset">Load and Preprocess TOY Dataset</a></li>
<li><a class="reference internal" href="#create-sampler-and-dataloader-for-toy-dataset">Create Sampler and DataLoader for TOY Dataset</a></li>
<li><a class="reference internal" href="#define-transformer-model">Define Transformer Model</a></li>
<li><a class="reference internal" href="#training-loop">Training Loop</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>                    

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="gnmt.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>Google Neural Machine Translation</div>
         </div>
     </a>
     <a id="button-next" href="../training/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>Training</div>
        </div>
     </a>
  </div>
            <footer class="site-footer h-card">
    <div class="wrapper">
        <div class="row">
            <div class="col-4">
                <h4 class="footer-category-title">Resources</h4>
                <ul class="contact-list">
                    <li><a class="u-email" href="mailto:dev@mxnet.apache.org">Dev list</a></li>
                    <li><a class="u-email" href="mailto:user@mxnet.apache.org">User mailing list</a></li>
                    <li><a href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home">Developer Wiki</a></li>
                    <li><a href="https://issues.apache.org/jira/projects/MXNET/issues">Jira Tracker</a></li>
                    <li><a href="https://github.com/apache/incubator-mxnet/labels/Roadmap">Github Roadmap</a></li>
                    <li><a href="https://discuss.mxnet.io">MXNet Discuss forum</a></li>
                    <li><a href="/community/contribute">Contribute To MXNet</a></li>

                </ul>
            </div>

            <div class="col-4"><ul class="social-media-list"><li><a href="https://github.com/apache/incubator-mxnet"><svg class="svg-icon"><use xlink:href="../../../../_static/minima-social-icons.svg#github"></use></svg> <span class="username">apache/incubator-mxnet</span></a></li><li><a href="https://www.twitter.com/apachemxnet"><svg class="svg-icon"><use xlink:href="../../../../_static/minima-social-icons.svg#twitter"></use></svg> <span class="username">apachemxnet</span></a></li><li><a href="https://youtube.com/apachemxnet"><svg class="svg-icon"><use xlink:href="../../../../_static/minima-social-icons.svg#youtube"></use></svg> <span class="username">apachemxnet</span></a></li></ul>
</div>

            <div class="col-4 footer-text">
                <p>A flexible and efficient library for deep learning.</p>
            </div>
        </div>
    </div>
</footer>

<footer class="site-footer2">
    <div class="wrapper">
        <div class="row">
            <div class="col-3">
                <img src="../../../../_static/apache_incubator_logo.png" class="footer-logo col-2">
            </div>
            <div class="footer-bottom-warning col-9">
                <p>Apache MXNet is an effort undergoing incubation at The Apache Software Foundation (ASF), <span style="font-weight:bold">sponsored by the <i>Apache Incubator</i></span>. Incubation is required
                    of all newly accepted projects until a further review indicates that the infrastructure,
                    communications, and decision making process have stabilized in a manner consistent with other
                    successful ASF projects. While incubation status is not necessarily a reflection of the completeness
                    or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
                </p><p>"Copyright  2017-2018, The Apache Software Foundation Apache MXNet, MXNet, Apache, the Apache
                    feather, and the Apache MXNet project logo are either registered trademarks or trademarks of the
                    Apache Software Foundation."</p>
            </div>
        </div>
    </div>
</footer>
        
  </body>
</html>