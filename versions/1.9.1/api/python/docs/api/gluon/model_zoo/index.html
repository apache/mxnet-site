<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <style>
    .dropdown {
        position: relative;
        display: inline-block;
    }

    .dropdown-content {
        display: none;
        position: absolute;
        background-color: #f9f9f9;
        min-width: 160px;
        box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
        padding: 12px 16px;
        z-index: 1;
        text-align: left;
    }

    .dropdown:hover .dropdown-content {
        display: block;
    }

    .dropdown-option:hover {
        color: #FF4500;
    }

    .dropdown-option-active {
        color: #FF4500;
        font-weight: lighter;
    }

    .dropdown-option {
        color: #000000;
        font-weight: lighter;
    }

    .dropdown-header {
        color: #FFFFFF;
        display: inline-flex;
    }

    .dropdown-caret {
        width: 18px;
    }

    .dropdown-caret-path {
        fill: #FFFFFF;
    }
    </style>
    
    <title>gluon.model_zoo.vision &#8212; Apache MXNet  documentation</title>

    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mxnet.css" />
    <link rel="stylesheet" href="../../../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/feedback.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/language_data.js"></script>
    <script src="../../../_static/matomo_analytics.js"></script>
    <script src="../../../_static/autodoc.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../../_static/mxnet-icon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="gluon.nn" href="../nn/index.html" />
    <link rel="prev" title="gluon.loss" href="../loss/index.html" /> 
  </head>
<body><header class="site-header" role="banner">
  <div class="wrapper">
      <a class="site-title" rel="author" href="/versions/1.9.1/"><img
            src="../../../_static/mxnet_logo.png" class="site-header-logo"></a>
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger"/>
      <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
      </label>

      <div class="trigger">
        <a class="page-link" href="/versions/1.9.1/get_started">Get Started</a>
        <a class="page-link" href="/versions/1.9.1/features">Features</a>
        <a class="page-link" href="/versions/1.9.1/ecosystem">Ecosystem</a>
        <a class="page-link page-current" href="/versions/1.9.1/api">Docs & Tutorials</a>
        <a class="page-link" href="/versions/1.9.1/trusted_by">Trusted By</a>
        <a class="page-link" href="https://github.com/apache/incubator-mxnet">GitHub</a>
        <div class="dropdown" style="min-width:100px">
          <span class="dropdown-header">Apache
            <svg class="dropdown-caret" viewBox="0 0 32 32" class="icon icon-caret-bottom" aria-hidden="true"><path class="dropdown-caret-path" d="M24 11.305l-7.997 11.39L8 11.305z"></path></svg>
          </span>
          <div class="dropdown-content" style="min-width:250px">
            <a href="https://www.apache.org/foundation/">Apache Software Foundation</a>
            <a href="https://incubator.apache.org/">Apache Incubator</a>
            <a href="https://www.apache.org/licenses/">License</a>
            <a href="/versions/1.9.1/api/faq/security.html">Security</a>
            <a href="https://privacy.apache.org/policies/privacy-policy-public.html">Privacy</a>
            <a href="https://www.apache.org/events/current-event">Events</a>
            <a href="https://www.apache.org/foundation/sponsorship.html">Sponsorship</a>
            <a href="https://www.apache.org/foundation/thanks.html">Thanks</a>
          </div>
        </div>
        <div class="dropdown">
          <span class="dropdown-header">1.9.1
            <svg class="dropdown-caret" viewBox="0 0 32 32" class="icon icon-caret-bottom" aria-hidden="true"><path class="dropdown-caret-path" d="M24 11.305l-7.997 11.39L8 11.305z"></path></svg>
          </span>
          <div class="dropdown-content">
            <a class="dropdown-option" href="/">master</a><br>
            <a class="dropdown-option-active" href="/versions/1.9.1/">1.9.1</a><br>
            <a class="dropdown-option" href="/versions/1.8.0/">1.8.0</a><br>
            <a class="dropdown-option" href="/versions/1.7.0/">1.7.0</a><br>
            <a class="dropdown-option" href="/versions/1.6.0/">1.6.0</a><br>
            <a class="dropdown-option" href="/versions/1.5.0/">1.5.0</a><br>
            <a class="dropdown-option" href="/versions/1.4.1/">1.4.1</a><br>
            <a class="dropdown-option" href="/versions/1.3.1/">1.3.1</a><br>
            <a class="dropdown-option" href="/versions/1.2.1/">1.2.1</a><br>
            <a class="dropdown-option" href="/versions/1.1.0/">1.1.0</a><br>
            <a class="dropdown-option" href="/versions/1.0.0/">1.0.0</a><br>
            <a class="dropdown-option" href="/versions/0.12.1/">0.12.1</a><br>
            <a class="dropdown-option" href="/versions/0.11.0/">0.11.0</a>
          </div>
        </div>
      </div>
    </nav>
  </div>
</header>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="../../index.html">Python API</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link" href="../index.html">mxnet.gluon</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active">gluon.model_zoo.vision</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../../../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../../../_sources/api/gluon/model_zoo/index.rst" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
      </nav>
    </div>
</header><header class="mdl-layout__drawer">      
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/index.html">Python Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/getting-started/index.html">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/index.html">Crash Course</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/1-ndarray.html">Manipulate data with <code class="docutils literal notranslate"><span class="pre">ndarray</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/2-nn.html">Create a neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/3-autograd.html">Automatic differentiation with <code class="docutils literal notranslate"><span class="pre">autograd</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/4-train.html">Train the neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-predict.html">Predict with a pre-trained model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/6-use_gpus.html">Use GPUs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/index.html">Moving to MXNet from Other Frameworks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/pytorch.html">PyTorch vs Apache MXNet</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/gluon_from_experiment_to_deployment.html">Gluon: from experiment to deployment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/logistic_regression_explained.html">Logistic regression explained</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html">MNIST</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/packages/index.html">Packages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/autograd/index.html">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/gluon/index.html">Gluon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/index.html">Blocks</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/custom-layer.html">Custom Layers</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/custom_layer_beginners.html">Customer Layers (Beginners)</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/hybridize.html">Hybridize</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/init.html">Initialization</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/naming.html">Parameter and Block Naming</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/nn.html">Layers and Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/parameters.html">Parameter Management</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/activations/activations.html">Activation Blocks</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/data/index.html">Data Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/data_augmentation.html">Image Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/data_augmentation.html#Spatial-Augmentation">Spatial Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/data_augmentation.html#Color-Augmentation">Color Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/data_augmentation.html#Composed-Augmentations">Composed Augmentations</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html">Gluon <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Using-own-data-with-included-Datasets">Using own data with included <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Using-own-data-with-custom-Datasets">Using own data with custom <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Appendix:-Upgrading-from-Module-DataIter-to-Gluon-DataLoader">Appendix: Upgrading from Module <code class="docutils literal notranslate"><span class="pre">DataIter</span></code> to Gluon <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/image/index.html">Image Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/image-augmentation.html">Image Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/info_gan.html">Image similarity search with InfoGAN</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/mnist.html">Handwritten Digit Recognition</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/pretrained_models.html">Using pre-trained models in MXNet</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/index.html">Losses</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/custom-loss.html">Custom Loss Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/kl_divergence.html">Kullback-Leibler (KL) Divergence</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/loss.html">Loss functions</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/text/index.html">Text Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/text/gnmt.html">Google Neural Machine Translation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/text/transformer.html">Machine Translation with Transformer</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/training/index.html">Training</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/fit_api_tutorial.html">MXNet Gluon Fit API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/trainer.html">Trainer</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/index.html">Learning Rates</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_finder.html">Learning Rate Finder</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_schedules.html">Learning Rate Schedules</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_schedules_advanced.html">Advanced Learning Rate Schedules</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/normalization/index.html">Normalization Blocks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/kvstore/index.html">KVStore</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/kvstore/kvstore.html">Distributed Key-Value Store</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/ndarray/index.html">NDArray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/ndarray/01-ndarray-intro.html">An Intro: Manipulate Data the MXNet Way with NDArray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/ndarray/02-ndarray-operations.html">NDArray Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/ndarray/03-ndarray-contexts.html">NDArray Contexts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/ndarray/gotchas_numpy_in_mxnet.html">Gotchas using NumPy in Apache MXNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/ndarray/sparse/index.html">Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/ndarray/sparse/csr.html">CSRNDArray - NDArray in Compressed Sparse Row Storage Format</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/ndarray/sparse/row_sparse.html">RowSparseNDArray - NDArray for Sparse Gradient Updates</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/ndarray/sparse/train.html">Train a Linear Regression Model with Sparse Symbols</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/ndarray/sparse/train_gluon.html">Sparse NDArrays with Gluon</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/onnx/index.html">ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/onnx/fine_tuning_gluon.html">Fine-tuning an ONNX model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/onnx/inference_on_onnx_model.html">Running inference on MXNet/Gluon from an ONNX model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/onnx/super_resolution.html">Importing an ONNX model into MXNet</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/deploy/export/onnx.html">Export ONNX Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/optimizer/index.html">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/viz/index.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/visualize_graph">Visualize networks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/performance/index.html">Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/compression/index.html">Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/compression/int8.html">Deploy with int-8</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/float16">Float16</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/gradient_compression">Gradient Compression</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/int8_inference.html">GluonCV with Quantized Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/backend/index.html">Accelerated Backend Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/mkldnn/index.html">Intel MKL-DNN</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/mkldnn/mkldnn_quantization.html">Quantize with MKL-DNN backend</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/mkldnn/mkldnn_quantization.html#Improving-accuracy-with-Intel®-Neural-Compressor">Improving accuracy with Intel® Neural Compressor</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/mkldnn/mkldnn_readme.html">Install MXNet with MKL-DNN</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/tensorrt/index.html">TensorRT</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/tensorrt/tensorrt.html">Optimizing Deep Learning Computation Graphs with TensorRT</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/tvm.html">Use TVM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/profiler.html">Profiling MXNet Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/amp.html">Using AMP: Automatic Mixed Precision</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/deploy/index.html">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/export/index.html">Export</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/export/onnx.html">Exporting to ONNX format</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/export_network.html">Export Gluon CV Models</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Save / Load Parameters</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/inference/index.html">Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/cpp.html">Deploy into C++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/image_classification_jetson.html">Image Classication using pretrained ResNet-50 model on Jetson module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/scala.html">Deploy into a Java or Scala Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/wine_detector.html">Real-time Object Detection with MXNet On The Raspberry Pi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/index.html">Run on AWS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_ec2.html">Run on an EC2 Instance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_sagemaker.html">Run on Amazon SageMaker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/cloud.html">MXNet on the Cloud</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/extend/index.html">Extend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/extend/custom_layer.html">Custom Layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/extend/customop.html">Custom Numpy Operators</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/new_op">New Operator Creation</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/add_op_in_backend">New Operator in MXNet Backend</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../ndarray/index.html">mxnet.ndarray</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/ndarray.html">ndarray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/contrib/index.html">ndarray.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/image/index.html">ndarray.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/linalg/index.html">ndarray.linalg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/op/index.html">ndarray.op</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/random/index.html">ndarray.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/register/index.html">ndarray.register</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/sparse/index.html">ndarray.sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/utils/index.html">ndarray.utils</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">mxnet.gluon</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../block.html">gluon.Block</a></li>
<li class="toctree-l3"><a class="reference internal" href="../hybrid_block.html">gluon.HybridBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../symbol_block.html">gluon.SymbolBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../constant.html">gluon.Constant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../parameter.html">gluon.Parameter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../parameter_dict.html">gluon.ParameterDict</a></li>
<li class="toctree-l3"><a class="reference internal" href="../trainer.html">gluon.Trainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contrib/index.html">gluon.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data/index.html">gluon.data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../data/vision/index.html">data.vision</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../data/vision/datasets/index.html">vision.datasets</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/vision/transforms/index.html">vision.transforms</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../loss/index.html">gluon.loss</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">gluon.model_zoo.vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nn/index.html">gluon.nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../rnn/index.html">gluon.rnn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils/index.html">gluon.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../autograd/index.html">mxnet.autograd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../initializer/index.html">mxnet.initializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optimizer/index.html">mxnet.optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../lr_scheduler/index.html">mxnet.lr_scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../metric/index.html">mxnet.metric</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore/index.html">mxnet.kvstore</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../symbol/index.html">mxnet.symbol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/symbol.html">symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/contrib/index.html">symbol.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/image/index.html">symbol.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/linalg/index.html">symbol.linalg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/op/index.html">symbol.op</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/random/index.html">symbol.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/register/index.html">symbol.register</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/sparse/index.html">symbol.sparse</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../module/index.html">mxnet.module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contrib/index.html">mxnet.contrib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/autograd/index.html">contrib.autograd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/io/index.html">contrib.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/ndarray/index.html">contrib.ndarray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/onnx/index.html">contrib.onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/quantization/index.html">contrib.quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/symbol/index.html">contrib.symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/tensorboard/index.html">contrib.tensorboard</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/tensorrt/index.html">contrib.tensorrt</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/text/index.html">contrib.text</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../mxnet/index.html">mxnet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/attribute/index.html">mxnet.attribute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/base/index.html">mxnet.base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/callback/index.html">mxnet.callback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/context/index.html">mxnet.context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/engine/index.html">mxnet.engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/executor/index.html">mxnet.executor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/executor_manager/index.html">mxnet.executor_manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/image/index.html">mxnet.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/io/index.html">mxnet.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/kvstore_server/index.html">mxnet.kvstore_server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/libinfo/index.html">mxnet.libinfo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/log/index.html">mxnet.log</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/model/index.html">mxnet.model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/monitor/index.html">mxnet.monitor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/name/index.html">mxnet.name</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/notebook/index.html">mxnet.notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/operator/index.html">mxnet.operator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/profiler/index.html">mxnet.profiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/random/index.html">mxnet.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/recordio/index.html">mxnet.recordio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/registry/index.html">mxnet.registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/rtc/index.html">mxnet.rtc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/runtime/index.html">mxnet.runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/test_utils/index.html">mxnet.test_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/torch/index.html">mxnet.torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/util/index.html">mxnet.util</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/visualization/index.html">mxnet.visualization</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

        <script type="text/javascript" src="../../../_static/sphinx_materialdesign_theme.js "></script>
        <script type="text/javascript" src="../../../_static/feedback.js"></script>
    <header class="mdl-layout__drawer">      
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/index.html">Python Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/getting-started/index.html">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/index.html">Crash Course</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/1-ndarray.html">Manipulate data with <code class="docutils literal notranslate"><span class="pre">ndarray</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/2-nn.html">Create a neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/3-autograd.html">Automatic differentiation with <code class="docutils literal notranslate"><span class="pre">autograd</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/4-train.html">Train the neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-predict.html">Predict with a pre-trained model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/6-use_gpus.html">Use GPUs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/index.html">Moving to MXNet from Other Frameworks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/pytorch.html">PyTorch vs Apache MXNet</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/gluon_from_experiment_to_deployment.html">Gluon: from experiment to deployment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/logistic_regression_explained.html">Logistic regression explained</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html">MNIST</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/packages/index.html">Packages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/autograd/index.html">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/gluon/index.html">Gluon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/index.html">Blocks</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/custom-layer.html">Custom Layers</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/custom_layer_beginners.html">Customer Layers (Beginners)</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/hybridize.html">Hybridize</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/init.html">Initialization</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/naming.html">Parameter and Block Naming</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/nn.html">Layers and Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/parameters.html">Parameter Management</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/activations/activations.html">Activation Blocks</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/data/index.html">Data Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/data_augmentation.html">Image Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/data_augmentation.html#Spatial-Augmentation">Spatial Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/data_augmentation.html#Color-Augmentation">Color Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/data_augmentation.html#Composed-Augmentations">Composed Augmentations</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html">Gluon <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Using-own-data-with-included-Datasets">Using own data with included <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Using-own-data-with-custom-Datasets">Using own data with custom <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Appendix:-Upgrading-from-Module-DataIter-to-Gluon-DataLoader">Appendix: Upgrading from Module <code class="docutils literal notranslate"><span class="pre">DataIter</span></code> to Gluon <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/image/index.html">Image Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/image-augmentation.html">Image Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/info_gan.html">Image similarity search with InfoGAN</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/mnist.html">Handwritten Digit Recognition</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/pretrained_models.html">Using pre-trained models in MXNet</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/index.html">Losses</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/custom-loss.html">Custom Loss Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/kl_divergence.html">Kullback-Leibler (KL) Divergence</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/loss.html">Loss functions</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/text/index.html">Text Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/text/gnmt.html">Google Neural Machine Translation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/text/transformer.html">Machine Translation with Transformer</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/training/index.html">Training</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/fit_api_tutorial.html">MXNet Gluon Fit API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/trainer.html">Trainer</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/index.html">Learning Rates</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_finder.html">Learning Rate Finder</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_schedules.html">Learning Rate Schedules</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_schedules_advanced.html">Advanced Learning Rate Schedules</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/normalization/index.html">Normalization Blocks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/kvstore/index.html">KVStore</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/kvstore/kvstore.html">Distributed Key-Value Store</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/ndarray/index.html">NDArray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/ndarray/01-ndarray-intro.html">An Intro: Manipulate Data the MXNet Way with NDArray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/ndarray/02-ndarray-operations.html">NDArray Operations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/ndarray/03-ndarray-contexts.html">NDArray Contexts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/ndarray/gotchas_numpy_in_mxnet.html">Gotchas using NumPy in Apache MXNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/ndarray/sparse/index.html">Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/ndarray/sparse/csr.html">CSRNDArray - NDArray in Compressed Sparse Row Storage Format</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/ndarray/sparse/row_sparse.html">RowSparseNDArray - NDArray for Sparse Gradient Updates</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/ndarray/sparse/train.html">Train a Linear Regression Model with Sparse Symbols</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/ndarray/sparse/train_gluon.html">Sparse NDArrays with Gluon</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/onnx/index.html">ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/onnx/fine_tuning_gluon.html">Fine-tuning an ONNX model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/onnx/inference_on_onnx_model.html">Running inference on MXNet/Gluon from an ONNX model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/onnx/super_resolution.html">Importing an ONNX model into MXNet</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/deploy/export/onnx.html">Export ONNX Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/optimizer/index.html">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/viz/index.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/visualize_graph">Visualize networks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/performance/index.html">Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/compression/index.html">Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/compression/int8.html">Deploy with int-8</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/float16">Float16</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/gradient_compression">Gradient Compression</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/int8_inference.html">GluonCV with Quantized Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/backend/index.html">Accelerated Backend Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/mkldnn/index.html">Intel MKL-DNN</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/mkldnn/mkldnn_quantization.html">Quantize with MKL-DNN backend</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/mkldnn/mkldnn_quantization.html#Improving-accuracy-with-Intel®-Neural-Compressor">Improving accuracy with Intel® Neural Compressor</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/mkldnn/mkldnn_readme.html">Install MXNet with MKL-DNN</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/tensorrt/index.html">TensorRT</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/tensorrt/tensorrt.html">Optimizing Deep Learning Computation Graphs with TensorRT</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/tvm.html">Use TVM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/profiler.html">Profiling MXNet Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/amp.html">Using AMP: Automatic Mixed Precision</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/deploy/index.html">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/export/index.html">Export</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/export/onnx.html">Exporting to ONNX format</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/export_network.html">Export Gluon CV Models</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Save / Load Parameters</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/inference/index.html">Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/cpp.html">Deploy into C++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/image_classification_jetson.html">Image Classication using pretrained ResNet-50 model on Jetson module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/scala.html">Deploy into a Java or Scala Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/wine_detector.html">Real-time Object Detection with MXNet On The Raspberry Pi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/index.html">Run on AWS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_ec2.html">Run on an EC2 Instance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_sagemaker.html">Run on Amazon SageMaker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/cloud.html">MXNet on the Cloud</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/extend/index.html">Extend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/extend/custom_layer.html">Custom Layers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/extend/customop.html">Custom Numpy Operators</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/new_op">New Operator Creation</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/add_op_in_backend">New Operator in MXNet Backend</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../ndarray/index.html">mxnet.ndarray</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/ndarray.html">ndarray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/contrib/index.html">ndarray.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/image/index.html">ndarray.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/linalg/index.html">ndarray.linalg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/op/index.html">ndarray.op</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/random/index.html">ndarray.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/register/index.html">ndarray.register</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/sparse/index.html">ndarray.sparse</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ndarray/utils/index.html">ndarray.utils</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">mxnet.gluon</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../block.html">gluon.Block</a></li>
<li class="toctree-l3"><a class="reference internal" href="../hybrid_block.html">gluon.HybridBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../symbol_block.html">gluon.SymbolBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../constant.html">gluon.Constant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../parameter.html">gluon.Parameter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../parameter_dict.html">gluon.ParameterDict</a></li>
<li class="toctree-l3"><a class="reference internal" href="../trainer.html">gluon.Trainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contrib/index.html">gluon.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data/index.html">gluon.data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../data/vision/index.html">data.vision</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../data/vision/datasets/index.html">vision.datasets</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/vision/transforms/index.html">vision.transforms</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../loss/index.html">gluon.loss</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">gluon.model_zoo.vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nn/index.html">gluon.nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../rnn/index.html">gluon.rnn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils/index.html">gluon.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../autograd/index.html">mxnet.autograd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../initializer/index.html">mxnet.initializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optimizer/index.html">mxnet.optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../lr_scheduler/index.html">mxnet.lr_scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../metric/index.html">mxnet.metric</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore/index.html">mxnet.kvstore</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../symbol/index.html">mxnet.symbol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/symbol.html">symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/contrib/index.html">symbol.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/image/index.html">symbol.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/linalg/index.html">symbol.linalg</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/op/index.html">symbol.op</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/random/index.html">symbol.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/register/index.html">symbol.register</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../symbol/sparse/index.html">symbol.sparse</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../module/index.html">mxnet.module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contrib/index.html">mxnet.contrib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/autograd/index.html">contrib.autograd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/io/index.html">contrib.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/ndarray/index.html">contrib.ndarray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/onnx/index.html">contrib.onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/quantization/index.html">contrib.quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/symbol/index.html">contrib.symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/tensorboard/index.html">contrib.tensorboard</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/tensorrt/index.html">contrib.tensorrt</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/text/index.html">contrib.text</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../mxnet/index.html">mxnet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/attribute/index.html">mxnet.attribute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/base/index.html">mxnet.base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/callback/index.html">mxnet.callback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/context/index.html">mxnet.context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/engine/index.html">mxnet.engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/executor/index.html">mxnet.executor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/executor_manager/index.html">mxnet.executor_manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/image/index.html">mxnet.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/io/index.html">mxnet.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/kvstore_server/index.html">mxnet.kvstore_server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/libinfo/index.html">mxnet.libinfo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/log/index.html">mxnet.log</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/model/index.html">mxnet.model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/monitor/index.html">mxnet.monitor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/name/index.html">mxnet.name</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/notebook/index.html">mxnet.notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/operator/index.html">mxnet.operator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/profiler/index.html">mxnet.profiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/random/index.html">mxnet.random</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/recordio/index.html">mxnet.recordio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/registry/index.html">mxnet.registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/rtc/index.html">mxnet.rtc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/runtime/index.html">mxnet.runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/test_utils/index.html">mxnet.test_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/torch/index.html">mxnet.torch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/util/index.html">mxnet.util</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnet/visualization/index.html">mxnet.visualization</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="gluon-model-zoo-vision">
<h1>gluon.model_zoo.vision<a class="headerlink" href="#gluon-model-zoo-vision" title="Permalink to this headline">¶</a></h1>
<p>Module for pre-defined neural network models.</p>
<p>This module contains definitions for the following model architectures:
-  <a class="reference external" href="https://arxiv.org/abs/1404.5997">AlexNet</a>
-  <a class="reference external" href="https://arxiv.org/abs/1608.06993">DenseNet</a>
-  <a class="reference external" href="http://arxiv.org/abs/1512.00567">Inception V3</a>
-  <a class="reference external" href="https://arxiv.org/abs/1512.03385">ResNet V1</a>
-  <a class="reference external" href="https://arxiv.org/abs/1603.05027">ResNet V2</a>
-  <a class="reference external" href="https://arxiv.org/abs/1602.07360">SqueezeNet</a>
-  <a class="reference external" href="https://arxiv.org/abs/1409.1556">VGG</a>
-  <a class="reference external" href="https://arxiv.org/abs/1704.04861">MobileNet</a>
-  <a class="reference external" href="https://arxiv.org/abs/1801.04381">MobileNetV2</a></p>
<p>You can construct a model with random weights by calling its constructor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mxnet.gluon.model_zoo</span> <span class="kn">import</span> <span class="n">vision</span>
<span class="n">resnet18</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">resnet18_v1</span><span class="p">()</span>
<span class="n">alexnet</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">alexnet</span><span class="p">()</span>
<span class="n">squeezenet</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">squeezenet1_0</span><span class="p">()</span>
<span class="n">densenet</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">densenet_161</span><span class="p">()</span>
</pre></div>
</div>
<p>We provide pre-trained models for all the listed models.
These models can constructed by passing <code class="docutils literal notranslate"><span class="pre">pretrained=True</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mxnet.gluon.model_zoo</span> <span class="kn">import</span> <span class="n">vision</span>
<span class="n">resnet18</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">resnet18_v1</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">alexnet</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">alexnet</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>All pre-trained models expect input images normalized in the same way,
i.e. mini-batches of 3-channel RGB images of shape (N x 3 x H x W),
where N is the batch size, and H and W are expected to be at least 224.
The images have to be loaded in to a range of [0, 1] and then normalized
using <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">=</span> <span class="pre">[0.485,</span> <span class="pre">0.456,</span> <span class="pre">0.406]</span></code> and <code class="docutils literal notranslate"><span class="pre">std</span> <span class="pre">=</span> <span class="pre">[0.229,</span> <span class="pre">0.224,</span> <span class="pre">0.225]</span></code>.
The transformation should preferrably happen at preprocessing. You can use
<code class="docutils literal notranslate"><span class="pre">mx.image.color_normalize</span></code> for such transformation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">/</span><span class="mi">255</span>
<span class="n">normalized</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">color_normalize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                      <span class="n">mean</span><span class="o">=</span><span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">]),</span>
                                      <span class="n">std</span><span class="o">=</span><span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]))</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">get_model</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision.html#get_model"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a pre-defined model by name</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – Name of the model.</p></li>
<li><p><strong>pretrained</strong> (<em>bool</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>classes</strong> (<em>int</em>) – Number of classes for the output layer.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../hybrid_block.html#mxnet.gluon.HybridBlock" title="mxnet.gluon.HybridBlock">gluon.HybridBlock</a></p>
</dd>
</dl>
</dd></dl>

<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.get_model" title="mxnet.gluon.model_zoo.vision.get_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_model</span></code></a>(name, **kwargs)</p></td>
<td><p>Returns a pre-defined model by name</p></td>
</tr>
</tbody>
</table>
<div class="section" id="resnet">
<h2>ResNet<a class="headerlink" href="#resnet" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet18_v1" title="mxnet.gluon.model_zoo.vision.resnet18_v1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet18_v1</span></code></a>(**kwargs)</p></td>
<td><p>ResNet-18 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet34_v1" title="mxnet.gluon.model_zoo.vision.resnet34_v1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet34_v1</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-34 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet50_v1" title="mxnet.gluon.model_zoo.vision.resnet50_v1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet50_v1</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-50 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet101_v1" title="mxnet.gluon.model_zoo.vision.resnet101_v1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet101_v1</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-101 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet152_v1" title="mxnet.gluon.model_zoo.vision.resnet152_v1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet152_v1</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-152 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet18_v2" title="mxnet.gluon.model_zoo.vision.resnet18_v2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet18_v2</span></code></a>(**kwargs)</p></td>
<td><p>ResNet-18 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet34_v2" title="mxnet.gluon.model_zoo.vision.resnet34_v2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet34_v2</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-34 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet50_v2" title="mxnet.gluon.model_zoo.vision.resnet50_v2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet50_v2</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-50 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet101_v2" title="mxnet.gluon.model_zoo.vision.resnet101_v2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet101_v2</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-101 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet152_v2" title="mxnet.gluon.model_zoo.vision.resnet152_v2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet152_v2</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-152 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
</tbody>
</table>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.ResNetV1" title="mxnet.gluon.model_zoo.vision.ResNetV1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ResNetV1</span></code></a>(block, layers, channels[, classes, …])</p></td>
<td><p><p>ResNet V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.ResNetV2" title="mxnet.gluon.model_zoo.vision.ResNetV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ResNetV2</span></code></a>(block, layers, channels[, classes, …])</p></td>
<td><p><p>ResNet V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BasicBlockV1" title="mxnet.gluon.model_zoo.vision.BasicBlockV1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BasicBlockV1</span></code></a>(channels, stride[, downsample, …])</p></td>
<td><p><p>BasicBlock V1 from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.This is used for ResNet V1 for 18, 34 layers..</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BasicBlockV2" title="mxnet.gluon.model_zoo.vision.BasicBlockV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BasicBlockV2</span></code></a>(channels, stride[, downsample, …])</p></td>
<td><p><p>BasicBlock V2 from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.This is used for ResNet V2 for 18, 34 layers..</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BottleneckV1" title="mxnet.gluon.model_zoo.vision.BottleneckV1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottleneckV1</span></code></a>(channels, stride[, downsample, …])</p></td>
<td><p><p>Bottleneck V1 from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.This is used for ResNet V1 for 50, 101, 152 layers..</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BottleneckV2" title="mxnet.gluon.model_zoo.vision.BottleneckV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottleneckV2</span></code></a>(channels, stride[, downsample, …])</p></td>
<td><p><p>Bottleneck V2 from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.This is used for ResNet V2 for 50, 101, 152 layers..</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.get_resnet" title="mxnet.gluon.model_zoo.vision.get_resnet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_resnet</span></code></a>(version, num_layers[, …])</p></td>
<td><p><p>ResNet V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.ResNet V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper..</p>
</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id17">
<h2>VGG<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg11" title="mxnet.gluon.model_zoo.vision.vgg11"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg11</span></code></a>(**kwargs)</p></td>
<td><p>VGG-11 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg13" title="mxnet.gluon.model_zoo.vision.vgg13"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg13</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-13 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg16" title="mxnet.gluon.model_zoo.vision.vgg16"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg16</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-16 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg19" title="mxnet.gluon.model_zoo.vision.vgg19"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg19</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-19 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg11_bn" title="mxnet.gluon.model_zoo.vision.vgg11_bn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg11_bn</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-11 model with batch normalization from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg13_bn" title="mxnet.gluon.model_zoo.vision.vgg13_bn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg13_bn</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-13 model with batch normalization from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg16_bn" title="mxnet.gluon.model_zoo.vision.vgg16_bn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg16_bn</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-16 model with batch normalization from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg19_bn" title="mxnet.gluon.model_zoo.vision.vgg19_bn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg19_bn</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-19 model with batch normalization from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
</tbody>
</table>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.VGG" title="mxnet.gluon.model_zoo.vision.VGG"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VGG</span></code></a>(layers, filters[, classes, batch_norm])</p></td>
<td><p><p>VGG model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.get_vgg" title="mxnet.gluon.model_zoo.vision.get_vgg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_vgg</span></code></a>(num_layers[, pretrained, ctx, root])</p></td>
<td><p><p>VGG model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id27">
<h2>Alexnet<a class="headerlink" href="#id27" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.alexnet" title="mxnet.gluon.model_zoo.vision.alexnet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">alexnet</span></code></a>([pretrained, ctx, root])</p></td>
<td><p>AlexNet model from the <a class="reference external" href="https://arxiv.org/abs/1404.5997">“One weird trick…”</a> paper.</p></td>
</tr>
</tbody>
</table>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.AlexNet" title="mxnet.gluon.model_zoo.vision.AlexNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AlexNet</span></code></a>([classes])</p></td>
<td><p><p>AlexNet model from the <a class="reference external" href="https://arxiv.org/abs/1404.5997">“One weird trick…”</a> paper.</p>
</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id29">
<h2>DenseNet<a class="headerlink" href="#id29" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.densenet121" title="mxnet.gluon.model_zoo.vision.densenet121"><code class="xref py py-obj docutils literal notranslate"><span class="pre">densenet121</span></code></a>(**kwargs)</p></td>
<td><p>Densenet-BC 121-layer model from the <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.densenet161" title="mxnet.gluon.model_zoo.vision.densenet161"><code class="xref py py-obj docutils literal notranslate"><span class="pre">densenet161</span></code></a>(**kwargs)</p></td>
<td><p><p>Densenet-BC 161-layer model from the <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.densenet169" title="mxnet.gluon.model_zoo.vision.densenet169"><code class="xref py py-obj docutils literal notranslate"><span class="pre">densenet169</span></code></a>(**kwargs)</p></td>
<td><p><p>Densenet-BC 169-layer model from the <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.densenet201" title="mxnet.gluon.model_zoo.vision.densenet201"><code class="xref py py-obj docutils literal notranslate"><span class="pre">densenet201</span></code></a>(**kwargs)</p></td>
<td><p><p>Densenet-BC 201-layer model from the <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
</p></td>
</tr>
</tbody>
</table>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.DenseNet" title="mxnet.gluon.model_zoo.vision.DenseNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DenseNet</span></code></a>(num_init_features, growth_rate, …)</p></td>
<td><p><p>Densenet-BC model from the <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id34">
<h2>SqueezeNet<a class="headerlink" href="#id34" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.squeezenet1_0" title="mxnet.gluon.model_zoo.vision.squeezenet1_0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">squeezenet1_0</span></code></a>(**kwargs)</p></td>
<td><p>SqueezeNet 1.0 model from the <a class="reference external" href="https://arxiv.org/abs/1602.07360">“SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size”</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.squeezenet1_1" title="mxnet.gluon.model_zoo.vision.squeezenet1_1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">squeezenet1_1</span></code></a>(**kwargs)</p></td>
<td><p>SqueezeNet 1.1 model from the <a class="reference external" href="https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1">official SqueezeNet repo</a>.SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy..</p></td>
</tr>
</tbody>
</table>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.SqueezeNet" title="mxnet.gluon.model_zoo.vision.SqueezeNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SqueezeNet</span></code></a>(version[, classes])</p></td>
<td><p><p>SqueezeNet model from the <a class="reference external" href="https://arxiv.org/abs/1602.07360">“SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size”</a> paper.SqueezeNet 1.1 model from the <a class="reference external" href="https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1">official SqueezeNet repo</a>.SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy..</p>
</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="inception">
<h2>Inception<a class="headerlink" href="#inception" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.inception_v3" title="mxnet.gluon.model_zoo.vision.inception_v3"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inception_v3</span></code></a>([pretrained, ctx, root])</p></td>
<td><p>Inception v3 model from <a class="reference external" href="http://arxiv.org/abs/1512.00567">“Rethinking the Inception Architecture for Computer Vision”</a> paper.</p></td>
</tr>
</tbody>
</table>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.Inception3" title="mxnet.gluon.model_zoo.vision.Inception3"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Inception3</span></code></a>([classes])</p></td>
<td><p><p>Inception v3 model from <a class="reference external" href="http://arxiv.org/abs/1512.00567">“Rethinking the Inception Architecture for Computer Vision”</a> paper.</p>
</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id38">
<h2>MobileNet<a class="headerlink" href="#id38" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet1_0" title="mxnet.gluon.model_zoo.vision.mobilenet1_0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet1_0</span></code></a>(**kwargs)</p></td>
<td><p>MobileNet model from the <a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 1.0.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet0_75" title="mxnet.gluon.model_zoo.vision.mobilenet0_75"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet0_75</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNet model from the <a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 0.75.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet0_5" title="mxnet.gluon.model_zoo.vision.mobilenet0_5"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet0_5</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNet model from the <a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 0.5.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet0_25" title="mxnet.gluon.model_zoo.vision.mobilenet0_25"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet0_25</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNet model from the <a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 0.25.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0" title="mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet_v2_1_0</span></code></a>(**kwargs)</p></td>
<td><p>MobileNetV2 model from the <a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75" title="mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet_v2_0_75</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNetV2 model from the <a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_0_5" title="mxnet.gluon.model_zoo.vision.mobilenet_v2_0_5"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet_v2_0_5</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNetV2 model from the <a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25" title="mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet_v2_0_25</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNetV2 model from the <a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
</p></td>
</tr>
</tbody>
</table>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.MobileNet" title="mxnet.gluon.model_zoo.vision.MobileNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MobileNet</span></code></a>([multiplier, classes])</p></td>
<td><p><p>MobileNet model from the <a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.MobileNetV2" title="mxnet.gluon.model_zoo.vision.MobileNetV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MobileNetV2</span></code></a>([multiplier, classes])</p></td>
<td><p><p>MobileNetV2 model from the <a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-mxnet.gluon.model_zoo.vision">
<span id="api-reference"></span><h2>API Reference<a class="headerlink" href="#module-mxnet.gluon.model_zoo.vision" title="Permalink to this headline">¶</a></h2>
<p>Module for pre-defined neural network models.</p>
<p>This module contains definitions for the following model architectures:
-  <a class="reference external" href="https://arxiv.org/abs/1404.5997">AlexNet</a>
-  <a class="reference external" href="https://arxiv.org/abs/1608.06993">DenseNet</a>
-  <a class="reference external" href="http://arxiv.org/abs/1512.00567">Inception V3</a>
-  <a class="reference external" href="https://arxiv.org/abs/1512.03385">ResNet V1</a>
-  <a class="reference external" href="https://arxiv.org/abs/1603.05027">ResNet V2</a>
-  <a class="reference external" href="https://arxiv.org/abs/1602.07360">SqueezeNet</a>
-  <a class="reference external" href="https://arxiv.org/abs/1409.1556">VGG</a>
-  <a class="reference external" href="https://arxiv.org/abs/1704.04861">MobileNet</a>
-  <a class="reference external" href="https://arxiv.org/abs/1801.04381">MobileNetV2</a></p>
<p>You can construct a model with random weights by calling its constructor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mxnet.gluon.model_zoo</span> <span class="kn">import</span> <span class="n">vision</span>
<span class="n">resnet18</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">resnet18_v1</span><span class="p">()</span>
<span class="n">alexnet</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">alexnet</span><span class="p">()</span>
<span class="n">squeezenet</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">squeezenet1_0</span><span class="p">()</span>
<span class="n">densenet</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">densenet_161</span><span class="p">()</span>
</pre></div>
</div>
<p>We provide pre-trained models for all the listed models.
These models can constructed by passing <code class="docutils literal notranslate"><span class="pre">pretrained=True</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mxnet.gluon.model_zoo</span> <span class="kn">import</span> <span class="n">vision</span>
<span class="n">resnet18</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">resnet18_v1</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">alexnet</span> <span class="o">=</span> <span class="n">vision</span><span class="o">.</span><span class="n">alexnet</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>All pre-trained models expect input images normalized in the same way,
i.e. mini-batches of 3-channel RGB images of shape (N x 3 x H x W),
where N is the batch size, and H and W are expected to be at least 224.
The images have to be loaded in to a range of [0, 1] and then normalized
using <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">=</span> <span class="pre">[0.485,</span> <span class="pre">0.456,</span> <span class="pre">0.406]</span></code> and <code class="docutils literal notranslate"><span class="pre">std</span> <span class="pre">=</span> <span class="pre">[0.229,</span> <span class="pre">0.224,</span> <span class="pre">0.225]</span></code>.
The transformation should preferrably happen at preprocessing. You can use
<code class="docutils literal notranslate"><span class="pre">mx.image.color_normalize</span></code> for such transformation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">/</span><span class="mi">255</span>
<span class="n">normalized</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">color_normalize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                      <span class="n">mean</span><span class="o">=</span><span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">]),</span>
                                      <span class="n">std</span><span class="o">=</span><span class="n">mx</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]))</span>
</pre></div>
</div>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.AlexNet" title="mxnet.gluon.model_zoo.vision.AlexNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AlexNet</span></code></a>([classes])</p></td>
<td><p><p>AlexNet model from the <a class="reference external" href="https://arxiv.org/abs/1404.5997">“One weird trick…”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BasicBlockV1" title="mxnet.gluon.model_zoo.vision.BasicBlockV1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BasicBlockV1</span></code></a>(channels, stride[, downsample, …])</p></td>
<td><p><p>BasicBlock V1 from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BasicBlockV2" title="mxnet.gluon.model_zoo.vision.BasicBlockV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BasicBlockV2</span></code></a>(channels, stride[, downsample, …])</p></td>
<td><p><p>BasicBlock V2 from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BottleneckV1" title="mxnet.gluon.model_zoo.vision.BottleneckV1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottleneckV1</span></code></a>(channels, stride[, downsample, …])</p></td>
<td><p><p>Bottleneck V1 from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BottleneckV2" title="mxnet.gluon.model_zoo.vision.BottleneckV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BottleneckV2</span></code></a>(channels, stride[, downsample, …])</p></td>
<td><p><p>Bottleneck V2 from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.DenseNet" title="mxnet.gluon.model_zoo.vision.DenseNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DenseNet</span></code></a>(num_init_features, growth_rate, …)</p></td>
<td><p><p>Densenet-BC model from the <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.Inception3" title="mxnet.gluon.model_zoo.vision.Inception3"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Inception3</span></code></a>([classes])</p></td>
<td><p><p>Inception v3 model from <a class="reference external" href="http://arxiv.org/abs/1512.00567">“Rethinking the Inception Architecture for Computer Vision”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.MobileNet" title="mxnet.gluon.model_zoo.vision.MobileNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MobileNet</span></code></a>([multiplier, classes])</p></td>
<td><p><p>MobileNet model from the <a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.MobileNetV2" title="mxnet.gluon.model_zoo.vision.MobileNetV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MobileNetV2</span></code></a>([multiplier, classes])</p></td>
<td><p><p>MobileNetV2 model from the <a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.ResNetV1" title="mxnet.gluon.model_zoo.vision.ResNetV1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ResNetV1</span></code></a>(block, layers, channels[, classes, …])</p></td>
<td><p><p>ResNet V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.ResNetV2" title="mxnet.gluon.model_zoo.vision.ResNetV2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ResNetV2</span></code></a>(block, layers, channels[, classes, …])</p></td>
<td><p><p>ResNet V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.SqueezeNet" title="mxnet.gluon.model_zoo.vision.SqueezeNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SqueezeNet</span></code></a>(version[, classes])</p></td>
<td><p><p>SqueezeNet model from the <a class="reference external" href="https://arxiv.org/abs/1602.07360">“SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.VGG" title="mxnet.gluon.model_zoo.vision.VGG"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VGG</span></code></a>(layers, filters[, classes, batch_norm])</p></td>
<td><p><p>VGG model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
</tbody>
</table>
<p><strong>Functions</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.alexnet" title="mxnet.gluon.model_zoo.vision.alexnet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">alexnet</span></code></a>([pretrained, ctx, root])</p></td>
<td><p><p>AlexNet model from the <a class="reference external" href="https://arxiv.org/abs/1404.5997">“One weird trick…”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.densenet121" title="mxnet.gluon.model_zoo.vision.densenet121"><code class="xref py py-obj docutils literal notranslate"><span class="pre">densenet121</span></code></a>(**kwargs)</p></td>
<td><p><p>Densenet-BC 121-layer model from the <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.densenet161" title="mxnet.gluon.model_zoo.vision.densenet161"><code class="xref py py-obj docutils literal notranslate"><span class="pre">densenet161</span></code></a>(**kwargs)</p></td>
<td><p><p>Densenet-BC 161-layer model from the <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.densenet169" title="mxnet.gluon.model_zoo.vision.densenet169"><code class="xref py py-obj docutils literal notranslate"><span class="pre">densenet169</span></code></a>(**kwargs)</p></td>
<td><p><p>Densenet-BC 169-layer model from the <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.densenet201" title="mxnet.gluon.model_zoo.vision.densenet201"><code class="xref py py-obj docutils literal notranslate"><span class="pre">densenet201</span></code></a>(**kwargs)</p></td>
<td><p><p>Densenet-BC 201-layer model from the <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.get_mobilenet" title="mxnet.gluon.model_zoo.vision.get_mobilenet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_mobilenet</span></code></a>(multiplier[, pretrained, ctx, …])</p></td>
<td><p><p>MobileNet model from the <a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.get_mobilenet_v2" title="mxnet.gluon.model_zoo.vision.get_mobilenet_v2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_mobilenet_v2</span></code></a>(multiplier[, pretrained, …])</p></td>
<td><p><p>MobileNetV2 model from the <a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.get_model" title="mxnet.gluon.model_zoo.vision.get_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_model</span></code></a>(name, **kwargs)</p></td>
<td><p>Returns a pre-defined model by name</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.get_resnet" title="mxnet.gluon.model_zoo.vision.get_resnet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_resnet</span></code></a>(version, num_layers[, …])</p></td>
<td><p><p>ResNet V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.get_vgg" title="mxnet.gluon.model_zoo.vision.get_vgg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_vgg</span></code></a>(num_layers[, pretrained, ctx, root])</p></td>
<td><p><p>VGG model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.inception_v3" title="mxnet.gluon.model_zoo.vision.inception_v3"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inception_v3</span></code></a>([pretrained, ctx, root])</p></td>
<td><p><p>Inception v3 model from <a class="reference external" href="http://arxiv.org/abs/1512.00567">“Rethinking the Inception Architecture for Computer Vision”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet0_25" title="mxnet.gluon.model_zoo.vision.mobilenet0_25"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet0_25</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNet model from the <a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 0.25.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet0_5" title="mxnet.gluon.model_zoo.vision.mobilenet0_5"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet0_5</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNet model from the <a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 0.5.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet0_75" title="mxnet.gluon.model_zoo.vision.mobilenet0_75"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet0_75</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNet model from the <a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 0.75.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet1_0" title="mxnet.gluon.model_zoo.vision.mobilenet1_0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet1_0</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNet model from the <a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 1.0.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25" title="mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet_v2_0_25</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNetV2 model from the <a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_0_5" title="mxnet.gluon.model_zoo.vision.mobilenet_v2_0_5"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet_v2_0_5</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNetV2 model from the <a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75" title="mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet_v2_0_75</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNetV2 model from the <a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0" title="mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mobilenet_v2_1_0</span></code></a>(**kwargs)</p></td>
<td><p><p>MobileNetV2 model from the <a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet101_v1" title="mxnet.gluon.model_zoo.vision.resnet101_v1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet101_v1</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-101 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet101_v2" title="mxnet.gluon.model_zoo.vision.resnet101_v2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet101_v2</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-101 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet152_v1" title="mxnet.gluon.model_zoo.vision.resnet152_v1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet152_v1</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-152 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet152_v2" title="mxnet.gluon.model_zoo.vision.resnet152_v2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet152_v2</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-152 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet18_v1" title="mxnet.gluon.model_zoo.vision.resnet18_v1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet18_v1</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-18 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet18_v2" title="mxnet.gluon.model_zoo.vision.resnet18_v2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet18_v2</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-18 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet34_v1" title="mxnet.gluon.model_zoo.vision.resnet34_v1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet34_v1</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-34 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet34_v2" title="mxnet.gluon.model_zoo.vision.resnet34_v2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet34_v2</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-34 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet50_v1" title="mxnet.gluon.model_zoo.vision.resnet50_v1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet50_v1</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-50 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.resnet50_v2" title="mxnet.gluon.model_zoo.vision.resnet50_v2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resnet50_v2</span></code></a>(**kwargs)</p></td>
<td><p><p>ResNet-50 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.squeezenet1_0" title="mxnet.gluon.model_zoo.vision.squeezenet1_0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">squeezenet1_0</span></code></a>(**kwargs)</p></td>
<td><p><p>SqueezeNet 1.0 model from the <a class="reference external" href="https://arxiv.org/abs/1602.07360">“SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.squeezenet1_1" title="mxnet.gluon.model_zoo.vision.squeezenet1_1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">squeezenet1_1</span></code></a>(**kwargs)</p></td>
<td><p><p>SqueezeNet 1.1 model from the <a class="reference external" href="https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1">official SqueezeNet repo</a>.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg11" title="mxnet.gluon.model_zoo.vision.vgg11"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg11</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-11 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg11_bn" title="mxnet.gluon.model_zoo.vision.vgg11_bn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg11_bn</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-11 model with batch normalization from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg13" title="mxnet.gluon.model_zoo.vision.vgg13"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg13</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-13 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg13_bn" title="mxnet.gluon.model_zoo.vision.vgg13_bn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg13_bn</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-13 model with batch normalization from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg16" title="mxnet.gluon.model_zoo.vision.vgg16"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg16</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-16 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg16_bn" title="mxnet.gluon.model_zoo.vision.vgg16_bn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg16_bn</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-16 model with batch normalization from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg19" title="mxnet.gluon.model_zoo.vision.vgg19"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg19</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-19 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.vgg19_bn" title="mxnet.gluon.model_zoo.vision.vgg19_bn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vgg19_bn</span></code></a>(**kwargs)</p></td>
<td><p><p>VGG-19 model with batch normalization from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
</p></td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.AlexNet">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">AlexNet</code><span class="sig-paren">(</span><em class="sig-param">classes=1000</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/alexnet.html#AlexNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.AlexNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.AlexNet.hybrid_forward" title="mxnet.gluon.model_zoo.vision.AlexNet.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>AlexNet model from the <a class="reference external" href="https://arxiv.org/abs/1404.5997">“One weird trick…”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>classes</strong> (<em>int</em><em>, </em><em>default 1000</em>) – Number of classes for the output layer.</p>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.AlexNet.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/alexnet.html#AlexNet.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.AlexNet.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.BasicBlockV1">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">BasicBlockV1</code><span class="sig-paren">(</span><em class="sig-param">channels</em>, <em class="sig-param">stride</em>, <em class="sig-param">downsample=False</em>, <em class="sig-param">in_channels=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#BasicBlockV1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.BasicBlockV1" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BasicBlockV1.hybrid_forward" title="mxnet.gluon.model_zoo.vision.BasicBlockV1.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>BasicBlock V1 from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.
This is used for ResNet V1 for 18, 34 layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>stride</strong> (<em>int</em>) – Stride size.</p></li>
<li><p><strong>downsample</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to downsample the input.</p></li>
<li><p><strong>in_channels</strong> (<em>int</em><em>, </em><em>default 0</em>) – Number of input channels. Default is 0, to infer from the graph.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.BasicBlockV1.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#BasicBlockV1.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.BasicBlockV1.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.BasicBlockV2">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">BasicBlockV2</code><span class="sig-paren">(</span><em class="sig-param">channels</em>, <em class="sig-param">stride</em>, <em class="sig-param">downsample=False</em>, <em class="sig-param">in_channels=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#BasicBlockV2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.BasicBlockV2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BasicBlockV2.hybrid_forward" title="mxnet.gluon.model_zoo.vision.BasicBlockV2.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>BasicBlock V2 from
<a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.
This is used for ResNet V2 for 18, 34 layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>stride</strong> (<em>int</em>) – Stride size.</p></li>
<li><p><strong>downsample</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to downsample the input.</p></li>
<li><p><strong>in_channels</strong> (<em>int</em><em>, </em><em>default 0</em>) – Number of input channels. Default is 0, to infer from the graph.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.BasicBlockV2.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#BasicBlockV2.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.BasicBlockV2.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.BottleneckV1">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">BottleneckV1</code><span class="sig-paren">(</span><em class="sig-param">channels</em>, <em class="sig-param">stride</em>, <em class="sig-param">downsample=False</em>, <em class="sig-param">in_channels=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#BottleneckV1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.BottleneckV1" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BottleneckV1.hybrid_forward" title="mxnet.gluon.model_zoo.vision.BottleneckV1.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>Bottleneck V1 from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.
This is used for ResNet V1 for 50, 101, 152 layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>stride</strong> (<em>int</em>) – Stride size.</p></li>
<li><p><strong>downsample</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to downsample the input.</p></li>
<li><p><strong>in_channels</strong> (<em>int</em><em>, </em><em>default 0</em>) – Number of input channels. Default is 0, to infer from the graph.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.BottleneckV1.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#BottleneckV1.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.BottleneckV1.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.BottleneckV2">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">BottleneckV2</code><span class="sig-paren">(</span><em class="sig-param">channels</em>, <em class="sig-param">stride</em>, <em class="sig-param">downsample=False</em>, <em class="sig-param">in_channels=0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#BottleneckV2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.BottleneckV2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.BottleneckV2.hybrid_forward" title="mxnet.gluon.model_zoo.vision.BottleneckV2.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>Bottleneck V2 from
<a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.
This is used for ResNet V2 for 50, 101, 152 layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> (<em>int</em>) – Number of output channels.</p></li>
<li><p><strong>stride</strong> (<em>int</em>) – Stride size.</p></li>
<li><p><strong>downsample</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to downsample the input.</p></li>
<li><p><strong>in_channels</strong> (<em>int</em><em>, </em><em>default 0</em>) – Number of input channels. Default is 0, to infer from the graph.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.BottleneckV2.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#BottleneckV2.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.BottleneckV2.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.DenseNet">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">DenseNet</code><span class="sig-paren">(</span><em class="sig-param">num_init_features</em>, <em class="sig-param">growth_rate</em>, <em class="sig-param">block_config</em>, <em class="sig-param">bn_size=4</em>, <em class="sig-param">dropout=0</em>, <em class="sig-param">classes=1000</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/densenet.html#DenseNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.DenseNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.DenseNet.hybrid_forward" title="mxnet.gluon.model_zoo.vision.DenseNet.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>Densenet-BC model from the
<a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_init_features</strong> (<em>int</em>) – Number of filters to learn in the first convolution layer.</p></li>
<li><p><strong>growth_rate</strong> (<em>int</em>) – Number of filters to add each layer (<cite>k</cite> in the paper).</p></li>
<li><p><strong>block_config</strong> (<em>list of int</em>) – List of integers for numbers of layers in each pooling block.</p></li>
<li><p><strong>bn_size</strong> (<em>int</em><em>, </em><em>default 4</em>) – Multiplicative factor for number of bottle neck layers.
(i.e. bn_size * k features in the bottleneck layer)</p></li>
<li><p><strong>dropout</strong> (<em>float</em><em>, </em><em>default 0</em>) – Rate of dropout after each dense layer.</p></li>
<li><p><strong>classes</strong> (<em>int</em><em>, </em><em>default 1000</em>) – Number of classification classes.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.DenseNet.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/densenet.html#DenseNet.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.DenseNet.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.Inception3">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">Inception3</code><span class="sig-paren">(</span><em class="sig-param">classes=1000</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/inception.html#Inception3"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.Inception3" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.Inception3.hybrid_forward" title="mxnet.gluon.model_zoo.vision.Inception3.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>Inception v3 model from
<a class="reference external" href="http://arxiv.org/abs/1512.00567">“Rethinking the Inception Architecture for Computer Vision”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>classes</strong> (<em>int</em><em>, </em><em>default 1000</em>) – Number of classification classes.</p>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.Inception3.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/inception.html#Inception3.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.Inception3.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.MobileNet">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">MobileNet</code><span class="sig-paren">(</span><em class="sig-param">multiplier=1.0</em>, <em class="sig-param">classes=1000</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#MobileNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.MobileNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.MobileNet.hybrid_forward" title="mxnet.gluon.model_zoo.vision.MobileNet.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>MobileNet model from the
<a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>multiplier</strong> (<em>float</em><em>, </em><em>default 1.0</em>) – The width multiplier for controling the model size. Only multipliers that are no
less than 0.25 are supported. The actual number of channels is equal to the original
channel size multiplied by this multiplier.</p></li>
<li><p><strong>classes</strong> (<em>int</em><em>, </em><em>default 1000</em>) – Number of classes for the output layer.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.MobileNet.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#MobileNet.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.MobileNet.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.MobileNetV2">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">MobileNetV2</code><span class="sig-paren">(</span><em class="sig-param">multiplier=1.0</em>, <em class="sig-param">classes=1000</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#MobileNetV2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.MobileNetV2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.MobileNetV2.hybrid_forward" title="mxnet.gluon.model_zoo.vision.MobileNetV2.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>MobileNetV2 model from the
<a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks:
Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>multiplier</strong> (<em>float</em><em>, </em><em>default 1.0</em>) – The width multiplier for controling the model size. The actual number of channels
is equal to the original channel size multiplied by this multiplier.</p></li>
<li><p><strong>classes</strong> (<em>int</em><em>, </em><em>default 1000</em>) – Number of classes for the output layer.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.MobileNetV2.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#MobileNetV2.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.MobileNetV2.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.ResNetV1">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">ResNetV1</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">layers</em>, <em class="sig-param">channels</em>, <em class="sig-param">classes=1000</em>, <em class="sig-param">thumbnail=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#ResNetV1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.ResNetV1" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.ResNetV1.hybrid_forward" title="mxnet.gluon.model_zoo.vision.ResNetV1.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>ResNet V1 model from
<a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block</strong> (<a class="reference internal" href="../hybrid_block.html#mxnet.gluon.HybridBlock" title="mxnet.gluon.HybridBlock"><em>gluon.HybridBlock</em></a>) – Class for the residual block. Options are BasicBlockV1, BottleneckV1.</p></li>
<li><p><strong>layers</strong> (<em>list of int</em>) – Numbers of layers in each block</p></li>
<li><p><strong>channels</strong> (<em>list of int</em>) – Numbers of channels in each block. Length should be one larger than layers list.</p></li>
<li><p><strong>classes</strong> (<em>int</em><em>, </em><em>default 1000</em>) – Number of classification classes.</p></li>
<li><p><strong>thumbnail</strong> (<em>bool</em><em>, </em><em>default False</em>) – Enable thumbnail.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.ResNetV1.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#ResNetV1.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.ResNetV1.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.ResNetV2">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">ResNetV2</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">layers</em>, <em class="sig-param">channels</em>, <em class="sig-param">classes=1000</em>, <em class="sig-param">thumbnail=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#ResNetV2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.ResNetV2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.ResNetV2.hybrid_forward" title="mxnet.gluon.model_zoo.vision.ResNetV2.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>ResNet V2 model from
<a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block</strong> (<a class="reference internal" href="../hybrid_block.html#mxnet.gluon.HybridBlock" title="mxnet.gluon.HybridBlock"><em>gluon.HybridBlock</em></a>) – Class for the residual block. Options are BasicBlockV1, BottleneckV1.</p></li>
<li><p><strong>layers</strong> (<em>list of int</em>) – Numbers of layers in each block</p></li>
<li><p><strong>channels</strong> (<em>list of int</em>) – Numbers of channels in each block. Length should be one larger than layers list.</p></li>
<li><p><strong>classes</strong> (<em>int</em><em>, </em><em>default 1000</em>) – Number of classification classes.</p></li>
<li><p><strong>thumbnail</strong> (<em>bool</em><em>, </em><em>default False</em>) – Enable thumbnail.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.ResNetV2.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#ResNetV2.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.ResNetV2.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.SqueezeNet">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">SqueezeNet</code><span class="sig-paren">(</span><em class="sig-param">version</em>, <em class="sig-param">classes=1000</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/squeezenet.html#SqueezeNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.SqueezeNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.SqueezeNet.hybrid_forward" title="mxnet.gluon.model_zoo.vision.SqueezeNet.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>SqueezeNet model from the <a class="reference external" href="https://arxiv.org/abs/1602.07360">“SqueezeNet: AlexNet-level accuracy with 50x fewer parameters
and &lt;0.5MB model size”</a> paper.
SqueezeNet 1.1 model from the <a class="reference external" href="https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1">official SqueezeNet repo</a>.
SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters
than SqueezeNet 1.0, without sacrificing accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>version</strong> (<em>str</em>) – Version of squeezenet. Options are ‘1.0’, ‘1.1’.</p></li>
<li><p><strong>classes</strong> (<em>int</em><em>, </em><em>default 1000</em>) – Number of classification classes.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.SqueezeNet.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/squeezenet.html#SqueezeNet.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.SqueezeNet.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.model_zoo.vision.VGG">
<em class="property">class </em><code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">VGG</code><span class="sig-paren">(</span><em class="sig-param">layers</em>, <em class="sig-param">filters</em>, <em class="sig-param">classes=1000</em>, <em class="sig-param">batch_norm=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/vgg.html#VGG"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.VGG" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.model_zoo.vision.VGG.hybrid_forward" title="mxnet.gluon.model_zoo.vision.VGG.hybrid_forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybrid_forward</span></code></a>(F, x)</p></td>
<td><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p></td>
</tr>
</tbody>
</table>
<p>VGG model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layers</strong> (<em>list of int</em>) – Numbers of layers in each feature block.</p></li>
<li><p><strong>filters</strong> (<em>list of int</em>) – Numbers of filters in each feature block. List length should match the layers.</p></li>
<li><p><strong>classes</strong> (<em>int</em><em>, </em><em>default 1000</em>) – Number of classification classes.</p></li>
<li><p><strong>batch_norm</strong> (<em>bool</em><em>, </em><em>default False</em>) – Use batch normalization.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.model_zoo.vision.VGG.hybrid_forward">
<code class="sig-name descname">hybrid_forward</code><span class="sig-paren">(</span><em class="sig-param">F</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/vgg.html#VGG.hybrid_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.VGG.hybrid_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Overrides to construct symbolic graph for this <cite>Block</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em> or </em><a class="reference internal" href="../../ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) – The first input tensor.</p></li>
<li><p><strong>*args</strong> (<em>list of Symbol</em><em> or </em><em>list of NDArray</em>) – Additional input tensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.alexnet">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">alexnet</code><span class="sig-paren">(</span><em class="sig-param">pretrained=False</em>, <em class="sig-param">ctx=cpu(0)</em>, <em class="sig-param">root='/home/jenkins_slave/.mxnet/models'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/alexnet.html#alexnet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.alexnet" title="Permalink to this definition">¶</a></dt>
<dd><p>AlexNet model from the <a class="reference external" href="https://arxiv.org/abs/1404.5997">“One weird trick…”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default $MXNET_HOME/models</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.densenet121">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">densenet121</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/densenet.html#densenet121"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.densenet121" title="Permalink to this definition">¶</a></dt>
<dd><p>Densenet-BC 121-layer model from the
<a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.densenet161">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">densenet161</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/densenet.html#densenet161"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.densenet161" title="Permalink to this definition">¶</a></dt>
<dd><p>Densenet-BC 161-layer model from the
<a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.densenet169">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">densenet169</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/densenet.html#densenet169"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.densenet169" title="Permalink to this definition">¶</a></dt>
<dd><p>Densenet-BC 169-layer model from the
<a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.densenet201">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">densenet201</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/densenet.html#densenet201"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.densenet201" title="Permalink to this definition">¶</a></dt>
<dd><p>Densenet-BC 201-layer model from the
<a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">“Densely Connected Convolutional Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.get_mobilenet">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">get_mobilenet</code><span class="sig-paren">(</span><em class="sig-param">multiplier</em>, <em class="sig-param">pretrained=False</em>, <em class="sig-param">ctx=cpu(0)</em>, <em class="sig-param">root='/home/jenkins_slave/.mxnet/models'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#get_mobilenet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.get_mobilenet" title="Permalink to this definition">¶</a></dt>
<dd><p>MobileNet model from the
<a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>multiplier</strong> (<em>float</em>) – The width multiplier for controling the model size. Only multipliers that are no
less than 0.25 are supported. The actual number of channels is equal to the original
channel size multiplied by this multiplier.</p></li>
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default $MXNET_HOME/models</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.get_mobilenet_v2">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">get_mobilenet_v2</code><span class="sig-paren">(</span><em class="sig-param">multiplier</em>, <em class="sig-param">pretrained=False</em>, <em class="sig-param">ctx=cpu(0)</em>, <em class="sig-param">root='/home/jenkins_slave/.mxnet/models'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#get_mobilenet_v2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.get_mobilenet_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>MobileNetV2 model from the
<a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks:
Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>multiplier</strong> (<em>float</em>) – The width multiplier for controling the model size. Only multipliers that are no
less than 0.25 are supported. The actual number of channels is equal to the original
channel size multiplied by this multiplier.</p></li>
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default $MXNET_HOME/models</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.get_model">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">get_model</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision.html#get_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.get_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a pre-defined model by name</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – Name of the model.</p></li>
<li><p><strong>pretrained</strong> (<em>bool</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>classes</strong> (<em>int</em>) – Number of classes for the output layer.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../hybrid_block.html#mxnet.gluon.HybridBlock" title="mxnet.gluon.HybridBlock">gluon.HybridBlock</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.get_resnet">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">get_resnet</code><span class="sig-paren">(</span><em class="sig-param">version</em>, <em class="sig-param">num_layers</em>, <em class="sig-param">pretrained=False</em>, <em class="sig-param">ctx=cpu(0)</em>, <em class="sig-param">root='/home/jenkins_slave/.mxnet/models'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#get_resnet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.get_resnet" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.
ResNet V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>version</strong> (<em>int</em>) – Version of ResNet. Options are 1, 2.</p></li>
<li><p><strong>num_layers</strong> (<em>int</em>) – Numbers of layers. Options are 18, 34, 50, 101, 152.</p></li>
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default $MXNET_HOME/models</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.get_vgg">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">get_vgg</code><span class="sig-paren">(</span><em class="sig-param">num_layers</em>, <em class="sig-param">pretrained=False</em>, <em class="sig-param">ctx=cpu(0)</em>, <em class="sig-param">root='/home/jenkins_slave/.mxnet/models'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/vgg.html#get_vgg"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.get_vgg" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_layers</strong> (<em>int</em>) – Number of layers for the variant of densenet. Options are 11, 13, 16, 19.</p></li>
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default $MXNET_HOME/models</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.inception_v3">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">inception_v3</code><span class="sig-paren">(</span><em class="sig-param">pretrained=False</em>, <em class="sig-param">ctx=cpu(0)</em>, <em class="sig-param">root='/home/jenkins_slave/.mxnet/models'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/inception.html#inception_v3"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.inception_v3" title="Permalink to this definition">¶</a></dt>
<dd><p>Inception v3 model from
<a class="reference external" href="http://arxiv.org/abs/1512.00567">“Rethinking the Inception Architecture for Computer Vision”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default $MXNET_HOME/models</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.mobilenet0_25">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">mobilenet0_25</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#mobilenet0_25"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.mobilenet0_25" title="Permalink to this definition">¶</a></dt>
<dd><p>MobileNet model from the
<a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 0.25.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.mobilenet0_5">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">mobilenet0_5</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#mobilenet0_5"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.mobilenet0_5" title="Permalink to this definition">¶</a></dt>
<dd><p>MobileNet model from the
<a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 0.5.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.mobilenet0_75">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">mobilenet0_75</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#mobilenet0_75"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.mobilenet0_75" title="Permalink to this definition">¶</a></dt>
<dd><p>MobileNet model from the
<a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 0.75.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.mobilenet1_0">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">mobilenet1_0</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#mobilenet1_0"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.mobilenet1_0" title="Permalink to this definition">¶</a></dt>
<dd><p>MobileNet model from the
<a class="reference external" href="https://arxiv.org/abs/1704.04861">“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”</a> paper, with width multiplier 1.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">mobilenet_v2_0_25</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#mobilenet_v2_0_25"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25" title="Permalink to this definition">¶</a></dt>
<dd><p>MobileNetV2 model from the
<a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks:
Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.mobilenet_v2_0_5">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">mobilenet_v2_0_5</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#mobilenet_v2_0_5"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_0_5" title="Permalink to this definition">¶</a></dt>
<dd><p>MobileNetV2 model from the
<a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks:
Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">mobilenet_v2_0_75</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#mobilenet_v2_0_75"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75" title="Permalink to this definition">¶</a></dt>
<dd><p>MobileNetV2 model from the
<a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks:
Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">mobilenet_v2_1_0</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/mobilenet.html#mobilenet_v2_1_0"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0" title="Permalink to this definition">¶</a></dt>
<dd><p>MobileNetV2 model from the
<a class="reference external" href="https://arxiv.org/abs/1801.04381">“Inverted Residuals and Linear Bottlenecks:
Mobile Networks for Classification, Detection and Segmentation”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.resnet101_v1">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">resnet101_v1</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#resnet101_v1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.resnet101_v1" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-101 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.resnet101_v2">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">resnet101_v2</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#resnet101_v2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.resnet101_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-101 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.resnet152_v1">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">resnet152_v1</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#resnet152_v1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.resnet152_v1" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-152 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.resnet152_v2">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">resnet152_v2</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#resnet152_v2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.resnet152_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-152 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.resnet18_v1">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">resnet18_v1</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#resnet18_v1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.resnet18_v1" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-18 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.resnet18_v2">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">resnet18_v2</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#resnet18_v2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.resnet18_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-18 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.resnet34_v1">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">resnet34_v1</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#resnet34_v1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.resnet34_v1" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-34 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.resnet34_v2">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">resnet34_v2</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#resnet34_v2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.resnet34_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-34 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.resnet50_v1">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">resnet50_v1</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#resnet50_v1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.resnet50_v1" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-50 V1 model from <a class="reference external" href="http://arxiv.org/abs/1512.03385">“Deep Residual Learning for Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.resnet50_v2">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">resnet50_v2</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/resnet.html#resnet50_v2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.resnet50_v2" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-50 V2 model from <a class="reference external" href="https://arxiv.org/abs/1603.05027">“Identity Mappings in Deep Residual Networks”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.squeezenet1_0">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">squeezenet1_0</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/squeezenet.html#squeezenet1_0"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.squeezenet1_0" title="Permalink to this definition">¶</a></dt>
<dd><p>SqueezeNet 1.0 model from the <a class="reference external" href="https://arxiv.org/abs/1602.07360">“SqueezeNet: AlexNet-level accuracy with 50x fewer parameters
and &lt;0.5MB model size”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.squeezenet1_1">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">squeezenet1_1</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/squeezenet.html#squeezenet1_1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.squeezenet1_1" title="Permalink to this definition">¶</a></dt>
<dd><p>SqueezeNet 1.1 model from the <a class="reference external" href="https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1">official SqueezeNet repo</a>.
SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters
than SqueezeNet 1.0, without sacrificing accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.vgg11">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">vgg11</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/vgg.html#vgg11"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.vgg11" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG-11 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.vgg11_bn">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">vgg11_bn</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/vgg.html#vgg11_bn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.vgg11_bn" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG-11 model with batch normalization from the
<a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.vgg13">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">vgg13</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/vgg.html#vgg13"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.vgg13" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG-13 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.vgg13_bn">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">vgg13_bn</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/vgg.html#vgg13_bn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.vgg13_bn" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG-13 model with batch normalization from the
<a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.vgg16">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">vgg16</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/vgg.html#vgg16"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.vgg16" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG-16 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.vgg16_bn">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">vgg16_bn</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/vgg.html#vgg16_bn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.vgg16_bn" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG-16 model with batch normalization from the
<a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.vgg19">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">vgg19</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/vgg.html#vgg19"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.vgg19" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG-19 model from the <a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="mxnet.gluon.model_zoo.vision.vgg19_bn">
<code class="sig-prename descclassname">mxnet.gluon.model_zoo.vision.</code><code class="sig-name descname">vgg19_bn</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/model_zoo/vision/vgg.html#vgg19_bn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.model_zoo.vision.vgg19_bn" title="Permalink to this definition">¶</a></dt>
<dd><p>VGG-19 model with batch normalization from the
<a class="reference external" href="https://arxiv.org/abs/1409.1556">“Very Deep Convolutional Networks for Large-Scale Image Recognition”</a> paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained</strong> (<em>bool</em><em>, </em><em>default False</em>) – Whether to load the pretrained weights for model.</p></li>
<li><p><strong>ctx</strong> (<a class="reference internal" href="../../mxnet/context/index.html#mxnet.context.Context" title="mxnet.context.Context"><em>Context</em></a><em>, </em><em>default CPU</em>) – The context in which to load the pretrained weights.</p></li>
<li><p><strong>root</strong> (<em>str</em><em>, </em><em>default '$MXNET_HOME/models'</em>) – Location for keeping the model parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
</div>


        <hr class="feedback-hr-top" />
<div class="feedback-container">
    <div class="feedback-question">Did this page help you?</div>
    <div class="feedback-answer-container">
        <div class="feedback-answer yes-link" data-response="yes">Yes</div>
        <div class="feedback-answer no-link" data-response="no">No</div>
    </div>
    <div class="feedback-thank-you">Thanks for your feedback!</div>
</div>
<hr class="feedback-hr-bottom" />
        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">gluon.model_zoo.vision</a><ul>
<li><a class="reference internal" href="#resnet">ResNet</a></li>
<li><a class="reference internal" href="#id17">VGG</a></li>
<li><a class="reference internal" href="#id27">Alexnet</a></li>
<li><a class="reference internal" href="#id29">DenseNet</a></li>
<li><a class="reference internal" href="#id34">SqueezeNet</a></li>
<li><a class="reference internal" href="#inception">Inception</a></li>
<li><a class="reference internal" href="#id38">MobileNet</a></li>
<li><a class="reference internal" href="#module-mxnet.gluon.model_zoo.vision">API Reference</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>                    

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="../loss/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>gluon.loss</div>
         </div>
     </a>
     <a id="button-next" href="../nn/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>gluon.nn</div>
        </div>
     </a>
  </div>
            <footer class="site-footer h-card">
    <div class="wrapper">
        <div class="row">
            <div class="col-4">
                <h4 class="footer-category-title">Resources</h4>
                <ul class="contact-list">
                    <li><a class="u-email" href="mailto:dev@mxnet.apache.org">Dev list</a></li>
                    <li><a class="u-email" href="mailto:user@mxnet.apache.org">User mailing list</a></li>
                    <li><a href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home">Developer Wiki</a></li>
                    <li><a href="https://issues.apache.org/jira/projects/MXNET/issues">Jira Tracker</a></li>
                    <li><a href="https://github.com/apache/incubator-mxnet/labels/Roadmap">Github Roadmap</a></li>
                    <li><a href="https://medium.com/apache-mxnet">Blog</a></li>
                    <li><a href="https://discuss.mxnet.io">Forum</a></li>
                    <li><a href="/community/contribute">Contribute</a></li>

                </ul>
            </div>

            <div class="col-4"><ul class="social-media-list"><li><a href="https://github.com/apache/incubator-mxnet"><svg class="svg-icon"><use xlink:href="../../../_static/minima-social-icons.svg#github"></use></svg> <span class="username">apache/incubator-mxnet</span></a></li><li><a href="https://www.twitter.com/apachemxnet"><svg class="svg-icon"><use xlink:href="../../../_static/minima-social-icons.svg#twitter"></use></svg> <span class="username">apachemxnet</span></a></li><li><a href="https://youtube.com/apachemxnet"><svg class="svg-icon"><use xlink:href="../../../_static/minima-social-icons.svg#youtube"></use></svg> <span class="username">apachemxnet</span></a></li></ul>
</div>

            <div class="col-4 footer-text">
                <p>A flexible and efficient library for deep learning.</p>
            </div>
        </div>
    </div>
</footer>

<footer class="site-footer2">
    <div class="wrapper">
        <div class="row">
            <div class="col-3">
                <img src="../../../_static/apache_incubator_logo.png" class="footer-logo col-2">
            </div>
            <div class="footer-bottom-warning col-9">
                <p>Apache MXNet is an effort undergoing incubation at <a href="http://www.apache.org/">The Apache Software Foundation</a> (ASF), <span style="font-weight:bold">sponsored by the <i>Apache Incubator</i></span>. Incubation is required
                    of all newly accepted projects until a further review indicates that the infrastructure,
                    communications, and decision making process have stabilized in a manner consistent with other
                    successful ASF projects. While incubation status is not necessarily a reflection of the completeness
                    or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
                </p><p>"Copyright © 2017-2018, The Apache Software Foundation Apache MXNet, MXNet, Apache, the Apache
                    feather, and the Apache MXNet project logo are either registered trademarks or trademarks of the
                    Apache Software Foundation."</p>
            </div>
        </div>
    </div>
</footer>
        
  </body>
</html>