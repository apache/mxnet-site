<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <style>
    .dropdown {
        position: relative;
        display: inline-block;
    }

    .dropdown-content {
        display: none;
        position: absolute;
        background-color: #f9f9f9;
        min-width: 160px;
        box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
        padding: 12px 16px;
        z-index: 1;
        text-align: left;
    }

    .dropdown:hover .dropdown-content {
        display: block;
    }

    .dropdown-option:hover {
        color: #FF4500;
    }

    .dropdown-option-active {
        color: #FF4500;
        font-weight: lighter;
    }

    .dropdown-option {
        color: #000000;
        font-weight: lighter;
    }

    .dropdown-header {
        color: #FFFFFF;
        display: inline-flex;
    }

    .dropdown-caret {
        width: 18px;
        height: 54px;
    }

    .dropdown-caret-path {
        fill: #FFFFFF;
    }
    </style>
    
    <title>gluon.rnn &#8212; Apache MXNet  documentation</title>

    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mxnet.css" />
    <link rel="stylesheet" href="../../../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/feedback.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/language_data.js"></script>
    <script src="../../../_static/matomo_analytics.js"></script>
    <script src="../../../_static/autodoc.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <script src="../../../_static/sphinx_materialdesign_theme.js"></script>
    <link rel="shortcut icon" href="../../../_static/mxnet-icon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="gluon.utils" href="../utils/index.html" />
    <link rel="prev" title="gluon.nn" href="../nn/index.html" /> 
  </head>
<body><header class="site-header" role="banner">
  <div class="wrapper">
      <a class="site-title" rel="author" href="/"><img
            src="../../../_static/mxnet_logo.png" class="site-header-logo"></a>
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger"/>
      <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
      </label>

      <div class="trigger">
        <a class="page-link" href="/get_started">Get Started</a>
        <a class="page-link" href="/features">Features</a>
        <a class="page-link" href="/ecosystem">Ecosystem</a>
        <a class="page-link page-current" href="/api">Docs & Tutorials</a>
        <a class="page-link" href="/trusted_by">Trusted By</a>
        <a class="page-link" href="https://github.com/apache/incubator-mxnet">GitHub</a>
        <div class="dropdown" style="min-width:100px">
          <span class="dropdown-header">Apache
            <svg class="dropdown-caret" viewBox="0 0 32 32" class="icon icon-caret-bottom" aria-hidden="true"><path class="dropdown-caret-path" d="M24 11.305l-7.997 11.39L8 11.305z"></path></svg>
          </span>
          <div class="dropdown-content" style="min-width:250px">
            <a href="https://www.apache.org/foundation/">Apache Software Foundation</a>
            <a href="https://incubator.apache.org/">Apache Incubator</a>
            <a href="https://www.apache.org/licenses/">License</a>
            <a href="/versions/1.9.1/api/faq/security.html">Security</a>
            <a href="https://privacy.apache.org/policies/privacy-policy-public.html">Privacy</a>
            <a href="https://www.apache.org/events/current-event">Events</a>
            <a href="https://www.apache.org/foundation/sponsorship.html">Sponsorship</a>
            <a href="https://www.apache.org/foundation/thanks.html">Thanks</a>
          </div>
        </div>
        <div class="dropdown">
          <span class="dropdown-header">master
            <svg class="dropdown-caret" viewBox="0 0 32 32" class="icon icon-caret-bottom" aria-hidden="true"><path class="dropdown-caret-path" d="M24 11.305l-7.997 11.39L8 11.305z"></path></svg>
          </span>
          <div class="dropdown-content">
            <a class="dropdown-option-active" href="/versions/master/">master</a><br>
            <a class="dropdown-option" href="/versions/1.9.1/">1.9.1</a><br>
            <a class="dropdown-option" href="/versions/1.8.0/">1.8.0</a><br>
            <a class="dropdown-option" href="/versions/1.7.0/">1.7.0</a><br>
            <a class="dropdown-option" href="/versions/1.6.0/">1.6.0</a><br>
            <a class="dropdown-option" href="/versions/1.5.0/">1.5.0</a><br>
            <a class="dropdown-option" href="/versions/1.4.1/">1.4.1</a><br>
            <a class="dropdown-option" href="/versions/1.3.1/">1.3.1</a><br>
            <a class="dropdown-option" href="/versions/1.2.1/">1.2.1</a><br>
            <a class="dropdown-option" href="/versions/1.1.0/">1.1.0</a><br>
            <a class="dropdown-option" href="/versions/1.0.0/">1.0.0</a><br>
            <a class="dropdown-option" href="/versions/0.12.1/">0.12.1</a><br>
            <a class="dropdown-option" href="/versions/0.11.0/">0.11.0</a>
          </div>
        </div>
      </div>
    </nav>
  </div>
</header>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="../../index.html">Python API</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link" href="../index.html">mxnet.gluon</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active">gluon.rnn</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../../../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-github"
    href="https://github.com/apache/mxnet/edit/master/docs/python_docs/python/api/gluon/rnn/index.rst" class="mdl-button mdl-js-button mdl-button--icon">
<i class="material-icons">edit</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-github">
Edit on Github
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
      </nav>
    </div>
</header><header class="mdl-layout__drawer">      
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/index.html">Python Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/getting-started/index.html">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/index.html">Crash Course</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/0-introduction.html">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/1-nparray.html">Step 1: Manipulate data with NP on MXNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/2-create-nn.html">Step 2: Create a neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/3-autograd.html">Step 3: Automatic differentiation with autograd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/4-components.html">Step 4: Necessary components that are not in the network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-datasets.html">Step 5: <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-datasets.html#Using-own-data-with-included-Datasets">Using own data with included <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-datasets.html#Using-your-own-data-with-custom-Datasets">Using your own data with custom <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-datasets.html#New-in-MXNet-2.0:-faster-C++-backend-dataloaders">New in MXNet 2.0: faster C++ backend dataloaders</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/6-train-nn.html">Step 6: Train a Neural Network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/7-use-gpus.html">Step 7: Load and Run a NN using GPU</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/index.html">Moving to MXNet from Other Frameworks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/pytorch.html">PyTorch vs Apache MXNet</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/gluon_from_experiment_to_deployment.html">Gluon: from experiment to deployment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/gluon_migration_guide.html">Gluon2.0: Migration Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/logistic_regression_explained.html">Logistic regression explained</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html">MNIST</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/packages/index.html">Packages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/autograd/index.html">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/gluon/index.html">Gluon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/index.html">Blocks</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/custom-layer.html">Custom Layers</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/hybridize.html">Hybridize</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/init.html">Initialization</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/naming.html">Parameter and Block Naming</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/nn.html">Layers and Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/parameters.html">Parameter Management</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/activations/activations.html">Activation Blocks</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/data/index.html">Data Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/data_augmentation.html">Image Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html">Gluon <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Using-own-data-with-included-Datasets">Using own data with included <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Using-own-data-with-custom-Datasets">Using own data with custom <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Appendix:-Upgrading-from-Module-DataIter-to-Gluon-DataLoader">Appendix: Upgrading from Module <code class="docutils literal notranslate"><span class="pre">DataIter</span></code> to Gluon <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/image/index.html">Image Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/info_gan.html">Image similarity search with InfoGAN</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/mnist.html">Handwritten Digit Recognition</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/index.html">Losses</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/custom-loss.html">Custom Loss Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/kl_divergence.html">Kullback-Leibler (KL) Divergence</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/loss.html">Loss functions</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/text/index.html">Text Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/text/gnmt.html">Google Neural Machine Translation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/text/transformer.html">Machine Translation with Transformer</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/training/index.html">Training</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/fit_api_tutorial.html">MXNet Gluon Fit API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/trainer.html">Trainer</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/index.html">Learning Rates</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_finder.html">Learning Rate Finder</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_schedules.html">Learning Rate Schedules</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_schedules_advanced.html">Advanced Learning Rate Schedules</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/normalization/index.html">Normalization Blocks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/kvstore/index.html">KVStore</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/kvstore/kvstore.html">Distributed Key-Value Store</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/legacy/index.html">Legacy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/index.html">NDArray</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/01-ndarray-intro.html">An Intro: Manipulate Data the MXNet Way with NDArray</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/02-ndarray-operations.html">NDArray Operations</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/03-ndarray-contexts.html">NDArray Contexts</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/gotchas_numpy_in_mxnet.html">Gotchas using NumPy in Apache MXNet</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/sparse/index.html">Tutorials</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/sparse/csr.html">CSRNDArray - NDArray in Compressed Sparse Row Storage Format</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/sparse/row_sparse.html">RowSparseNDArray - NDArray for Sparse Gradient Updates</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/np/index.html">What is NP on MXNet</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/np/cheat-sheet.html">The NP on MXNet cheat sheet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/np/np-vs-numpy.html">Differences between NP on MXNet and NumPy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/onnx/index.html">ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/onnx/fine_tuning_gluon.html">Fine-tuning an ONNX model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/onnx/inference_on_onnx_model.html">Running inference on MXNet/Gluon from an ONNX model</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/deploy/export/onnx.html">Export ONNX Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/optimizer/index.html">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/viz/index.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/visualize_graph">Visualize networks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/performance/index.html">Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/compression/index.html">Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/compression/int8.html">Deploy with int-8</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/float16">Float16</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/gradient_compression">Gradient Compression</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/int8_inference.html">GluonCV with Quantized Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/backend/index.html">Accelerated Backend Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/dnnl/index.html">oneDNN</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/dnnl/dnnl_readme.html">Install MXNet with oneDNN</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/dnnl/dnnl_quantization.html">oneDNN Quantization</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/dnnl/dnnl_quantization_inc.html">Improving accuracy with IntelÂ® Neural Compressor</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/tvm.html">Use TVM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/profiler.html">Profiling MXNet Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/amp.html">Using AMP: Automatic Mixed Precision</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/deploy/index.html">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/export/index.html">Export</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/export/onnx.html">Exporting to ONNX format</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/export_network.html">Export Gluon CV Models</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Save / Load Parameters</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/inference/index.html">Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/cpp.html">Deploy into C++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/image_classification_jetson.html">Image Classication using pretrained ResNet-50 model on Jetson module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/index.html">Run on AWS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_ec2.html">Run on an EC2 Instance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_sagemaker.html">Run on Amazon SageMaker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/cloud.html">MXNet on the Cloud</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/extend/index.html">Extend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/extend/customop.html">Custom Numpy Operators</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/new_op">New Operator Creation</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/add_op_in_backend">New Operator in MXNet Backend</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/using_rtc">Using RTC for CUDA kernels</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../np/index.html">mxnet.np</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../np/arrays.html">Array objects</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../np/arrays.ndarray.html">The N-dimensional array (<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../np/arrays.indexing.html">Indexing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../np/routines.html">Routines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.array-creation.html">Array creation routines</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.eye.html">mxnet.np.eye</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.empty.html">mxnet.np.empty</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.full.html">mxnet.np.full</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.identity.html">mxnet.np.identity</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ones.html">mxnet.np.ones</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ones_like.html">mxnet.np.ones_like</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.zeros.html">mxnet.np.zeros</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.zeros_like.html">mxnet.np.zeros_like</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.array.html">mxnet.np.array</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.copy.html">mxnet.np.copy</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arange.html">mxnet.np.arange</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linspace.html">mxnet.np.linspace</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.logspace.html">mxnet.np.logspace</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.meshgrid.html">mxnet.np.meshgrid</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.tril.html">mxnet.np.tril</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.array-manipulation.html">Array manipulation routines</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.reshape.html">mxnet.np.reshape</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ravel.html">mxnet.np.ravel</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ndarray.flatten.html">mxnet.np.ndarray.flatten</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.swapaxes.html">mxnet.np.swapaxes</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ndarray.T.html">mxnet.np.ndarray.T</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.transpose.html">mxnet.np.transpose</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.moveaxis.html">mxnet.np.moveaxis</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.rollaxis.html">mxnet.np.rollaxis</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.expand_dims.html">mxnet.np.expand_dims</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.squeeze.html">mxnet.np.squeeze</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.broadcast_to.html">mxnet.np.broadcast_to</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.broadcast_arrays.html">mxnet.np.broadcast_arrays</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.atleast_1d.html">mxnet.np.atleast_1d</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.atleast_2d.html">mxnet.np.atleast_2d</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.atleast_3d.html">mxnet.np.atleast_3d</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.concatenate.html">mxnet.np.concatenate</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.stack.html">mxnet.np.stack</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.dstack.html">mxnet.np.dstack</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.vstack.html">mxnet.np.vstack</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.column_stack.html">mxnet.np.column_stack</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.hstack.html">mxnet.np.hstack</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.split.html">mxnet.np.split</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.hsplit.html">mxnet.np.hsplit</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.vsplit.html">mxnet.np.vsplit</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.array_split.html">mxnet.np.array_split</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.dsplit.html">mxnet.np.dsplit</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.tile.html">mxnet.np.tile</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.repeat.html">mxnet.np.repeat</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.unique.html">mxnet.np.unique</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.delete.html">mxnet.np.delete</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.insert.html">mxnet.np.insert</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.append.html">mxnet.np.append</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.resize.html">mxnet.np.resize</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.trim_zeros.html">mxnet.np.trim_zeros</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.reshape.html">mxnet.np.reshape</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.flip.html">mxnet.np.flip</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.roll.html">mxnet.np.roll</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.rot90.html">mxnet.np.rot90</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fliplr.html">mxnet.np.fliplr</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.flipud.html">mxnet.np.flipud</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.io.html">Input and output</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.genfromtxt.html">mxnet.np.genfromtxt</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ndarray.tolist.html">mxnet.np.ndarray.tolist</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.set_printoptions.html">mxnet.np.set_printoptions</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.linalg.html">Linear algebra (<code class="xref py py-mod docutils literal notranslate"><span class="pre">numpy.linalg</span></code>)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.dot.html">mxnet.np.dot</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.vdot.html">mxnet.np.vdot</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.inner.html">mxnet.np.inner</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.outer.html">mxnet.np.outer</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.tensordot.html">mxnet.np.tensordot</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.einsum.html">mxnet.np.einsum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.multi_dot.html">mxnet.np.linalg.multi_dot</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.matmul.html">mxnet.np.matmul</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.matrix_power.html">mxnet.np.linalg.matrix_power</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.kron.html">mxnet.np.kron</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.svd.html">mxnet.np.linalg.svd</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.cholesky.html">mxnet.np.linalg.cholesky</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.qr.html">mxnet.np.linalg.qr</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.eig.html">mxnet.np.linalg.eig</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.eigh.html">mxnet.np.linalg.eigh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.eigvals.html">mxnet.np.linalg.eigvals</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.eigvalsh.html">mxnet.np.linalg.eigvalsh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.norm.html">mxnet.np.linalg.norm</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.trace.html">mxnet.np.trace</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.cond.html">mxnet.np.linalg.cond</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.det.html">mxnet.np.linalg.det</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.matrix_rank.html">mxnet.np.linalg.matrix_rank</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.slogdet.html">mxnet.np.linalg.slogdet</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.solve.html">mxnet.np.linalg.solve</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.tensorsolve.html">mxnet.np.linalg.tensorsolve</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.lstsq.html">mxnet.np.linalg.lstsq</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.inv.html">mxnet.np.linalg.inv</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.pinv.html">mxnet.np.linalg.pinv</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.tensorinv.html">mxnet.np.linalg.tensorinv</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.math.html">Mathematical functions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sin.html">mxnet.np.sin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cos.html">mxnet.np.cos</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.tan.html">mxnet.np.tan</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arcsin.html">mxnet.np.arcsin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arccos.html">mxnet.np.arccos</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arctan.html">mxnet.np.arctan</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.degrees.html">mxnet.np.degrees</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.radians.html">mxnet.np.radians</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.hypot.html">mxnet.np.hypot</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arctan2.html">mxnet.np.arctan2</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.deg2rad.html">mxnet.np.deg2rad</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.rad2deg.html">mxnet.np.rad2deg</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.unwrap.html">mxnet.np.unwrap</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sinh.html">mxnet.np.sinh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cosh.html">mxnet.np.cosh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.tanh.html">mxnet.np.tanh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arcsinh.html">mxnet.np.arcsinh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arccosh.html">mxnet.np.arccosh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arctanh.html">mxnet.np.arctanh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.rint.html">mxnet.np.rint</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fix.html">mxnet.np.fix</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.floor.html">mxnet.np.floor</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ceil.html">mxnet.np.ceil</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.trunc.html">mxnet.np.trunc</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.around.html">mxnet.np.around</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.round_.html">mxnet.np.round_</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sum.html">mxnet.np.sum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.prod.html">mxnet.np.prod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cumsum.html">mxnet.np.cumsum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanprod.html">mxnet.np.nanprod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nansum.html">mxnet.np.nansum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cumprod.html">mxnet.np.cumprod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nancumprod.html">mxnet.np.nancumprod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nancumsum.html">mxnet.np.nancumsum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.diff.html">mxnet.np.diff</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ediff1d.html">mxnet.np.ediff1d</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cross.html">mxnet.np.cross</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.trapz.html">mxnet.np.trapz</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.exp.html">mxnet.np.exp</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.expm1.html">mxnet.np.expm1</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.log.html">mxnet.np.log</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.log10.html">mxnet.np.log10</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.log2.html">mxnet.np.log2</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.log1p.html">mxnet.np.log1p</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.logaddexp.html">mxnet.np.logaddexp</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.i0.html">mxnet.np.i0</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ldexp.html">mxnet.np.ldexp</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.signbit.html">mxnet.np.signbit</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.copysign.html">mxnet.np.copysign</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.frexp.html">mxnet.np.frexp</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.spacing.html">mxnet.np.spacing</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.lcm.html">mxnet.np.lcm</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.gcd.html">mxnet.np.gcd</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.add.html">mxnet.np.add</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.reciprocal.html">mxnet.np.reciprocal</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.negative.html">mxnet.np.negative</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.divide.html">mxnet.np.divide</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.power.html">mxnet.np.power</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.subtract.html">mxnet.np.subtract</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.mod.html">mxnet.np.mod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.multiply.html">mxnet.np.multiply</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.true_divide.html">mxnet.np.true_divide</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.remainder.html">mxnet.np.remainder</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.positive.html">mxnet.np.positive</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.float_power.html">mxnet.np.float_power</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fmod.html">mxnet.np.fmod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.modf.html">mxnet.np.modf</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.divmod.html">mxnet.np.divmod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.floor_divide.html">mxnet.np.floor_divide</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.clip.html">mxnet.np.clip</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sqrt.html">mxnet.np.sqrt</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cbrt.html">mxnet.np.cbrt</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.square.html">mxnet.np.square</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.absolute.html">mxnet.np.absolute</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sign.html">mxnet.np.sign</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.maximum.html">mxnet.np.maximum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.minimum.html">mxnet.np.minimum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fabs.html">mxnet.np.fabs</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.heaviside.html">mxnet.np.heaviside</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fmax.html">mxnet.np.fmax</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fmin.html">mxnet.np.fmin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nan_to_num.html">mxnet.np.nan_to_num</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.interp.html">mxnet.np.interp</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/random/index.html">np.random</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.choice.html">mxnet.np.random.choice</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.shuffle.html">mxnet.np.random.shuffle</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.normal.html">mxnet.np.random.normal</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.uniform.html">mxnet.np.random.uniform</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.rand.html">mxnet.np.random.rand</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.randint.html">mxnet.np.random.randint</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.beta.html">mxnet.np.random.beta</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.chisquare.html">mxnet.np.random.chisquare</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.exponential.html">mxnet.np.random.exponential</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.f.html">mxnet.np.random.f</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.gamma.html">mxnet.np.random.gamma</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.gumbel.html">mxnet.np.random.gumbel</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.laplace.html">mxnet.np.random.laplace</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.logistic.html">mxnet.np.random.logistic</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.lognormal.html">mxnet.np.random.lognormal</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.multinomial.html">mxnet.np.random.multinomial</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.multivariate_normal.html">mxnet.np.random.multivariate_normal</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.pareto.html">mxnet.np.random.pareto</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.power.html">mxnet.np.random.power</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.rayleigh.html">mxnet.np.random.rayleigh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.weibull.html">mxnet.np.random.weibull</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.sort.html">Sorting, searching, and counting</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ndarray.sort.html">mxnet.np.ndarray.sort</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sort.html">mxnet.np.sort</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.lexsort.html">mxnet.np.lexsort</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.argsort.html">mxnet.np.argsort</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.msort.html">mxnet.np.msort</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.partition.html">mxnet.np.partition</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.argpartition.html">mxnet.np.argpartition</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.argmax.html">mxnet.np.argmax</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.argmin.html">mxnet.np.argmin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanargmax.html">mxnet.np.nanargmax</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanargmin.html">mxnet.np.nanargmin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.argwhere.html">mxnet.np.argwhere</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nonzero.html">mxnet.np.nonzero</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.flatnonzero.html">mxnet.np.flatnonzero</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.where.html">mxnet.np.where</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.searchsorted.html">mxnet.np.searchsorted</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.extract.html">mxnet.np.extract</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.count_nonzero.html">mxnet.np.count_nonzero</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.statistics.html">Statistics</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.min.html">mxnet.np.min</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.max.html">mxnet.np.max</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.amin.html">mxnet.np.amin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.amax.html">mxnet.np.amax</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanmin.html">mxnet.np.nanmin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanmax.html">mxnet.np.nanmax</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ptp.html">mxnet.np.ptp</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.percentile.html">mxnet.np.percentile</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanpercentile.html">mxnet.np.nanpercentile</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.quantile.html">mxnet.np.quantile</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanquantile.html">mxnet.np.nanquantile</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.mean.html">mxnet.np.mean</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.std.html">mxnet.np.std</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.var.html">mxnet.np.var</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.median.html">mxnet.np.median</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.average.html">mxnet.np.average</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanmedian.html">mxnet.np.nanmedian</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanstd.html">mxnet.np.nanstd</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanvar.html">mxnet.np.nanvar</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.corrcoef.html">mxnet.np.corrcoef</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.correlate.html">mxnet.np.correlate</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cov.html">mxnet.np.cov</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.histogram.html">mxnet.np.histogram</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.histogram2d.html">mxnet.np.histogram2d</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.histogramdd.html">mxnet.np.histogramdd</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.bincount.html">mxnet.np.bincount</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.histogram_bin_edges.html">mxnet.np.histogram_bin_edges</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.digitize.html">mxnet.np.digitize</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../npx/index.html">NPX: NumPy Neural Network Extension</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.set_np.html">mxnet.npx.set_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.reset_np.html">mxnet.npx.reset_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.cpu.html">mxnet.npx.cpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.cpu_pinned.html">mxnet.npx.cpu_pinned</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.gpu.html">mxnet.npx.gpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.gpu_memory_info.html">mxnet.npx.gpu_memory_info</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.current_device.html">mxnet.npx.current_device</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.num_gpus.html">mxnet.npx.num_gpus</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.activation.html">mxnet.npx.activation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.batch_norm.html">mxnet.npx.batch_norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.convolution.html">mxnet.npx.convolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.dropout.html">mxnet.npx.dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.embedding.html">mxnet.npx.embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.fully_connected.html">mxnet.npx.fully_connected</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.layer_norm.html">mxnet.npx.layer_norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.pooling.html">mxnet.npx.pooling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.rnn.html">mxnet.npx.rnn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.leaky_relu.html">mxnet.npx.leaky_relu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.multibox_detection.html">mxnet.npx.multibox_detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.multibox_prior.html">mxnet.npx.multibox_prior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.multibox_target.html">mxnet.npx.multibox_target</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.roi_pooling.html">mxnet.npx.roi_pooling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.sigmoid.html">mxnet.npx.sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.relu.html">mxnet.npx.relu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.smooth_l1.html">mxnet.npx.smooth_l1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.softmax.html">mxnet.npx.softmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.log_softmax.html">mxnet.npx.log_softmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.topk.html">mxnet.npx.topk</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.waitall.html">mxnet.npx.waitall</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.load.html">mxnet.npx.load</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.save.html">mxnet.npx.save</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.one_hot.html">mxnet.npx.one_hot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.pick.html">mxnet.npx.pick</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.reshape_like.html">mxnet.npx.reshape_like</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.batch_flatten.html">mxnet.npx.batch_flatten</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.batch_dot.html">mxnet.npx.batch_dot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.gamma.html">mxnet.npx.gamma</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.sequence_mask.html">mxnet.npx.sequence_mask</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">mxnet.gluon</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../block.html">gluon.Block</a></li>
<li class="toctree-l3"><a class="reference internal" href="../hybrid_block.html">gluon.HybridBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../symbol_block.html">gluon.SymbolBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../constant.html">gluon.Constant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../parameter.html">gluon.Parameter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../trainer.html">gluon.Trainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contrib/index.html">gluon.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data/index.html">gluon.data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../data/vision/index.html">data.vision</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../data/vision/datasets/index.html">vision.datasets</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/vision/transforms/index.html">vision.transforms</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../loss/index.html">gluon.loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../metric/index.html">gluon.metric</a></li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo/index.html">gluon.model_zoo.vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nn/index.html">gluon.nn</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">gluon.rnn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils/index.html">gluon.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../autograd/index.html">mxnet.autograd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../initializer/index.html">mxnet.initializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optimizer/index.html">mxnet.optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../lr_scheduler/index.html">mxnet.lr_scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore/index.html">KVStore: Communication for Distributed Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore/index.html#horovod">Horovod</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/generated/mxnet.kvstore.Horovod.html">mxnet.kvstore.Horovod</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore/index.html#byteps">BytePS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/generated/mxnet.kvstore.BytePS.html">mxnet.kvstore.BytePS</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore/index.html#kvstore-interface">KVStore Interface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/generated/mxnet.kvstore.KVStore.html">mxnet.kvstore.KVStore</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/generated/mxnet.kvstore.KVStoreBase.html">mxnet.kvstore.KVStoreBase</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/generated/mxnet.kvstore.KVStoreServer.html">mxnet.kvstore.KVStoreServer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../contrib/index.html">mxnet.contrib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/io/index.html">contrib.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/ndarray/index.html">contrib.ndarray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/onnx/index.html">contrib.onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/quantization/index.html">contrib.quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/symbol/index.html">contrib.symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/tensorboard/index.html">contrib.tensorboard</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/tensorrt/index.html">contrib.tensorrt</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/text/index.html">contrib.text</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../legacy/index.html">Legacy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/callback/index.html">mxnet.callback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/image/index.html">mxnet.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/io/index.html">mxnet.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/ndarray/index.html">mxnet.ndarray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/ndarray.html">ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/contrib/index.html">ndarray.contrib</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/image/index.html">ndarray.image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/linalg/index.html">ndarray.linalg</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/op/index.html">ndarray.op</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/random/index.html">ndarray.random</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/register/index.html">ndarray.register</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/sparse/index.html">ndarray.sparse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/utils/index.html">ndarray.utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/recordio/index.html">mxnet.recordio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/symbol/index.html">mxnet.symbol</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/symbol.html">symbol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/contrib/index.html">symbol.contrib</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/image/index.html">symbol.image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/linalg/index.html">symbol.linalg</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/op/index.html">symbol.op</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/random/index.html">symbol.random</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/register/index.html">symbol.register</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/sparse/index.html">symbol.sparse</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/visualization/index.html">mxnet.visualization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../device/index.html">mxnet.device</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../engine/index.html">mxnet.engine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../executor/index.html">mxnet.executor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore_server/index.html">mxnet.kvstore_server</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../profiler/index.html">mxnet.profiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rtc/index.html">mxnet.rtc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../runtime/index.html">mxnet.runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../runtime/generated/mxnet.runtime.Feature.html">mxnet.runtime.Feature</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../runtime/generated/mxnet.runtime.Features.html">mxnet.runtime.Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../runtime/generated/mxnet.runtime.feature_list.html">mxnet.runtime.feature_list</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../test_utils/index.html">mxnet.test_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../util/index.html">mxnet.util</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">
<header class="mdl-layout__drawer">      
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/index.html">Python Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/getting-started/index.html">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/index.html">Crash Course</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/0-introduction.html">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/1-nparray.html">Step 1: Manipulate data with NP on MXNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/2-create-nn.html">Step 2: Create a neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/3-autograd.html">Step 3: Automatic differentiation with autograd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/4-components.html">Step 4: Necessary components that are not in the network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-datasets.html">Step 5: <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-datasets.html#Using-own-data-with-included-Datasets">Using own data with included <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-datasets.html#Using-your-own-data-with-custom-Datasets">Using your own data with custom <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-datasets.html#New-in-MXNet-2.0:-faster-C++-backend-dataloaders">New in MXNet 2.0: faster C++ backend dataloaders</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/6-train-nn.html">Step 6: Train a Neural Network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/7-use-gpus.html">Step 7: Load and Run a NN using GPU</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/index.html">Moving to MXNet from Other Frameworks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/pytorch.html">PyTorch vs Apache MXNet</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/gluon_from_experiment_to_deployment.html">Gluon: from experiment to deployment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/gluon_migration_guide.html">Gluon2.0: Migration Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/logistic_regression_explained.html">Logistic regression explained</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/image/mnist.html">MNIST</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/packages/index.html">Packages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/autograd/index.html">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/gluon/index.html">Gluon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/index.html">Blocks</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/custom-layer.html">Custom Layers</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/hybridize.html">Hybridize</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/init.html">Initialization</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/naming.html">Parameter and Block Naming</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/nn.html">Layers and Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/parameters.html">Parameter Management</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/blocks/activations/activations.html">Activation Blocks</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/data/index.html">Data Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/data_augmentation.html">Image Augmentation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html">Gluon <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Using-own-data-with-included-Datasets">Using own data with included <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Using-own-data-with-custom-Datasets">Using own data with custom <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>s</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/data/datasets.html#Appendix:-Upgrading-from-Module-DataIter-to-Gluon-DataLoader">Appendix: Upgrading from Module <code class="docutils literal notranslate"><span class="pre">DataIter</span></code> to Gluon <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/image/index.html">Image Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/info_gan.html">Image similarity search with InfoGAN</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/mnist.html">Handwritten Digit Recognition</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/index.html">Losses</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/custom-loss.html">Custom Loss Blocks</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/kl_divergence.html">Kullback-Leibler (KL) Divergence</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/loss/loss.html">Loss functions</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/text/index.html">Text Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/text/gnmt.html">Google Neural Machine Translation</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/text/transformer.html">Machine Translation with Transformer</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/training/index.html">Training</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/fit_api_tutorial.html">MXNet Gluon Fit API</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/trainer.html">Trainer</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/index.html">Learning Rates</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_finder.html">Learning Rate Finder</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_schedules.html">Learning Rate Schedules</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/gluon/training/learning_rates/learning_rate_schedules_advanced.html">Advanced Learning Rate Schedules</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/training/normalization/index.html">Normalization Blocks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/kvstore/index.html">KVStore</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/kvstore/kvstore.html">Distributed Key-Value Store</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/legacy/index.html">Legacy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/index.html">NDArray</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/01-ndarray-intro.html">An Intro: Manipulate Data the MXNet Way with NDArray</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/02-ndarray-operations.html">NDArray Operations</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/03-ndarray-contexts.html">NDArray Contexts</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/gotchas_numpy_in_mxnet.html">Gotchas using NumPy in Apache MXNet</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/sparse/index.html">Tutorials</a><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/sparse/csr.html">CSRNDArray - NDArray in Compressed Sparse Row Storage Format</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../../tutorials/packages/legacy/ndarray/sparse/row_sparse.html">RowSparseNDArray - NDArray for Sparse Gradient Updates</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/np/index.html">What is NP on MXNet</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/np/cheat-sheet.html">The NP on MXNet cheat sheet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/np/np-vs-numpy.html">Differences between NP on MXNet and NumPy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/onnx/index.html">ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/onnx/fine_tuning_gluon.html">Fine-tuning an ONNX model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/onnx/inference_on_onnx_model.html">Running inference on MXNet/Gluon from an ONNX model</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/deploy/export/onnx.html">Export ONNX Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/optimizer/index.html">Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/viz/index.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/visualize_graph">Visualize networks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/performance/index.html">Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/compression/index.html">Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/compression/int8.html">Deploy with int-8</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/float16">Float16</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/faq/gradient_compression">Gradient Compression</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/int8_inference.html">GluonCV with Quantized Models</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/backend/index.html">Accelerated Backend Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/dnnl/index.html">oneDNN</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/dnnl/dnnl_readme.html">Install MXNet with oneDNN</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/dnnl/dnnl_quantization.html">oneDNN Quantization</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/performance/backend/dnnl/dnnl_quantization_inc.html">Improving accuracy with IntelÂ® Neural Compressor</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/tvm.html">Use TVM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/profiler.html">Profiling MXNet Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/backend/amp.html">Using AMP: Automatic Mixed Precision</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/deploy/index.html">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/export/index.html">Export</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/export/onnx.html">Exporting to ONNX format</a></li>
<li class="toctree-l4"><a class="reference external" href="https://gluon-cv.mxnet.io/build/examples_deployment/export_network.html">Export Gluon CV Models</a></li>
<li class="toctree-l4"><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Save / Load Parameters</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/inference/index.html">Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/cpp.html">Deploy into C++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/inference/image_classification_jetson.html">Image Classication using pretrained ResNet-50 model on Jetson module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/index.html">Run on AWS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_ec2.html">Run on an EC2 Instance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_sagemaker.html">Run on Amazon SageMaker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/cloud.html">MXNet on the Cloud</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/extend/index.html">Extend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/extend/customop.html">Custom Numpy Operators</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/new_op">New Operator Creation</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/add_op_in_backend">New Operator in MXNet Backend</a></li>
<li class="toctree-l3"><a class="reference external" href="https://mxnet.apache.org/api/faq/using_rtc">Using RTC for CUDA kernels</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../np/index.html">mxnet.np</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../np/arrays.html">Array objects</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../np/arrays.ndarray.html">The N-dimensional array (<code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../np/arrays.indexing.html">Indexing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../np/routines.html">Routines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.array-creation.html">Array creation routines</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.eye.html">mxnet.np.eye</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.empty.html">mxnet.np.empty</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.full.html">mxnet.np.full</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.identity.html">mxnet.np.identity</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ones.html">mxnet.np.ones</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ones_like.html">mxnet.np.ones_like</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.zeros.html">mxnet.np.zeros</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.zeros_like.html">mxnet.np.zeros_like</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.array.html">mxnet.np.array</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.copy.html">mxnet.np.copy</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arange.html">mxnet.np.arange</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linspace.html">mxnet.np.linspace</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.logspace.html">mxnet.np.logspace</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.meshgrid.html">mxnet.np.meshgrid</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.tril.html">mxnet.np.tril</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.array-manipulation.html">Array manipulation routines</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.reshape.html">mxnet.np.reshape</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ravel.html">mxnet.np.ravel</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ndarray.flatten.html">mxnet.np.ndarray.flatten</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.swapaxes.html">mxnet.np.swapaxes</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ndarray.T.html">mxnet.np.ndarray.T</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.transpose.html">mxnet.np.transpose</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.moveaxis.html">mxnet.np.moveaxis</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.rollaxis.html">mxnet.np.rollaxis</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.expand_dims.html">mxnet.np.expand_dims</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.squeeze.html">mxnet.np.squeeze</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.broadcast_to.html">mxnet.np.broadcast_to</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.broadcast_arrays.html">mxnet.np.broadcast_arrays</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.atleast_1d.html">mxnet.np.atleast_1d</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.atleast_2d.html">mxnet.np.atleast_2d</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.atleast_3d.html">mxnet.np.atleast_3d</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.concatenate.html">mxnet.np.concatenate</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.stack.html">mxnet.np.stack</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.dstack.html">mxnet.np.dstack</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.vstack.html">mxnet.np.vstack</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.column_stack.html">mxnet.np.column_stack</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.hstack.html">mxnet.np.hstack</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.split.html">mxnet.np.split</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.hsplit.html">mxnet.np.hsplit</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.vsplit.html">mxnet.np.vsplit</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.array_split.html">mxnet.np.array_split</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.dsplit.html">mxnet.np.dsplit</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.tile.html">mxnet.np.tile</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.repeat.html">mxnet.np.repeat</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.unique.html">mxnet.np.unique</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.delete.html">mxnet.np.delete</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.insert.html">mxnet.np.insert</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.append.html">mxnet.np.append</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.resize.html">mxnet.np.resize</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.trim_zeros.html">mxnet.np.trim_zeros</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.reshape.html">mxnet.np.reshape</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.flip.html">mxnet.np.flip</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.roll.html">mxnet.np.roll</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.rot90.html">mxnet.np.rot90</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fliplr.html">mxnet.np.fliplr</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.flipud.html">mxnet.np.flipud</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.io.html">Input and output</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.genfromtxt.html">mxnet.np.genfromtxt</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ndarray.tolist.html">mxnet.np.ndarray.tolist</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.set_printoptions.html">mxnet.np.set_printoptions</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.linalg.html">Linear algebra (<code class="xref py py-mod docutils literal notranslate"><span class="pre">numpy.linalg</span></code>)</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.dot.html">mxnet.np.dot</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.vdot.html">mxnet.np.vdot</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.inner.html">mxnet.np.inner</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.outer.html">mxnet.np.outer</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.tensordot.html">mxnet.np.tensordot</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.einsum.html">mxnet.np.einsum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.multi_dot.html">mxnet.np.linalg.multi_dot</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.matmul.html">mxnet.np.matmul</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.matrix_power.html">mxnet.np.linalg.matrix_power</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.kron.html">mxnet.np.kron</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.svd.html">mxnet.np.linalg.svd</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.cholesky.html">mxnet.np.linalg.cholesky</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.qr.html">mxnet.np.linalg.qr</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.eig.html">mxnet.np.linalg.eig</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.eigh.html">mxnet.np.linalg.eigh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.eigvals.html">mxnet.np.linalg.eigvals</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.eigvalsh.html">mxnet.np.linalg.eigvalsh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.norm.html">mxnet.np.linalg.norm</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.trace.html">mxnet.np.trace</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.cond.html">mxnet.np.linalg.cond</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.det.html">mxnet.np.linalg.det</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.matrix_rank.html">mxnet.np.linalg.matrix_rank</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.slogdet.html">mxnet.np.linalg.slogdet</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.solve.html">mxnet.np.linalg.solve</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.tensorsolve.html">mxnet.np.linalg.tensorsolve</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.lstsq.html">mxnet.np.linalg.lstsq</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.inv.html">mxnet.np.linalg.inv</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.pinv.html">mxnet.np.linalg.pinv</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.linalg.tensorinv.html">mxnet.np.linalg.tensorinv</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.math.html">Mathematical functions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sin.html">mxnet.np.sin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cos.html">mxnet.np.cos</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.tan.html">mxnet.np.tan</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arcsin.html">mxnet.np.arcsin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arccos.html">mxnet.np.arccos</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arctan.html">mxnet.np.arctan</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.degrees.html">mxnet.np.degrees</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.radians.html">mxnet.np.radians</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.hypot.html">mxnet.np.hypot</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arctan2.html">mxnet.np.arctan2</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.deg2rad.html">mxnet.np.deg2rad</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.rad2deg.html">mxnet.np.rad2deg</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.unwrap.html">mxnet.np.unwrap</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sinh.html">mxnet.np.sinh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cosh.html">mxnet.np.cosh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.tanh.html">mxnet.np.tanh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arcsinh.html">mxnet.np.arcsinh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arccosh.html">mxnet.np.arccosh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.arctanh.html">mxnet.np.arctanh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.rint.html">mxnet.np.rint</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fix.html">mxnet.np.fix</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.floor.html">mxnet.np.floor</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ceil.html">mxnet.np.ceil</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.trunc.html">mxnet.np.trunc</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.around.html">mxnet.np.around</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.round_.html">mxnet.np.round_</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sum.html">mxnet.np.sum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.prod.html">mxnet.np.prod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cumsum.html">mxnet.np.cumsum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanprod.html">mxnet.np.nanprod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nansum.html">mxnet.np.nansum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cumprod.html">mxnet.np.cumprod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nancumprod.html">mxnet.np.nancumprod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nancumsum.html">mxnet.np.nancumsum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.diff.html">mxnet.np.diff</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ediff1d.html">mxnet.np.ediff1d</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cross.html">mxnet.np.cross</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.trapz.html">mxnet.np.trapz</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.exp.html">mxnet.np.exp</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.expm1.html">mxnet.np.expm1</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.log.html">mxnet.np.log</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.log10.html">mxnet.np.log10</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.log2.html">mxnet.np.log2</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.log1p.html">mxnet.np.log1p</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.logaddexp.html">mxnet.np.logaddexp</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.i0.html">mxnet.np.i0</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ldexp.html">mxnet.np.ldexp</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.signbit.html">mxnet.np.signbit</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.copysign.html">mxnet.np.copysign</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.frexp.html">mxnet.np.frexp</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.spacing.html">mxnet.np.spacing</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.lcm.html">mxnet.np.lcm</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.gcd.html">mxnet.np.gcd</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.add.html">mxnet.np.add</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.reciprocal.html">mxnet.np.reciprocal</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.negative.html">mxnet.np.negative</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.divide.html">mxnet.np.divide</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.power.html">mxnet.np.power</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.subtract.html">mxnet.np.subtract</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.mod.html">mxnet.np.mod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.multiply.html">mxnet.np.multiply</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.true_divide.html">mxnet.np.true_divide</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.remainder.html">mxnet.np.remainder</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.positive.html">mxnet.np.positive</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.float_power.html">mxnet.np.float_power</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fmod.html">mxnet.np.fmod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.modf.html">mxnet.np.modf</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.divmod.html">mxnet.np.divmod</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.floor_divide.html">mxnet.np.floor_divide</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.clip.html">mxnet.np.clip</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sqrt.html">mxnet.np.sqrt</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cbrt.html">mxnet.np.cbrt</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.square.html">mxnet.np.square</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.absolute.html">mxnet.np.absolute</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sign.html">mxnet.np.sign</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.maximum.html">mxnet.np.maximum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.minimum.html">mxnet.np.minimum</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fabs.html">mxnet.np.fabs</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.heaviside.html">mxnet.np.heaviside</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fmax.html">mxnet.np.fmax</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.fmin.html">mxnet.np.fmin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nan_to_num.html">mxnet.np.nan_to_num</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.interp.html">mxnet.np.interp</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/random/index.html">np.random</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.choice.html">mxnet.np.random.choice</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.shuffle.html">mxnet.np.random.shuffle</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.normal.html">mxnet.np.random.normal</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.uniform.html">mxnet.np.random.uniform</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.rand.html">mxnet.np.random.rand</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.randint.html">mxnet.np.random.randint</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.beta.html">mxnet.np.random.beta</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.chisquare.html">mxnet.np.random.chisquare</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.exponential.html">mxnet.np.random.exponential</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.f.html">mxnet.np.random.f</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.gamma.html">mxnet.np.random.gamma</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.gumbel.html">mxnet.np.random.gumbel</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.laplace.html">mxnet.np.random.laplace</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.logistic.html">mxnet.np.random.logistic</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.lognormal.html">mxnet.np.random.lognormal</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.multinomial.html">mxnet.np.random.multinomial</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.multivariate_normal.html">mxnet.np.random.multivariate_normal</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.pareto.html">mxnet.np.random.pareto</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.power.html">mxnet.np.random.power</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.rayleigh.html">mxnet.np.random.rayleigh</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/random/generated/mxnet.np.random.weibull.html">mxnet.np.random.weibull</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.sort.html">Sorting, searching, and counting</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ndarray.sort.html">mxnet.np.ndarray.sort</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.sort.html">mxnet.np.sort</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.lexsort.html">mxnet.np.lexsort</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.argsort.html">mxnet.np.argsort</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.msort.html">mxnet.np.msort</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.partition.html">mxnet.np.partition</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.argpartition.html">mxnet.np.argpartition</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.argmax.html">mxnet.np.argmax</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.argmin.html">mxnet.np.argmin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanargmax.html">mxnet.np.nanargmax</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanargmin.html">mxnet.np.nanargmin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.argwhere.html">mxnet.np.argwhere</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nonzero.html">mxnet.np.nonzero</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.flatnonzero.html">mxnet.np.flatnonzero</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.where.html">mxnet.np.where</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.searchsorted.html">mxnet.np.searchsorted</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.extract.html">mxnet.np.extract</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.count_nonzero.html">mxnet.np.count_nonzero</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../np/routines.statistics.html">Statistics</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.min.html">mxnet.np.min</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.max.html">mxnet.np.max</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.amin.html">mxnet.np.amin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.amax.html">mxnet.np.amax</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanmin.html">mxnet.np.nanmin</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanmax.html">mxnet.np.nanmax</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.ptp.html">mxnet.np.ptp</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.percentile.html">mxnet.np.percentile</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanpercentile.html">mxnet.np.nanpercentile</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.quantile.html">mxnet.np.quantile</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanquantile.html">mxnet.np.nanquantile</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.mean.html">mxnet.np.mean</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.std.html">mxnet.np.std</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.var.html">mxnet.np.var</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.median.html">mxnet.np.median</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.average.html">mxnet.np.average</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanmedian.html">mxnet.np.nanmedian</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanstd.html">mxnet.np.nanstd</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.nanvar.html">mxnet.np.nanvar</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.corrcoef.html">mxnet.np.corrcoef</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.correlate.html">mxnet.np.correlate</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.cov.html">mxnet.np.cov</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.histogram.html">mxnet.np.histogram</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.histogram2d.html">mxnet.np.histogram2d</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.histogramdd.html">mxnet.np.histogramdd</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.bincount.html">mxnet.np.bincount</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.histogram_bin_edges.html">mxnet.np.histogram_bin_edges</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../np/generated/mxnet.np.digitize.html">mxnet.np.digitize</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../npx/index.html">NPX: NumPy Neural Network Extension</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.set_np.html">mxnet.npx.set_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.reset_np.html">mxnet.npx.reset_np</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.cpu.html">mxnet.npx.cpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.cpu_pinned.html">mxnet.npx.cpu_pinned</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.gpu.html">mxnet.npx.gpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.gpu_memory_info.html">mxnet.npx.gpu_memory_info</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.current_device.html">mxnet.npx.current_device</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.num_gpus.html">mxnet.npx.num_gpus</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.activation.html">mxnet.npx.activation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.batch_norm.html">mxnet.npx.batch_norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.convolution.html">mxnet.npx.convolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.dropout.html">mxnet.npx.dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.embedding.html">mxnet.npx.embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.fully_connected.html">mxnet.npx.fully_connected</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.layer_norm.html">mxnet.npx.layer_norm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.pooling.html">mxnet.npx.pooling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.rnn.html">mxnet.npx.rnn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.leaky_relu.html">mxnet.npx.leaky_relu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.multibox_detection.html">mxnet.npx.multibox_detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.multibox_prior.html">mxnet.npx.multibox_prior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.multibox_target.html">mxnet.npx.multibox_target</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.roi_pooling.html">mxnet.npx.roi_pooling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.sigmoid.html">mxnet.npx.sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.relu.html">mxnet.npx.relu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.smooth_l1.html">mxnet.npx.smooth_l1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.softmax.html">mxnet.npx.softmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.log_softmax.html">mxnet.npx.log_softmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.topk.html">mxnet.npx.topk</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.waitall.html">mxnet.npx.waitall</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.load.html">mxnet.npx.load</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.save.html">mxnet.npx.save</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.one_hot.html">mxnet.npx.one_hot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.pick.html">mxnet.npx.pick</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.reshape_like.html">mxnet.npx.reshape_like</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.batch_flatten.html">mxnet.npx.batch_flatten</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.batch_dot.html">mxnet.npx.batch_dot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.gamma.html">mxnet.npx.gamma</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../npx/generated/mxnet.npx.sequence_mask.html">mxnet.npx.sequence_mask</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">mxnet.gluon</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../block.html">gluon.Block</a></li>
<li class="toctree-l3"><a class="reference internal" href="../hybrid_block.html">gluon.HybridBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../symbol_block.html">gluon.SymbolBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../constant.html">gluon.Constant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../parameter.html">gluon.Parameter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../trainer.html">gluon.Trainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contrib/index.html">gluon.contrib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../data/index.html">gluon.data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../data/vision/index.html">data.vision</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../data/vision/datasets/index.html">vision.datasets</a></li>
<li class="toctree-l5"><a class="reference internal" href="../data/vision/transforms/index.html">vision.transforms</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../loss/index.html">gluon.loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../metric/index.html">gluon.metric</a></li>
<li class="toctree-l3"><a class="reference internal" href="../model_zoo/index.html">gluon.model_zoo.vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nn/index.html">gluon.nn</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">gluon.rnn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../utils/index.html">gluon.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../autograd/index.html">mxnet.autograd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../initializer/index.html">mxnet.initializer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../optimizer/index.html">mxnet.optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../lr_scheduler/index.html">mxnet.lr_scheduler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore/index.html">KVStore: Communication for Distributed Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore/index.html#horovod">Horovod</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/generated/mxnet.kvstore.Horovod.html">mxnet.kvstore.Horovod</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore/index.html#byteps">BytePS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/generated/mxnet.kvstore.BytePS.html">mxnet.kvstore.BytePS</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore/index.html#kvstore-interface">KVStore Interface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/generated/mxnet.kvstore.KVStore.html">mxnet.kvstore.KVStore</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/generated/mxnet.kvstore.KVStoreBase.html">mxnet.kvstore.KVStoreBase</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../kvstore/generated/mxnet.kvstore.KVStoreServer.html">mxnet.kvstore.KVStoreServer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../contrib/index.html">mxnet.contrib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/io/index.html">contrib.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/ndarray/index.html">contrib.ndarray</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/onnx/index.html">contrib.onnx</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/quantization/index.html">contrib.quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/symbol/index.html">contrib.symbol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/tensorboard/index.html">contrib.tensorboard</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/tensorrt/index.html">contrib.tensorrt</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../contrib/text/index.html">contrib.text</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../legacy/index.html">Legacy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/callback/index.html">mxnet.callback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/image/index.html">mxnet.image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/io/index.html">mxnet.io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/ndarray/index.html">mxnet.ndarray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/ndarray.html">ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/contrib/index.html">ndarray.contrib</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/image/index.html">ndarray.image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/linalg/index.html">ndarray.linalg</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/op/index.html">ndarray.op</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/random/index.html">ndarray.random</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/register/index.html">ndarray.register</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/sparse/index.html">ndarray.sparse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/ndarray/utils/index.html">ndarray.utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/recordio/index.html">mxnet.recordio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/symbol/index.html">mxnet.symbol</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/symbol.html">symbol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/contrib/index.html">symbol.contrib</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/image/index.html">symbol.image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/linalg/index.html">symbol.linalg</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/op/index.html">symbol.op</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/random/index.html">symbol.random</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/register/index.html">symbol.register</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../legacy/symbol/sparse/index.html">symbol.sparse</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../legacy/visualization/index.html">mxnet.visualization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../device/index.html">mxnet.device</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../engine/index.html">mxnet.engine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../executor/index.html">mxnet.executor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../kvstore_server/index.html">mxnet.kvstore_server</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../profiler/index.html">mxnet.profiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rtc/index.html">mxnet.rtc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../runtime/index.html">mxnet.runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../runtime/generated/mxnet.runtime.Feature.html">mxnet.runtime.Feature</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../runtime/generated/mxnet.runtime.Features.html">mxnet.runtime.Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../runtime/generated/mxnet.runtime.feature_list.html">mxnet.runtime.feature_list</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../test_utils/index.html">mxnet.test_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../util/index.html">mxnet.util</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="gluon-rnn">
<h1>gluon.rnn<a class="headerlink" href="#gluon-rnn" title="Permalink to this headline">Â¶</a></h1>
<p>Build-in recurrent neural network layers are provided in the following two modules:</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#module-mxnet.gluon.rnn" title="mxnet.gluon.rnn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mxnet.gluon.rnn</span></code></a></p></td>
<td><p>Recurrent neural network module.</p></td>
</tr>
</tbody>
</table>
<div class="section" id="recurrent-cells">
<h2>Recurrent Cells<a class="headerlink" href="#recurrent-cells" title="Permalink to this headline">Â¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell" title="mxnet.gluon.rnn.LSTMCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.LSTMCell</span></code></a></p></td>
<td><p>Long-Short Term Memory (LSTM) network cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell" title="mxnet.gluon.rnn.GRUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.GRUCell</span></code></a></p></td>
<td><p>Gated Rectified Unit (GRU) network cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell" title="mxnet.gluon.rnn.RecurrentCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.RecurrentCell</span></code></a></p></td>
<td><p>Abstract base class for RNN cells</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell" title="mxnet.gluon.rnn.LSTMPCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.LSTMPCell</span></code></a></p></td>
<td><p>Long-Short Term Memory Projected (LSTMP) network cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell" title="mxnet.gluon.rnn.SequentialRNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.SequentialRNNCell</span></code></a></p></td>
<td><p>Sequentially stacking multiple RNN cells.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell" title="mxnet.gluon.rnn.BidirectionalCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.BidirectionalCell</span></code></a></p></td>
<td><p>Bidirectional RNN cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell" title="mxnet.gluon.rnn.DropoutCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.DropoutCell</span></code></a></p></td>
<td><p>Applies dropout on input.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell" title="mxnet.gluon.rnn.VariationalDropoutCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.VariationalDropoutCell</span></code></a></p></td>
<td><p>Applies Variational Dropout on base cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell" title="mxnet.gluon.rnn.ZoneoutCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.ZoneoutCell</span></code></a></p></td>
<td><p>Applies Zoneout on base cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell" title="mxnet.gluon.rnn.ResidualCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.ResidualCell</span></code></a></p></td>
<td><p>Adds residual connection as described in Wu et al, 2016 (<a class="reference external" href="https://arxiv.org/abs/1609.08144">https://arxiv.org/abs/1609.08144</a>).</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="convolutional-recurrent-cells">
<h2>Convolutional Recurrent Cells<a class="headerlink" href="#convolutional-recurrent-cells" title="Permalink to this headline">Â¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv1DLSTMCell" title="mxnet.gluon.rnn.Conv1DLSTMCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.Conv1DLSTMCell</span></code></a></p></td>
<td><p>1D Convolutional LSTM network cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv2DLSTMCell" title="mxnet.gluon.rnn.Conv2DLSTMCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.Conv2DLSTMCell</span></code></a></p></td>
<td><p>2D Convolutional LSTM network cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv3DLSTMCell" title="mxnet.gluon.rnn.Conv3DLSTMCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.Conv3DLSTMCell</span></code></a></p></td>
<td><p>3D Convolutional LSTM network cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv1DGRUCell" title="mxnet.gluon.rnn.Conv1DGRUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.Conv1DGRUCell</span></code></a></p></td>
<td><p>1D Convolutional Gated Rectified Unit (GRU) network cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv2DGRUCell" title="mxnet.gluon.rnn.Conv2DGRUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.Conv2DGRUCell</span></code></a></p></td>
<td><p>2D Convolutional Gated Rectified Unit (GRU) network cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv3DGRUCell" title="mxnet.gluon.rnn.Conv3DGRUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.Conv3DGRUCell</span></code></a></p></td>
<td><p>3D Convolutional Gated Rectified Unit (GRU) network cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv1DRNNCell" title="mxnet.gluon.rnn.Conv1DRNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.Conv1DRNNCell</span></code></a></p></td>
<td><p>1D Convolutional RNN cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv2DRNNCell" title="mxnet.gluon.rnn.Conv2DRNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.Conv2DRNNCell</span></code></a></p></td>
<td><p>2D Convolutional RNN cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv3DRNNCell" title="mxnet.gluon.rnn.Conv3DRNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.Conv3DRNNCell</span></code></a></p></td>
<td><p>3D Convolutional RNN cells</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="recurrent-layers">
<h2>Recurrent Layers<a class="headerlink" href="#recurrent-layers" title="Permalink to this headline">Â¶</a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNN" title="mxnet.gluon.rnn.RNN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.RNN</span></code></a></p></td>
<td><p>Applies a multi-layer Elman RNN with <cite>tanh</cite> or <cite>ReLU</cite> non-linearity to an input sequence.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTM" title="mxnet.gluon.rnn.LSTM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.LSTM</span></code></a></p></td>
<td><p>Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRU" title="mxnet.gluon.rnn.GRU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rnn.GRU</span></code></a></p></td>
<td><p>Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="module-mxnet.gluon.rnn">
<span id="api-reference"></span><h2>API Reference<a class="headerlink" href="#module-mxnet.gluon.rnn" title="Permalink to this headline">Â¶</a></h2>
<p>Recurrent neural network module.</p>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell" title="mxnet.gluon.rnn.BidirectionalCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BidirectionalCell</span></code></a>(l_cell,Â r_cell)</p></td>
<td><p>Bidirectional RNN cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv1DGRUCell" title="mxnet.gluon.rnn.Conv1DGRUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Conv1DGRUCell</span></code></a>(input_shape,Â hidden_channels,Â â¦)</p></td>
<td><p>1D Convolutional Gated Rectified Unit (GRU) network cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv1DLSTMCell" title="mxnet.gluon.rnn.Conv1DLSTMCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Conv1DLSTMCell</span></code></a>(input_shape,Â hidden_channels,Â â¦)</p></td>
<td><p>1D Convolutional LSTM network cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv1DRNNCell" title="mxnet.gluon.rnn.Conv1DRNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Conv1DRNNCell</span></code></a>(input_shape,Â hidden_channels,Â â¦)</p></td>
<td><p>1D Convolutional RNN cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv2DGRUCell" title="mxnet.gluon.rnn.Conv2DGRUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Conv2DGRUCell</span></code></a>(input_shape,Â hidden_channels,Â â¦)</p></td>
<td><p>2D Convolutional Gated Rectified Unit (GRU) network cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv2DLSTMCell" title="mxnet.gluon.rnn.Conv2DLSTMCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Conv2DLSTMCell</span></code></a>(input_shape,Â hidden_channels,Â â¦)</p></td>
<td><p>2D Convolutional LSTM network cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv2DRNNCell" title="mxnet.gluon.rnn.Conv2DRNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Conv2DRNNCell</span></code></a>(input_shape,Â hidden_channels,Â â¦)</p></td>
<td><p>2D Convolutional RNN cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv3DGRUCell" title="mxnet.gluon.rnn.Conv3DGRUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Conv3DGRUCell</span></code></a>(input_shape,Â hidden_channels,Â â¦)</p></td>
<td><p>3D Convolutional Gated Rectified Unit (GRU) network cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv3DLSTMCell" title="mxnet.gluon.rnn.Conv3DLSTMCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Conv3DLSTMCell</span></code></a>(input_shape,Â hidden_channels,Â â¦)</p></td>
<td><p>3D Convolutional LSTM network cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.Conv3DRNNCell" title="mxnet.gluon.rnn.Conv3DRNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Conv3DRNNCell</span></code></a>(input_shape,Â hidden_channels,Â â¦)</p></td>
<td><p>3D Convolutional RNN cells</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell" title="mxnet.gluon.rnn.DropoutCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DropoutCell</span></code></a>(rate[,Â axes])</p></td>
<td><p>Applies dropout on input.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRU" title="mxnet.gluon.rnn.GRU"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GRU</span></code></a>(hidden_size[,Â num_layers,Â layout,Â â¦])</p></td>
<td><p>Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell" title="mxnet.gluon.rnn.GRUCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GRUCell</span></code></a>(hidden_size[,Â â¦])</p></td>
<td><p>Gated Rectified Unit (GRU) network cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell" title="mxnet.gluon.rnn.HybridRecurrentCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HybridRecurrentCell</span></code></a>()</p></td>
<td><p>HybridRecurrentCell supports hybridize.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell" title="mxnet.gluon.rnn.HybridSequentialRNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HybridSequentialRNNCell</span></code></a>()</p></td>
<td><p>Sequentially stacking multiple HybridRNN cells.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTM" title="mxnet.gluon.rnn.LSTM"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LSTM</span></code></a>(hidden_size[,Â num_layers,Â layout,Â â¦])</p></td>
<td><p>Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell" title="mxnet.gluon.rnn.LSTMCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LSTMCell</span></code></a>(hidden_size[,Â â¦])</p></td>
<td><p>Long-Short Term Memory (LSTM) network cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell" title="mxnet.gluon.rnn.LSTMPCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LSTMPCell</span></code></a>(hidden_size,Â projection_size[,Â â¦])</p></td>
<td><p>Long-Short Term Memory Projected (LSTMP) network cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell" title="mxnet.gluon.rnn.ModifierCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ModifierCell</span></code></a>(base_cell)</p></td>
<td><p>Base class for modifier cells.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNN" title="mxnet.gluon.rnn.RNN"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RNN</span></code></a>(hidden_size[,Â num_layers,Â activation,Â â¦])</p></td>
<td><p>Applies a multi-layer Elman RNN with <cite>tanh</cite> or <cite>ReLU</cite> non-linearity to an input sequence.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell" title="mxnet.gluon.rnn.RNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RNNCell</span></code></a>(hidden_size[,Â activation,Â â¦])</p></td>
<td><p>Elman RNN recurrent neural network cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell" title="mxnet.gluon.rnn.RecurrentCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RecurrentCell</span></code></a>()</p></td>
<td><p>Abstract base class for RNN cells</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell" title="mxnet.gluon.rnn.ResidualCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ResidualCell</span></code></a>(base_cell)</p></td>
<td><p>Adds residual connection as described in Wu et al, 2016 (<a class="reference external" href="https://arxiv.org/abs/1609.08144">https://arxiv.org/abs/1609.08144</a>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell" title="mxnet.gluon.rnn.SequentialRNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SequentialRNNCell</span></code></a>()</p></td>
<td><p>Sequentially stacking multiple RNN cells.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell" title="mxnet.gluon.rnn.VariationalDropoutCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">VariationalDropoutCell</span></code></a>(base_cell[,Â â¦])</p></td>
<td><p>Applies Variational Dropout on base cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell" title="mxnet.gluon.rnn.ZoneoutCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ZoneoutCell</span></code></a>(base_cell[,Â zoneout_outputs,Â â¦])</p></td>
<td><p>Applies Zoneout on base cell.</p></td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="mxnet.gluon.rnn.BidirectionalCell">
<em class="property">class </em><code class="sig-name descname">BidirectionalCell</code><span class="sig-paren">(</span><em class="sig-param">l_cell</em>, <em class="sig-param">r_cell</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#BidirectionalCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.HybridRecurrentCell</span></code></p>
<p>Bidirectional RNN cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>l_cell</strong> (<a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell" title="mxnet.gluon.rnn.RecurrentCell"><em>RecurrentCell</em></a>) â Cell for forward unrolling</p></li>
<li><p><strong>r_cell</strong> (<a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell" title="mxnet.gluon.rnn.RecurrentCell"><em>RecurrentCell</em></a>) â Cell for backward unrolling</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.apply" title="mxnet.gluon.rnn.BidirectionalCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.begin_state" title="mxnet.gluon.rnn.BidirectionalCell.begin_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">begin_state</span></code></a>(**kwargs)</p></td>
<td><p>Initial state for this cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.cast" title="mxnet.gluon.rnn.BidirectionalCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.collect_params" title="mxnet.gluon.rnn.BidirectionalCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.export" title="mxnet.gluon.rnn.BidirectionalCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.hybridize" title="mxnet.gluon.rnn.BidirectionalCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.infer_shape" title="mxnet.gluon.rnn.BidirectionalCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(i,Â x,Â is_bidirect)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.infer_type" title="mxnet.gluon.rnn.BidirectionalCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.initialize" title="mxnet.gluon.rnn.BidirectionalCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.load" title="mxnet.gluon.rnn.BidirectionalCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.load_dict" title="mxnet.gluon.rnn.BidirectionalCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.load_parameters" title="mxnet.gluon.rnn.BidirectionalCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.optimize_for" title="mxnet.gluon.rnn.BidirectionalCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.register_child" title="mxnet.gluon.rnn.BidirectionalCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.register_forward_hook" title="mxnet.gluon.rnn.BidirectionalCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.register_forward_pre_hook" title="mxnet.gluon.rnn.BidirectionalCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.register_op_hook" title="mxnet.gluon.rnn.BidirectionalCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.reset" title="mxnet.gluon.rnn.BidirectionalCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.reset_ctx" title="mxnet.gluon.rnn.BidirectionalCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.reset_device" title="mxnet.gluon.rnn.BidirectionalCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.save" title="mxnet.gluon.rnn.BidirectionalCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.save_parameters" title="mxnet.gluon.rnn.BidirectionalCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.setattr" title="mxnet.gluon.rnn.BidirectionalCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.share_parameters" title="mxnet.gluon.rnn.BidirectionalCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.state_info" title="mxnet.gluon.rnn.BidirectionalCell.state_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_info</span></code></a>([batch_size])</p></td>
<td><p>shape and layout information of states</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.summary" title="mxnet.gluon.rnn.BidirectionalCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.unroll" title="mxnet.gluon.rnn.BidirectionalCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.zero_grad" title="mxnet.gluon.rnn.BidirectionalCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.BidirectionalCell.params" title="mxnet.gluon.rnn.BidirectionalCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its childrenâs parameters).</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.begin_state">
<code class="sig-name descname">begin_state</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#BidirectionalCell.begin_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.begin_state" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initial state for this cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) â <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â Only required for NDArray API. Size of the batch (âNâ in layout)
dimension of input.</p></li>
<li><p><strong>**kwargs</strong> â Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states</strong> â Starting states for the first RNN step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested list of Symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">i</em>, <em class="sig-param">x</em>, <em class="sig-param">is_bidirect</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#BidirectionalCell.infer_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its
childrenâs parameters).</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.state_info">
<code class="sig-name descname">state_info</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#BidirectionalCell.state_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.state_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#BidirectionalCell.unroll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.BidirectionalCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.BidirectionalCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.Conv1DGRUCell">
<em class="property">class </em><code class="sig-name descname">Conv1DGRUCell</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">i2h_kernel</em>, <em class="sig-param">h2h_kernel</em>, <em class="sig-param">i2h_pad=(0</em>, <em class="sig-param">)</em>, <em class="sig-param">i2h_dilate=(1</em>, <em class="sig-param">)</em>, <em class="sig-param">h2h_dilate=(1</em>, <em class="sig-param">)</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">conv_layout='NCW'</em>, <em class="sig-param">activation='tanh'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/conv_rnn_cell.html#Conv1DGRUCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.Conv1DGRUCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.conv_rnn_cell._ConvGRUCell</span></code></p>
<p>1D Convolutional Gated Rectified Unit (GRU) network cell.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
r_t = \sigma(W_r \ast x_t + R_r \ast h_{t-1} + b_r) \\
z_t = \sigma(W_z \ast x_t + R_z \ast h_{t-1} + b_z) \\
n_t = tanh(W_i \ast x_t + b_i + r_t \circ (R_n \ast h_{t-1} + b_n)) \\
h^\prime_t = (1 - z_t) \circ n_t + z_t \circ h \\
\end{array}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple of int</em>) â Input tensor shape at each time step for each sample, excluding dimension of the batch size
and sequence length. Must be consistent with <cite>conv_layout</cite>.
For example, for layout âNCWâ the shape should be (C, W).</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) â Number of output channels.</p></li>
<li><p><strong>i2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Input convolution kernel sizes.</p></li>
<li><p><strong>h2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.</p></li>
<li><p><strong>i2h_pad</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>0</em><em>,</em><em>)</em>) â Pad for input convolution.</p></li>
<li><p><strong>i2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>,</em><em>)</em>) â Input convolution dilate.</p></li>
<li><p><strong>h2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>,</em><em>)</em>) â Recurrent convolution dilate.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the input convolutions.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the input convolutions.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the input convolution bias vectors.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the recurrent convolution bias vectors.</p></li>
<li><p><strong>conv_layout</strong> (<em>str</em><em>, </em><em>default 'NCW'</em>) â Layout for all convolution inputs, outputs and weights. Options are âNCWâ and âNWCâ.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em> or </em><a class="reference internal" href="../block.html#mxnet.gluon.Block" title="mxnet.gluon.Block"><em>gluon.Block</em></a><em>, </em><em>default 'tanh'</em>) â Type of activation function used in n_t.
If argument type is string, itâs equivalent to nn.Activation(act_type=str). See
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.Activation" title="mxnet.ndarray.Activation"><code class="xref py py-func docutils literal notranslate"><span class="pre">Activation()</span></code></a> for available choices.
Alternatively, other activation blocks such as nn.LeakyReLU can be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.Conv1DLSTMCell">
<em class="property">class </em><code class="sig-name descname">Conv1DLSTMCell</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">i2h_kernel</em>, <em class="sig-param">h2h_kernel</em>, <em class="sig-param">i2h_pad=(0</em>, <em class="sig-param">)</em>, <em class="sig-param">i2h_dilate=(1</em>, <em class="sig-param">)</em>, <em class="sig-param">h2h_dilate=(1</em>, <em class="sig-param">)</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">conv_layout='NCW'</em>, <em class="sig-param">activation='tanh'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/conv_rnn_cell.html#Conv1DLSTMCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.Conv1DLSTMCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.conv_rnn_cell._ConvLSTMCell</span></code></p>
<p>1D Convolutional LSTM network cell.</p>
<p><a class="reference external" href="https://arxiv.org/abs/1506.04214">âConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcastingâ</a> paper. Xingjian et al. NIPS2015</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
i_t = \sigma(W_i \ast x_t + R_i \ast h_{t-1} + b_i) \\
f_t = \sigma(W_f \ast x_t + R_f \ast h_{t-1} + b_f) \\
o_t = \sigma(W_o \ast x_t + R_o \ast h_{t-1} + b_o) \\
c^\prime_t = tanh(W_c \ast x_t + R_c \ast h_{t-1} + b_c) \\
c_t = f_t \circ c_{t-1} + i_t \circ c^\prime_t \\
h_t = o_t \circ tanh(c_t) \\
\end{array}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple of int</em>) â Input tensor shape at each time step for each sample, excluding dimension of the batch size
and sequence length. Must be consistent with <cite>conv_layout</cite>.
For example, for layout âNCWâ the shape should be (C, W).</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) â Number of output channels.</p></li>
<li><p><strong>i2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Input convolution kernel sizes.</p></li>
<li><p><strong>h2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.</p></li>
<li><p><strong>i2h_pad</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>0</em><em>,</em><em>)</em>) â Pad for input convolution.</p></li>
<li><p><strong>i2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>,</em><em>)</em>) â Input convolution dilate.</p></li>
<li><p><strong>h2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>,</em><em>)</em>) â Recurrent convolution dilate.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the input convolutions.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the input convolutions.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the input convolution bias vectors.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the recurrent convolution bias vectors.</p></li>
<li><p><strong>conv_layout</strong> (<em>str</em><em>, </em><em>default 'NCW'</em>) â Layout for all convolution inputs, outputs and weights. Options are âNCWâ and âNWCâ.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em> or </em><a class="reference internal" href="../block.html#mxnet.gluon.Block" title="mxnet.gluon.Block"><em>gluon.Block</em></a><em>, </em><em>default 'tanh'</em>) â Type of activation function used in c^prime_t.
If argument type is string, itâs equivalent to nn.Activation(act_type=str). See
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.Activation" title="mxnet.ndarray.Activation"><code class="xref py py-func docutils literal notranslate"><span class="pre">Activation()</span></code></a> for available choices.
Alternatively, other activation blocks such as nn.LeakyReLU can be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.Conv1DRNNCell">
<em class="property">class </em><code class="sig-name descname">Conv1DRNNCell</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">i2h_kernel</em>, <em class="sig-param">h2h_kernel</em>, <em class="sig-param">i2h_pad=(0</em>, <em class="sig-param">)</em>, <em class="sig-param">i2h_dilate=(1</em>, <em class="sig-param">)</em>, <em class="sig-param">h2h_dilate=(1</em>, <em class="sig-param">)</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">conv_layout='NCW'</em>, <em class="sig-param">activation='tanh'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/conv_rnn_cell.html#Conv1DRNNCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.Conv1DRNNCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.conv_rnn_cell._ConvRNNCell</span></code></p>
<p>1D Convolutional RNN cell.</p>
<div class="math notranslate nohighlight">
\[h_t = tanh(W_i \ast x_t + R_i \ast h_{t-1} + b_i)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple of int</em>) â Input tensor shape at each time step for each sample, excluding dimension of the batch size
and sequence length. Must be consistent with <cite>conv_layout</cite>.
For example, for layout âNCWâ the shape should be (C, W).</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) â Number of output channels.</p></li>
<li><p><strong>i2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Input convolution kernel sizes.</p></li>
<li><p><strong>h2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.</p></li>
<li><p><strong>i2h_pad</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>0</em><em>,</em><em>)</em>) â Pad for input convolution.</p></li>
<li><p><strong>i2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>,</em><em>)</em>) â Input convolution dilate.</p></li>
<li><p><strong>h2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>,</em><em>)</em>) â Recurrent convolution dilate.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the input convolutions.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the input convolutions.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the input convolution bias vectors.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the recurrent convolution bias vectors.</p></li>
<li><p><strong>conv_layout</strong> (<em>str</em><em>, </em><em>default 'NCW'</em>) â Layout for all convolution inputs, outputs and weights. Options are âNCWâ and âNWCâ.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em> or </em><a class="reference internal" href="../block.html#mxnet.gluon.Block" title="mxnet.gluon.Block"><em>gluon.Block</em></a><em>, </em><em>default 'tanh'</em>) â Type of activation function.
If argument type is string, itâs equivalent to nn.Activation(act_type=str). See
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.Activation" title="mxnet.ndarray.Activation"><code class="xref py py-func docutils literal notranslate"><span class="pre">Activation()</span></code></a> for available choices.
Alternatively, other activation blocks such as nn.LeakyReLU can be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.Conv2DGRUCell">
<em class="property">class </em><code class="sig-name descname">Conv2DGRUCell</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">i2h_kernel</em>, <em class="sig-param">h2h_kernel</em>, <em class="sig-param">i2h_pad=(0</em>, <em class="sig-param">0)</em>, <em class="sig-param">i2h_dilate=(1</em>, <em class="sig-param">1)</em>, <em class="sig-param">h2h_dilate=(1</em>, <em class="sig-param">1)</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">conv_layout='NCHW'</em>, <em class="sig-param">activation='tanh'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/conv_rnn_cell.html#Conv2DGRUCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.Conv2DGRUCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.conv_rnn_cell._ConvGRUCell</span></code></p>
<p>2D Convolutional Gated Rectified Unit (GRU) network cell.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
r_t = \sigma(W_r \ast x_t + R_r \ast h_{t-1} + b_r) \\
z_t = \sigma(W_z \ast x_t + R_z \ast h_{t-1} + b_z) \\
n_t = tanh(W_i \ast x_t + b_i + r_t \circ (R_n \ast h_{t-1} + b_n)) \\
h^\prime_t = (1 - z_t) \circ n_t + z_t \circ h \\
\end{array}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple of int</em>) â Input tensor shape at each time step for each sample, excluding dimension of the batch size
and sequence length. Must be consistent with <cite>conv_layout</cite>.
For example, for layout âNCHWâ the shape should be (C, H, W).</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) â Number of output channels.</p></li>
<li><p><strong>i2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Input convolution kernel sizes.</p></li>
<li><p><strong>h2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.</p></li>
<li><p><strong>i2h_pad</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>0</em><em>, </em><em>0</em><em>)</em>) â Pad for input convolution.</p></li>
<li><p><strong>i2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>)</em>) â Input convolution dilate.</p></li>
<li><p><strong>h2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>)</em>) â Recurrent convolution dilate.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the input convolutions.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the input convolutions.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the input convolution bias vectors.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the recurrent convolution bias vectors.</p></li>
<li><p><strong>conv_layout</strong> (<em>str</em><em>, </em><em>default 'NCHW'</em>) â Layout for all convolution inputs, outputs and weights. Options are âNCHWâ and âNHWCâ.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em> or </em><a class="reference internal" href="../block.html#mxnet.gluon.Block" title="mxnet.gluon.Block"><em>gluon.Block</em></a><em>, </em><em>default 'tanh'</em>) â Type of activation function used in n_t.
If argument type is string, itâs equivalent to nn.Activation(act_type=str). See
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.Activation" title="mxnet.ndarray.Activation"><code class="xref py py-func docutils literal notranslate"><span class="pre">Activation()</span></code></a> for available choices.
Alternatively, other activation blocks such as nn.LeakyReLU can be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.Conv2DLSTMCell">
<em class="property">class </em><code class="sig-name descname">Conv2DLSTMCell</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">i2h_kernel</em>, <em class="sig-param">h2h_kernel</em>, <em class="sig-param">i2h_pad=(0</em>, <em class="sig-param">0)</em>, <em class="sig-param">i2h_dilate=(1</em>, <em class="sig-param">1)</em>, <em class="sig-param">h2h_dilate=(1</em>, <em class="sig-param">1)</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">conv_layout='NCHW'</em>, <em class="sig-param">activation='tanh'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/conv_rnn_cell.html#Conv2DLSTMCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.Conv2DLSTMCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.conv_rnn_cell._ConvLSTMCell</span></code></p>
<p>2D Convolutional LSTM network cell.</p>
<p><a class="reference external" href="https://arxiv.org/abs/1506.04214">âConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcastingâ</a> paper. Xingjian et al. NIPS2015</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
i_t = \sigma(W_i \ast x_t + R_i \ast h_{t-1} + b_i) \\
f_t = \sigma(W_f \ast x_t + R_f \ast h_{t-1} + b_f) \\
o_t = \sigma(W_o \ast x_t + R_o \ast h_{t-1} + b_o) \\
c^\prime_t = tanh(W_c \ast x_t + R_c \ast h_{t-1} + b_c) \\
c_t = f_t \circ c_{t-1} + i_t \circ c^\prime_t \\
h_t = o_t \circ tanh(c_t) \\
\end{array}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple of int</em>) â Input tensor shape at each time step for each sample, excluding dimension of the batch size
and sequence length. Must be consistent with <cite>conv_layout</cite>.
For example, for layout âNCHWâ the shape should be (C, H, W).</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) â Number of output channels.</p></li>
<li><p><strong>i2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Input convolution kernel sizes.</p></li>
<li><p><strong>h2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.</p></li>
<li><p><strong>i2h_pad</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>0</em><em>, </em><em>0</em><em>)</em>) â Pad for input convolution.</p></li>
<li><p><strong>i2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>)</em>) â Input convolution dilate.</p></li>
<li><p><strong>h2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>)</em>) â Recurrent convolution dilate.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the input convolutions.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the input convolutions.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the input convolution bias vectors.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the recurrent convolution bias vectors.</p></li>
<li><p><strong>conv_layout</strong> (<em>str</em><em>, </em><em>default 'NCHW'</em>) â Layout for all convolution inputs, outputs and weights. Options are âNCHWâ and âNHWCâ.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em> or </em><a class="reference internal" href="../block.html#mxnet.gluon.Block" title="mxnet.gluon.Block"><em>gluon.Block</em></a><em>, </em><em>default 'tanh'</em>) â Type of activation function used in c^prime_t.
If argument type is string, itâs equivalent to nn.Activation(act_type=str). See
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.Activation" title="mxnet.ndarray.Activation"><code class="xref py py-func docutils literal notranslate"><span class="pre">Activation()</span></code></a> for available choices.
Alternatively, other activation blocks such as nn.LeakyReLU can be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.Conv2DRNNCell">
<em class="property">class </em><code class="sig-name descname">Conv2DRNNCell</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">i2h_kernel</em>, <em class="sig-param">h2h_kernel</em>, <em class="sig-param">i2h_pad=(0</em>, <em class="sig-param">0)</em>, <em class="sig-param">i2h_dilate=(1</em>, <em class="sig-param">1)</em>, <em class="sig-param">h2h_dilate=(1</em>, <em class="sig-param">1)</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">conv_layout='NCHW'</em>, <em class="sig-param">activation='tanh'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/conv_rnn_cell.html#Conv2DRNNCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.Conv2DRNNCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.conv_rnn_cell._ConvRNNCell</span></code></p>
<p>2D Convolutional RNN cell.</p>
<div class="math notranslate nohighlight">
\[h_t = tanh(W_i \ast x_t + R_i \ast h_{t-1} + b_i)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple of int</em>) â Input tensor shape at each time step for each sample, excluding dimension of the batch size
and sequence length. Must be consistent with <cite>conv_layout</cite>.
For example, for layout âNCHWâ the shape should be (C, H, W).</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) â Number of output channels.</p></li>
<li><p><strong>i2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Input convolution kernel sizes.</p></li>
<li><p><strong>h2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.</p></li>
<li><p><strong>i2h_pad</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>0</em><em>, </em><em>0</em><em>)</em>) â Pad for input convolution.</p></li>
<li><p><strong>i2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>)</em>) â Input convolution dilate.</p></li>
<li><p><strong>h2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>)</em>) â Recurrent convolution dilate.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the input convolutions.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the input convolutions.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the input convolution bias vectors.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the recurrent convolution bias vectors.</p></li>
<li><p><strong>conv_layout</strong> (<em>str</em><em>, </em><em>default 'NCHW'</em>) â Layout for all convolution inputs, outputs and weights. Options are âNCHWâ and âNHWCâ.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em> or </em><a class="reference internal" href="../block.html#mxnet.gluon.Block" title="mxnet.gluon.Block"><em>gluon.Block</em></a><em>, </em><em>default 'tanh'</em>) â Type of activation function.
If argument type is string, itâs equivalent to nn.Activation(act_type=str). See
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.Activation" title="mxnet.ndarray.Activation"><code class="xref py py-func docutils literal notranslate"><span class="pre">Activation()</span></code></a> for available choices.
Alternatively, other activation blocks such as nn.LeakyReLU can be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.Conv3DGRUCell">
<em class="property">class </em><code class="sig-name descname">Conv3DGRUCell</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">i2h_kernel</em>, <em class="sig-param">h2h_kernel</em>, <em class="sig-param">i2h_pad=(0</em>, <em class="sig-param">0</em>, <em class="sig-param">0)</em>, <em class="sig-param">i2h_dilate=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">h2h_dilate=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">conv_layout='NCDHW'</em>, <em class="sig-param">activation='tanh'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/conv_rnn_cell.html#Conv3DGRUCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.Conv3DGRUCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.conv_rnn_cell._ConvGRUCell</span></code></p>
<p>3D Convolutional Gated Rectified Unit (GRU) network cell.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
r_t = \sigma(W_r \ast x_t + R_r \ast h_{t-1} + b_r) \\
z_t = \sigma(W_z \ast x_t + R_z \ast h_{t-1} + b_z) \\
n_t = tanh(W_i \ast x_t + b_i + r_t \circ (R_n \ast h_{t-1} + b_n)) \\
h^\prime_t = (1 - z_t) \circ n_t + z_t \circ h \\
\end{array}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple of int</em>) â Input tensor shape at each time step for each sample, excluding dimension of the batch size
and sequence length. Must be consistent with <cite>conv_layout</cite>.
For example, for layout âNCDHWâ the shape should be (C, D, H, W).</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) â Number of output channels.</p></li>
<li><p><strong>i2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Input convolution kernel sizes.</p></li>
<li><p><strong>h2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.</p></li>
<li><p><strong>i2h_pad</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>0</em><em>, </em><em>0</em><em>, </em><em>0</em><em>)</em>) â Pad for input convolution.</p></li>
<li><p><strong>i2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>, </em><em>1</em><em>)</em>) â Input convolution dilate.</p></li>
<li><p><strong>h2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>, </em><em>1</em><em>)</em>) â Recurrent convolution dilate.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the input convolutions.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the input convolutions.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the input convolution bias vectors.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the recurrent convolution bias vectors.</p></li>
<li><p><strong>conv_layout</strong> (<em>str</em><em>, </em><em>default 'NCDHW'</em>) â Layout for all convolution inputs, outputs and weights. Options are âNCDHWâ and âNDHWCâ.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em> or </em><a class="reference internal" href="../block.html#mxnet.gluon.Block" title="mxnet.gluon.Block"><em>gluon.Block</em></a><em>, </em><em>default 'tanh'</em>) â Type of activation function used in n_t.
If argument type is string, itâs equivalent to nn.Activation(act_type=str). See
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.Activation" title="mxnet.ndarray.Activation"><code class="xref py py-func docutils literal notranslate"><span class="pre">Activation()</span></code></a> for available choices.
Alternatively, other activation blocks such as nn.LeakyReLU can be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.Conv3DLSTMCell">
<em class="property">class </em><code class="sig-name descname">Conv3DLSTMCell</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">i2h_kernel</em>, <em class="sig-param">h2h_kernel</em>, <em class="sig-param">i2h_pad=(0</em>, <em class="sig-param">0</em>, <em class="sig-param">0)</em>, <em class="sig-param">i2h_dilate=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">h2h_dilate=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">conv_layout='NCDHW'</em>, <em class="sig-param">activation='tanh'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/conv_rnn_cell.html#Conv3DLSTMCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.Conv3DLSTMCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.conv_rnn_cell._ConvLSTMCell</span></code></p>
<p>3D Convolutional LSTM network cell.</p>
<p><a class="reference external" href="https://arxiv.org/abs/1506.04214">âConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcastingâ</a> paper. Xingjian et al. NIPS2015</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
i_t = \sigma(W_i \ast x_t + R_i \ast h_{t-1} + b_i) \\
f_t = \sigma(W_f \ast x_t + R_f \ast h_{t-1} + b_f) \\
o_t = \sigma(W_o \ast x_t + R_o \ast h_{t-1} + b_o) \\
c^\prime_t = tanh(W_c \ast x_t + R_c \ast h_{t-1} + b_c) \\
c_t = f_t \circ c_{t-1} + i_t \circ c^\prime_t \\
h_t = o_t \circ tanh(c_t) \\
\end{array}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple of int</em>) â Input tensor shape at each time step for each sample, excluding dimension of the batch size
and sequence length. Must be consistent with <cite>conv_layout</cite>.
For example, for layout âNCDHWâ the shape should be (C, D, H, W).</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) â Number of output channels.</p></li>
<li><p><strong>i2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Input convolution kernel sizes.</p></li>
<li><p><strong>h2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.</p></li>
<li><p><strong>i2h_pad</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>0</em><em>, </em><em>0</em><em>, </em><em>0</em><em>)</em>) â Pad for input convolution.</p></li>
<li><p><strong>i2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>, </em><em>1</em><em>)</em>) â Input convolution dilate.</p></li>
<li><p><strong>h2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>, </em><em>1</em><em>)</em>) â Recurrent convolution dilate.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the input convolutions.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the input convolutions.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the input convolution bias vectors.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the recurrent convolution bias vectors.</p></li>
<li><p><strong>conv_layout</strong> (<em>str</em><em>, </em><em>default 'NCDHW'</em>) â Layout for all convolution inputs, outputs and weights. Options are âNCDHWâ and âNDHWCâ.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em> or </em><a class="reference internal" href="../block.html#mxnet.gluon.Block" title="mxnet.gluon.Block"><em>gluon.Block</em></a><em>, </em><em>default 'tanh'</em>) â Type of activation function used in c^prime_t.
If argument type is string, itâs equivalent to nn.Activation(act_type=str). See
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.Activation" title="mxnet.ndarray.Activation"><code class="xref py py-func docutils literal notranslate"><span class="pre">Activation()</span></code></a> for available choices.
Alternatively, other activation blocks such as nn.LeakyReLU can be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.Conv3DRNNCell">
<em class="property">class </em><code class="sig-name descname">Conv3DRNNCell</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">i2h_kernel</em>, <em class="sig-param">h2h_kernel</em>, <em class="sig-param">i2h_pad=(0</em>, <em class="sig-param">0</em>, <em class="sig-param">0)</em>, <em class="sig-param">i2h_dilate=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">h2h_dilate=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">conv_layout='NCDHW'</em>, <em class="sig-param">activation='tanh'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/conv_rnn_cell.html#Conv3DRNNCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.Conv3DRNNCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.conv_rnn_cell._ConvRNNCell</span></code></p>
<p>3D Convolutional RNN cells</p>
<div class="math notranslate nohighlight">
\[h_t = tanh(W_i \ast x_t + R_i \ast h_{t-1} + b_i)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>tuple of int</em>) â Input tensor shape at each time step for each sample, excluding dimension of the batch size
and sequence length. Must be consistent with <cite>conv_layout</cite>.
For example, for layout âNCDHWâ the shape should be (C, D, H, W).</p></li>
<li><p><strong>hidden_channels</strong> (<em>int</em>) â Number of output channels.</p></li>
<li><p><strong>i2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Input convolution kernel sizes.</p></li>
<li><p><strong>h2h_kernel</strong> (<em>int</em><em> or </em><em>tuple of int</em>) â Recurrent convolution kernel sizes. Only odd-numbered sizes are supported.</p></li>
<li><p><strong>i2h_pad</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>0</em><em>, </em><em>0</em><em>, </em><em>0</em><em>)</em>) â Pad for input convolution.</p></li>
<li><p><strong>i2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>, </em><em>1</em><em>)</em>) â Input convolution dilate.</p></li>
<li><p><strong>h2h_dilate</strong> (<em>int</em><em> or </em><em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>1</em><em>, </em><em>1</em><em>, </em><em>1</em><em>)</em>) â Recurrent convolution dilate.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the input convolutions.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the input convolutions.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the input convolution bias vectors.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default zeros</em>) â Initializer for the recurrent convolution bias vectors.</p></li>
<li><p><strong>conv_layout</strong> (<em>str</em><em>, </em><em>default 'NCDHW'</em>) â Layout for all convolution inputs, outputs and weights. Options are âNCDHWâ and âNDHWCâ.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em> or </em><a class="reference internal" href="../block.html#mxnet.gluon.Block" title="mxnet.gluon.Block"><em>gluon.Block</em></a><em>, </em><em>default 'tanh'</em>) â Type of activation function.
If argument type is string, itâs equivalent to nn.Activation(act_type=str). See
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.Activation" title="mxnet.ndarray.Activation"><code class="xref py py-func docutils literal notranslate"><span class="pre">Activation()</span></code></a> for available choices.
Alternatively, other activation blocks such as nn.LeakyReLU can be used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.DropoutCell">
<em class="property">class </em><code class="sig-name descname">DropoutCell</code><span class="sig-paren">(</span><em class="sig-param">rate</em>, <em class="sig-param">axes=()</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#DropoutCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.HybridRecurrentCell</span></code></p>
<p>Applies dropout on input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rate</strong> (<em>float</em>) â Percentage of elements to drop out, which
is 1 - percentage to retain.</p></li>
<li><p><strong>axes</strong> (<em>tuple of int</em><em>, </em><em>default</em><em> (</em><em>)</em>) â The axes on which dropout mask is shared. If empty, regular dropout is applied.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.apply" title="mxnet.gluon.rnn.DropoutCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.begin_state" title="mxnet.gluon.rnn.DropoutCell.begin_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">begin_state</span></code></a>([batch_size,Â func])</p></td>
<td><p>Initial state for this cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.cast" title="mxnet.gluon.rnn.DropoutCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.collect_params" title="mxnet.gluon.rnn.DropoutCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.export" title="mxnet.gluon.rnn.DropoutCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.forward" title="mxnet.gluon.rnn.DropoutCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs,Â states)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.hybridize" title="mxnet.gluon.rnn.DropoutCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.infer_shape" title="mxnet.gluon.rnn.DropoutCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(*args)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.infer_type" title="mxnet.gluon.rnn.DropoutCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.initialize" title="mxnet.gluon.rnn.DropoutCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.load" title="mxnet.gluon.rnn.DropoutCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.load_dict" title="mxnet.gluon.rnn.DropoutCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.load_parameters" title="mxnet.gluon.rnn.DropoutCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.optimize_for" title="mxnet.gluon.rnn.DropoutCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.register_child" title="mxnet.gluon.rnn.DropoutCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.register_forward_hook" title="mxnet.gluon.rnn.DropoutCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.register_forward_pre_hook" title="mxnet.gluon.rnn.DropoutCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.register_op_hook" title="mxnet.gluon.rnn.DropoutCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.reset" title="mxnet.gluon.rnn.DropoutCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.reset_ctx" title="mxnet.gluon.rnn.DropoutCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.reset_device" title="mxnet.gluon.rnn.DropoutCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.save" title="mxnet.gluon.rnn.DropoutCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.save_parameters" title="mxnet.gluon.rnn.DropoutCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.setattr" title="mxnet.gluon.rnn.DropoutCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.share_parameters" title="mxnet.gluon.rnn.DropoutCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.state_info" title="mxnet.gluon.rnn.DropoutCell.state_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_info</span></code></a>([batch_size])</p></td>
<td><p>shape and layout information of states</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.summary" title="mxnet.gluon.rnn.DropoutCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.unroll" title="mxnet.gluon.rnn.DropoutCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.zero_grad" title="mxnet.gluon.rnn.DropoutCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.params" title="mxnet.gluon.rnn.DropoutCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its childrenâs parameters).</p></td>
</tr>
</tbody>
</table>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>data</strong>: input tensor with shape <cite>(batch_size, size)</cite>.</p></li>
<li><p><strong>states</strong>: a list of recurrent state tensors.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>out</strong>: output tensor with shape <cite>(batch_size, size)</cite>.</p></li>
<li><p><strong>next_states</strong>: returns input <cite>states</cite> directly.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.begin_state">
<code class="sig-name descname">begin_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em>, <em class="sig-param">func=&lt;function zeros&gt;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.begin_state" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initial state for this cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) â <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â Only required for NDArray API. Size of the batch (âNâ in layout)
dimension of input.</p></li>
<li><p><strong>**kwargs</strong> â Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states</strong> â Starting states for the first RNN step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested list of Symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#DropoutCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.begin_state" title="mxnet.gluon.rnn.DropoutCell.begin_state"><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></a></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.unroll" title="mxnet.gluon.rnn.DropoutCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its
childrenâs parameters).</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.forward" title="mxnet.gluon.rnn.DropoutCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.DropoutCell.forward" title="mxnet.gluon.rnn.DropoutCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.state_info">
<code class="sig-name descname">state_info</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#DropoutCell.state_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.state_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#DropoutCell.unroll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.DropoutCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.DropoutCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.GRU">
<em class="property">class </em><code class="sig-name descname">GRU</code><span class="sig-paren">(</span><em class="sig-param">hidden_size</em>, <em class="sig-param">num_layers=1</em>, <em class="sig-param">layout='TNC'</em>, <em class="sig-param">dropout=0</em>, <em class="sig-param">bidirectional=False</em>, <em class="sig-param">input_size=0</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">dtype='float32'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_layer.html#GRU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.GRU" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_layer._RNNLayer</span></code></p>
<p>Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.
Note: this is an implementation of the cuDNN version of GRUs
(slight modification compared to Cho et al. 2014; the reset gate <span class="math notranslate nohighlight">\(r_t\)</span>
is applied after matrix multiplication).</p>
<p>For each element in the input sequence, each layer computes the following
function:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
r_t = sigmoid(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\
i_t = sigmoid(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\
n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)} + b_{hn})) \\
h_t = (1 - i_t) * n_t + i_t * h_{(t-1)} \\
\end{array}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(h_t\)</span> is the hidden state at time <cite>t</cite>, <span class="math notranslate nohighlight">\(x_t\)</span> is the hidden
state of the previous layer at time <cite>t</cite> or <span class="math notranslate nohighlight">\(input_t\)</span> for the first layer,
and <span class="math notranslate nohighlight">\(r_t\)</span>, <span class="math notranslate nohighlight">\(i_t\)</span>, <span class="math notranslate nohighlight">\(n_t\)</span> are the reset, input, and new gates, respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>) â The number of features in the hidden state h</p></li>
<li><p><strong>num_layers</strong> (<em>int</em><em>, </em><em>default 1</em>) â Number of recurrent layers.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>default 'TNC'</em>) â The format of input and output tensors. T, N and C stand for
sequence length, batch size, and feature dimensions respectively.</p></li>
<li><p><strong>dropout</strong> (<em>float</em><em>, </em><em>default 0</em>) â If non-zero, introduces a dropout layer on the outputs of each
RNN layer except the last layer</p></li>
<li><p><strong>bidirectional</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, becomes a bidirectional RNN.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the linear
transformation of the inputs.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the bias vector.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the bias vector.</p></li>
<li><p><strong>dtype</strong> (<em>str</em><em>, </em><em>default 'float32'</em>) â Type to initialize the parameters and default states to</p></li>
<li><p><strong>input_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â The number of expected features in the input x.
If not specified, it will be inferred from input.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>data</strong>: input tensor with shape <cite>(sequence_length, batch_size, input_size)</cite>
when <cite>layout</cite> is âTNCâ. For other layouts, dimensions are permuted accordingly
using transpose() operator which adds performance overhead. Consider creating
batches in TNC layout during data batching step.</p></li>
<li><p><strong>states</strong>: initial recurrent state tensor with shape
<cite>(num_layers, batch_size, num_hidden)</cite>. If <cite>bidirectional</cite> is True,
shape will instead be <cite>(2*num_layers, batch_size, num_hidden)</cite>. If
<cite>states</cite> is None, zeros will be used as default begin states.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>out</strong>: output tensor with shape <cite>(sequence_length, batch_size, num_hidden)</cite>
when <cite>layout</cite> is âTNCâ. If <cite>bidirectional</cite> is True, output shape will instead
be <cite>(sequence_length, batch_size, 2*num_hidden)</cite></p></li>
<li><p><strong>out_states</strong>: output recurrent state tensor with the same shape as <cite>states</cite>.
If <cite>states</cite> is None <cite>out_states</cite> will not be returned.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># by default zeros are used as begin state</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># manually specify begin state.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h0</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.GRUCell">
<em class="property">class </em><code class="sig-name descname">GRUCell</code><span class="sig-paren">(</span><em class="sig-param">hidden_size</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">input_size=0</em>, <em class="sig-param">activation='tanh'</em>, <em class="sig-param">recurrent_activation='sigmoid'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#GRUCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.HybridRecurrentCell</span></code></p>
<p>Gated Rectified Unit (GRU) network cell.
Note: this is an implementation of the cuDNN version of GRUs
(slight modification compared to Cho et al. 2014; the reset gate <span class="math notranslate nohighlight">\(r_t\)</span>
is applied after matrix multiplication).</p>
<p>Each call computes the following function:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
r_t = sigmoid(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\
i_t = sigmoid(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\
n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)} + b_{hn})) \\
h_t = (1 - i_t) * n_t + i_t * h_{(t-1)} \\
\end{array}\end{split}\]</div>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.apply" title="mxnet.gluon.rnn.GRUCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.begin_state" title="mxnet.gluon.rnn.GRUCell.begin_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">begin_state</span></code></a>([batch_size,Â func])</p></td>
<td><p>Initial state for this cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.cast" title="mxnet.gluon.rnn.GRUCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.collect_params" title="mxnet.gluon.rnn.GRUCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.export" title="mxnet.gluon.rnn.GRUCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.forward" title="mxnet.gluon.rnn.GRUCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs,Â states)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.hybridize" title="mxnet.gluon.rnn.GRUCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.infer_shape" title="mxnet.gluon.rnn.GRUCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(i,Â x,Â is_bidirect)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.infer_type" title="mxnet.gluon.rnn.GRUCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.initialize" title="mxnet.gluon.rnn.GRUCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.load" title="mxnet.gluon.rnn.GRUCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.load_dict" title="mxnet.gluon.rnn.GRUCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.load_parameters" title="mxnet.gluon.rnn.GRUCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.optimize_for" title="mxnet.gluon.rnn.GRUCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.register_child" title="mxnet.gluon.rnn.GRUCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.register_forward_hook" title="mxnet.gluon.rnn.GRUCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.register_forward_pre_hook" title="mxnet.gluon.rnn.GRUCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.register_op_hook" title="mxnet.gluon.rnn.GRUCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.reset" title="mxnet.gluon.rnn.GRUCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.reset_ctx" title="mxnet.gluon.rnn.GRUCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.reset_device" title="mxnet.gluon.rnn.GRUCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.save" title="mxnet.gluon.rnn.GRUCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.save_parameters" title="mxnet.gluon.rnn.GRUCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.setattr" title="mxnet.gluon.rnn.GRUCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.share_parameters" title="mxnet.gluon.rnn.GRUCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.state_info" title="mxnet.gluon.rnn.GRUCell.state_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_info</span></code></a>([batch_size])</p></td>
<td><p>shape and layout information of states</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.summary" title="mxnet.gluon.rnn.GRUCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.unroll" title="mxnet.gluon.rnn.GRUCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.zero_grad" title="mxnet.gluon.rnn.GRUCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.params" title="mxnet.gluon.rnn.GRUCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its childrenâs parameters).</p></td>
</tr>
</tbody>
</table>
<p>where <span class="math notranslate nohighlight">\(h_t\)</span> is the hidden state at time <cite>t</cite>, <span class="math notranslate nohighlight">\(x_t\)</span> is the hidden
state of the previous layer at time <cite>t</cite> or <span class="math notranslate nohighlight">\(input_t\)</span> for the first layer,
and <span class="math notranslate nohighlight">\(r_t\)</span>, <span class="math notranslate nohighlight">\(i_t\)</span>, <span class="math notranslate nohighlight">\(n_t\)</span> are the reset, input, and new gates, respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>) â Number of units in output symbol.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the linear
transformation of the inputs.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default 'zeros'</em>) â Initializer for the bias vector.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default 'zeros'</em>) â Initializer for the bias vector.</p></li>
<li><p><strong>input_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â The number of expected features in the input x.
If not specified, it will be inferred from input.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>default 'tanh'</em>) â Activation type to use. See nd/symbol Activation
for supported types.</p></li>
<li><p><strong>recurrent_activation</strong> (<em>str</em><em>, </em><em>default 'sigmoid'</em>) â Activation type to use for the recurrent step. See nd/symbol Activation
for supported types.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>data</strong>: input tensor with shape <cite>(batch_size, input_size)</cite>.</p></li>
<li><p><strong>states</strong>: a list of one initial recurrent state tensor with shape
<cite>(batch_size, num_hidden)</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>out</strong>: output tensor with shape <cite>(batch_size, num_hidden)</cite>.</p></li>
<li><p><strong>next_states</strong>: a list of one output recurrent state tensor with the
same shape as <cite>states</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.begin_state">
<code class="sig-name descname">begin_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em>, <em class="sig-param">func=&lt;function zeros&gt;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.begin_state" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initial state for this cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) â <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â Only required for NDArray API. Size of the batch (âNâ in layout)
dimension of input.</p></li>
<li><p><strong>**kwargs</strong> â Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states</strong> â Starting states for the first RNN step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested list of Symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#GRUCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.begin_state" title="mxnet.gluon.rnn.GRUCell.begin_state"><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></a></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.unroll" title="mxnet.gluon.rnn.GRUCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">i</em>, <em class="sig-param">x</em>, <em class="sig-param">is_bidirect</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#GRUCell.infer_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its
childrenâs parameters).</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.forward" title="mxnet.gluon.rnn.GRUCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.GRUCell.forward" title="mxnet.gluon.rnn.GRUCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.state_info">
<code class="sig-name descname">state_info</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#GRUCell.state_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.state_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.GRUCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.GRUCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell">
<em class="property">class </em><code class="sig-name descname">HybridRecurrentCell</code><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#HybridRecurrentCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.RecurrentCell</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.HybridBlock</span></code></p>
<p>HybridRecurrentCell supports hybridize.</p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.apply" title="mxnet.gluon.rnn.HybridRecurrentCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.begin_state" title="mxnet.gluon.rnn.HybridRecurrentCell.begin_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">begin_state</span></code></a>([batch_size,Â func])</p></td>
<td><p>Initial state for this cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.cast" title="mxnet.gluon.rnn.HybridRecurrentCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.collect_params" title="mxnet.gluon.rnn.HybridRecurrentCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.export" title="mxnet.gluon.rnn.HybridRecurrentCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.forward" title="mxnet.gluon.rnn.HybridRecurrentCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(x,Â *args,Â **kwargs)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.hybridize" title="mxnet.gluon.rnn.HybridRecurrentCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.infer_shape" title="mxnet.gluon.rnn.HybridRecurrentCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(*args)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.infer_type" title="mxnet.gluon.rnn.HybridRecurrentCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.initialize" title="mxnet.gluon.rnn.HybridRecurrentCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.load" title="mxnet.gluon.rnn.HybridRecurrentCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.load_dict" title="mxnet.gluon.rnn.HybridRecurrentCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.load_parameters" title="mxnet.gluon.rnn.HybridRecurrentCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.optimize_for" title="mxnet.gluon.rnn.HybridRecurrentCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.register_child" title="mxnet.gluon.rnn.HybridRecurrentCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.register_forward_hook" title="mxnet.gluon.rnn.HybridRecurrentCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.register_forward_pre_hook" title="mxnet.gluon.rnn.HybridRecurrentCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.register_op_hook" title="mxnet.gluon.rnn.HybridRecurrentCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.reset" title="mxnet.gluon.rnn.HybridRecurrentCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.reset_ctx" title="mxnet.gluon.rnn.HybridRecurrentCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.reset_device" title="mxnet.gluon.rnn.HybridRecurrentCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.save" title="mxnet.gluon.rnn.HybridRecurrentCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.save_parameters" title="mxnet.gluon.rnn.HybridRecurrentCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.setattr" title="mxnet.gluon.rnn.HybridRecurrentCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.share_parameters" title="mxnet.gluon.rnn.HybridRecurrentCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.state_info" title="mxnet.gluon.rnn.HybridRecurrentCell.state_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_info</span></code></a>([batch_size])</p></td>
<td><p>shape and layout information of states</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.summary" title="mxnet.gluon.rnn.HybridRecurrentCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.unroll" title="mxnet.gluon.rnn.HybridRecurrentCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.zero_grad" title="mxnet.gluon.rnn.HybridRecurrentCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.params" title="mxnet.gluon.rnn.HybridRecurrentCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its childrenâs parameters).</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.begin_state">
<code class="sig-name descname">begin_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em>, <em class="sig-param">func=&lt;function zeros&gt;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.begin_state" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initial state for this cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) â <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â Only required for NDArray API. Size of the batch (âNâ in layout)
dimension of input.</p></li>
<li><p><strong>**kwargs</strong> â Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states</strong> â Starting states for the first RNN step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested list of Symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#HybridRecurrentCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.begin_state" title="mxnet.gluon.rnn.HybridRecurrentCell.begin_state"><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></a></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.unroll" title="mxnet.gluon.rnn.HybridRecurrentCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its
childrenâs parameters).</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.forward" title="mxnet.gluon.rnn.HybridRecurrentCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.HybridRecurrentCell.forward" title="mxnet.gluon.rnn.HybridRecurrentCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.state_info">
<code class="sig-name descname">state_info</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.state_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridRecurrentCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridRecurrentCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell">
<em class="property">class </em><code class="sig-name descname">HybridSequentialRNNCell</code><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#HybridSequentialRNNCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.HybridRecurrentCell</span></code></p>
<p>Sequentially stacking multiple HybridRNN cells.</p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.add" title="mxnet.gluon.rnn.HybridSequentialRNNCell.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a>(cell)</p></td>
<td><p>Appends a cell into the stack.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.apply" title="mxnet.gluon.rnn.HybridSequentialRNNCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.begin_state" title="mxnet.gluon.rnn.HybridSequentialRNNCell.begin_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">begin_state</span></code></a>(**kwargs)</p></td>
<td><p>Initial state for this cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.cast" title="mxnet.gluon.rnn.HybridSequentialRNNCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.collect_params" title="mxnet.gluon.rnn.HybridSequentialRNNCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.export" title="mxnet.gluon.rnn.HybridSequentialRNNCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.forward" title="mxnet.gluon.rnn.HybridSequentialRNNCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs,Â states)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.hybridize" title="mxnet.gluon.rnn.HybridSequentialRNNCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.infer_shape" title="mxnet.gluon.rnn.HybridSequentialRNNCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(_,Â x,Â is_bidirect)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.infer_type" title="mxnet.gluon.rnn.HybridSequentialRNNCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.initialize" title="mxnet.gluon.rnn.HybridSequentialRNNCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.load" title="mxnet.gluon.rnn.HybridSequentialRNNCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.load_dict" title="mxnet.gluon.rnn.HybridSequentialRNNCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.load_parameters" title="mxnet.gluon.rnn.HybridSequentialRNNCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.optimize_for" title="mxnet.gluon.rnn.HybridSequentialRNNCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.register_child" title="mxnet.gluon.rnn.HybridSequentialRNNCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.register_forward_hook" title="mxnet.gluon.rnn.HybridSequentialRNNCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.register_forward_pre_hook" title="mxnet.gluon.rnn.HybridSequentialRNNCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.register_op_hook" title="mxnet.gluon.rnn.HybridSequentialRNNCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.reset" title="mxnet.gluon.rnn.HybridSequentialRNNCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.reset_ctx" title="mxnet.gluon.rnn.HybridSequentialRNNCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.reset_device" title="mxnet.gluon.rnn.HybridSequentialRNNCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.save" title="mxnet.gluon.rnn.HybridSequentialRNNCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.save_parameters" title="mxnet.gluon.rnn.HybridSequentialRNNCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.setattr" title="mxnet.gluon.rnn.HybridSequentialRNNCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.share_parameters" title="mxnet.gluon.rnn.HybridSequentialRNNCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.state_info" title="mxnet.gluon.rnn.HybridSequentialRNNCell.state_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_info</span></code></a>([batch_size])</p></td>
<td><p>shape and layout information of states</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.summary" title="mxnet.gluon.rnn.HybridSequentialRNNCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.unroll" title="mxnet.gluon.rnn.HybridSequentialRNNCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.zero_grad" title="mxnet.gluon.rnn.HybridSequentialRNNCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.params" title="mxnet.gluon.rnn.HybridSequentialRNNCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its childrenâs parameters).</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.add">
<code class="sig-name descname">add</code><span class="sig-paren">(</span><em class="sig-param">cell</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#HybridSequentialRNNCell.add"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.add" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Appends a cell into the stack.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>cell</strong> (<a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell" title="mxnet.gluon.rnn.RecurrentCell"><em>RecurrentCell</em></a>) â The cell to add.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.begin_state">
<code class="sig-name descname">begin_state</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#HybridSequentialRNNCell.begin_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.begin_state" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initial state for this cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) â <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â Only required for NDArray API. Size of the batch (âNâ in layout)
dimension of input.</p></li>
<li><p><strong>**kwargs</strong> â Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states</strong> â Starting states for the first RNN step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested list of Symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#HybridSequentialRNNCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.begin_state" title="mxnet.gluon.rnn.HybridSequentialRNNCell.begin_state"><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></a></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.unroll" title="mxnet.gluon.rnn.HybridSequentialRNNCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">_</em>, <em class="sig-param">x</em>, <em class="sig-param">is_bidirect</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#HybridSequentialRNNCell.infer_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its
childrenâs parameters).</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.forward" title="mxnet.gluon.rnn.HybridSequentialRNNCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.forward" title="mxnet.gluon.rnn.HybridSequentialRNNCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.state_info">
<code class="sig-name descname">state_info</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#HybridSequentialRNNCell.state_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.state_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#HybridSequentialRNNCell.unroll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.HybridSequentialRNNCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.HybridSequentialRNNCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.LSTM">
<em class="property">class </em><code class="sig-name descname">LSTM</code><span class="sig-paren">(</span><em class="sig-param">hidden_size</em>, <em class="sig-param">num_layers=1</em>, <em class="sig-param">layout='TNC'</em>, <em class="sig-param">dropout=0</em>, <em class="sig-param">bidirectional=False</em>, <em class="sig-param">input_size=0</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">projection_size=None</em>, <em class="sig-param">h2r_weight_initializer=None</em>, <em class="sig-param">state_clip_min=None</em>, <em class="sig-param">state_clip_max=None</em>, <em class="sig-param">state_clip_nan=False</em>, <em class="sig-param">dtype='float32'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_layer.html#LSTM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.LSTM" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_layer._RNNLayer</span></code></p>
<p>Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.</p>
<p>For each element in the input sequence, each layer computes the following
function:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
i_t = sigmoid(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\
f_t = sigmoid(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\
g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hc} h_{(t-1)} + b_{hg}) \\
o_t = sigmoid(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\
c_t = f_t * c_{(t-1)} + i_t * g_t \\
h_t = o_t * \tanh(c_t)
\end{array}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(h_t\)</span> is the hidden state at time <cite>t</cite>, <span class="math notranslate nohighlight">\(c_t\)</span> is the
cell state at time <cite>t</cite>, <span class="math notranslate nohighlight">\(x_t\)</span> is the hidden state of the previous
layer at time <cite>t</cite> or <span class="math notranslate nohighlight">\(input_t\)</span> for the first layer, and <span class="math notranslate nohighlight">\(i_t\)</span>,
<span class="math notranslate nohighlight">\(f_t\)</span>, <span class="math notranslate nohighlight">\(g_t\)</span>, <span class="math notranslate nohighlight">\(o_t\)</span> are the input, forget, cell, and
out gates, respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>) â The number of features in the hidden state h.</p></li>
<li><p><strong>num_layers</strong> (<em>int</em><em>, </em><em>default 1</em>) â Number of recurrent layers.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>default 'TNC'</em>) â The format of input and output tensors. T, N and C stand for
sequence length, batch size, and feature dimensions respectively.</p></li>
<li><p><strong>dropout</strong> (<em>float</em><em>, </em><em>default 0</em>) â If non-zero, introduces a dropout layer on the outputs of each
RNN layer except the last layer.</p></li>
<li><p><strong>bidirectional</strong> (<em>bool</em><em>, </em><em>default False</em>) â If <cite>True</cite>, becomes a bidirectional RNN.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the linear
transformation of the inputs.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default 'lstmbias'</em>) â Initializer for the bias vector. By default, bias for the forget
gate is initialized to 1 while all other biases are initialized
to zero.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the bias vector.</p></li>
<li><p><strong>projection_size</strong> (<em>int</em><em>, </em><em>default None</em>) â The number of features after projection.</p></li>
<li><p><strong>h2r_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default None</em>) â Initializer for the projected recurrent weights matrix, used for the linear
transformation of the recurrent state to the projected space.</p></li>
<li><p><strong>state_clip_min</strong> (<em>float</em><em> or </em><em>None</em><em>, </em><em>default None</em>) â Minimum clip value of LSTM states. This option must be used together with
state_clip_max. If None, clipping is not applied.</p></li>
<li><p><strong>state_clip_max</strong> (<em>float</em><em> or </em><em>None</em><em>, </em><em>default None</em>) â Maximum clip value of LSTM states. This option must be used together with
state_clip_min. If None, clipping is not applied.</p></li>
<li><p><strong>state_clip_nan</strong> (<em>boolean</em><em>, </em><em>default False</em>) â Whether to stop NaN from propagating in state by clipping it to min/max.
If the clipping range is not specified, this option is ignored.</p></li>
<li><p><strong>dtype</strong> (<em>str</em><em>, </em><em>default 'float32'</em>) â Type to initialize the parameters and default states to</p></li>
<li><p><strong>input_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â The number of expected features in the input x.
If not specified, it will be inferred from input.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>data</strong>: input tensor with shape <cite>(sequence_length, batch_size, input_size)</cite>
when <cite>layout</cite> is âTNCâ. For other layouts, dimensions are permuted accordingly
using transpose() operator which adds performance overhead. Consider creating
batches in TNC layout during data batching step.</p></li>
<li><p><strong>states</strong>: a list of two initial recurrent state tensors. Each has shape
<cite>(num_layers, batch_size, num_hidden)</cite>. If <cite>bidirectional</cite> is True,
shape will instead be <cite>(2*num_layers, batch_size, num_hidden)</cite>. If
<cite>states</cite> is None, zeros will be used as default begin states.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>out</strong>: output tensor with shape <cite>(sequence_length, batch_size, num_hidden)</cite>
when <cite>layout</cite> is âTNCâ. If <cite>bidirectional</cite> is True, output shape will instead
be <cite>(sequence_length, batch_size, 2*num_hidden)</cite></p></li>
<li><p><strong>out_states</strong>: a list of two output recurrent state tensors with the same
shape as in <cite>states</cite>. If <cite>states</cite> is None <cite>out_states</cite> will not be returned.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># by default zeros are used as begin state</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># manually specify begin state.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h0</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c0</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">[</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.LSTMCell">
<em class="property">class </em><code class="sig-name descname">LSTMCell</code><span class="sig-paren">(</span><em class="sig-param">hidden_size</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">input_size=0</em>, <em class="sig-param">activation='tanh'</em>, <em class="sig-param">recurrent_activation='sigmoid'</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#LSTMCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.HybridRecurrentCell</span></code></p>
<p>Long-Short Term Memory (LSTM) network cell.</p>
<p>Each call computes the following function:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
i_t = sigmoid(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\
f_t = sigmoid(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\
g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hc} h_{(t-1)} + b_{hg}) \\
o_t = sigmoid(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\
c_t = f_t * c_{(t-1)} + i_t * g_t \\
h_t = o_t * \tanh(c_t)
\end{array}\end{split}\]</div>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.apply" title="mxnet.gluon.rnn.LSTMCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.begin_state" title="mxnet.gluon.rnn.LSTMCell.begin_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">begin_state</span></code></a>([batch_size,Â func])</p></td>
<td><p>Initial state for this cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.cast" title="mxnet.gluon.rnn.LSTMCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.collect_params" title="mxnet.gluon.rnn.LSTMCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.export" title="mxnet.gluon.rnn.LSTMCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.forward" title="mxnet.gluon.rnn.LSTMCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs,Â states)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.hybridize" title="mxnet.gluon.rnn.LSTMCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.infer_shape" title="mxnet.gluon.rnn.LSTMCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(i,Â x,Â is_bidirect)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.infer_type" title="mxnet.gluon.rnn.LSTMCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.initialize" title="mxnet.gluon.rnn.LSTMCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.load" title="mxnet.gluon.rnn.LSTMCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.load_dict" title="mxnet.gluon.rnn.LSTMCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.load_parameters" title="mxnet.gluon.rnn.LSTMCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.optimize_for" title="mxnet.gluon.rnn.LSTMCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.register_child" title="mxnet.gluon.rnn.LSTMCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.register_forward_hook" title="mxnet.gluon.rnn.LSTMCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.register_forward_pre_hook" title="mxnet.gluon.rnn.LSTMCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.register_op_hook" title="mxnet.gluon.rnn.LSTMCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.reset" title="mxnet.gluon.rnn.LSTMCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.reset_ctx" title="mxnet.gluon.rnn.LSTMCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.reset_device" title="mxnet.gluon.rnn.LSTMCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.save" title="mxnet.gluon.rnn.LSTMCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.save_parameters" title="mxnet.gluon.rnn.LSTMCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.setattr" title="mxnet.gluon.rnn.LSTMCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.share_parameters" title="mxnet.gluon.rnn.LSTMCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.state_info" title="mxnet.gluon.rnn.LSTMCell.state_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_info</span></code></a>([batch_size])</p></td>
<td><p>shape and layout information of states</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.summary" title="mxnet.gluon.rnn.LSTMCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.unroll" title="mxnet.gluon.rnn.LSTMCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.zero_grad" title="mxnet.gluon.rnn.LSTMCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.params" title="mxnet.gluon.rnn.LSTMCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its childrenâs parameters).</p></td>
</tr>
</tbody>
</table>
<p>where <span class="math notranslate nohighlight">\(h_t\)</span> is the hidden state at time <cite>t</cite>, <span class="math notranslate nohighlight">\(c_t\)</span> is the
cell state at time <cite>t</cite>, <span class="math notranslate nohighlight">\(x_t\)</span> is the hidden state of the previous
layer at time <cite>t</cite> or <span class="math notranslate nohighlight">\(input_t\)</span> for the first layer, and <span class="math notranslate nohighlight">\(i_t\)</span>,
<span class="math notranslate nohighlight">\(f_t\)</span>, <span class="math notranslate nohighlight">\(g_t\)</span>, <span class="math notranslate nohighlight">\(o_t\)</span> are the input, forget, cell, and
out gates, respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>) â Number of units in output symbol.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the linear
transformation of the inputs.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default 'zeros'</em>) â Initializer for the bias vector.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default 'zeros'</em>) â Initializer for the bias vector.</p></li>
<li><p><strong>input_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â The number of expected features in the input x.
If not specified, it will be inferred from input.</p></li>
<li><p><strong>activation</strong> (<em>str</em><em>, </em><em>default 'tanh'</em>) â Activation type to use. See nd/symbol Activation
for supported types.</p></li>
<li><p><strong>recurrent_activation</strong> (<em>str</em><em>, </em><em>default 'sigmoid'</em>) â Activation type to use for the recurrent step. See nd/symbol Activation
for supported types.</p></li>
<li><p><strong>Inputs</strong> â <ul>
<li><p><strong>data</strong>: input tensor with shape <cite>(batch_size, input_size)</cite>.</p></li>
<li><p><strong>states</strong>: a list of two initial recurrent state tensors. Each has shape
<cite>(batch_size, num_hidden)</cite>.</p></li>
</ul>
</p></li>
<li><p><strong>Outputs</strong> â <ul>
<li><p><strong>out</strong>: output tensor with shape <cite>(batch_size, num_hidden)</cite>.</p></li>
<li><p><strong>next_states</strong>: a list of two output recurrent state tensors. Each has
the same shape as <cite>states</cite>.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.begin_state">
<code class="sig-name descname">begin_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em>, <em class="sig-param">func=&lt;function zeros&gt;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.begin_state" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initial state for this cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) â <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â Only required for NDArray API. Size of the batch (âNâ in layout)
dimension of input.</p></li>
<li><p><strong>**kwargs</strong> â Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states</strong> â Starting states for the first RNN step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested list of Symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#LSTMCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.begin_state" title="mxnet.gluon.rnn.LSTMCell.begin_state"><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></a></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.unroll" title="mxnet.gluon.rnn.LSTMCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">i</em>, <em class="sig-param">x</em>, <em class="sig-param">is_bidirect</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#LSTMCell.infer_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its
childrenâs parameters).</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.forward" title="mxnet.gluon.rnn.LSTMCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.LSTMCell.forward" title="mxnet.gluon.rnn.LSTMCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.state_info">
<code class="sig-name descname">state_info</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#LSTMCell.state_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.state_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.LSTMPCell">
<em class="property">class </em><code class="sig-name descname">LSTMPCell</code><span class="sig-paren">(</span><em class="sig-param">hidden_size</em>, <em class="sig-param">projection_size</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">h2r_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">input_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#LSTMPCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.HybridRecurrentCell</span></code></p>
<p>Long-Short Term Memory Projected (LSTMP) network cell.
(<a class="reference external" href="https://arxiv.org/abs/1402.1128">https://arxiv.org/abs/1402.1128</a>)</p>
<p>Each call computes the following function:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{ll}
i_t = sigmoid(W_{ii} x_t + b_{ii} + W_{ri} r_{(t-1)} + b_{ri}) \\
f_t = sigmoid(W_{if} x_t + b_{if} + W_{rf} r_{(t-1)} + b_{rf}) \\
g_t = \tanh(W_{ig} x_t + b_{ig} + W_{rc} r_{(t-1)} + b_{rg}) \\
o_t = sigmoid(W_{io} x_t + b_{io} + W_{ro} r_{(t-1)} + b_{ro}) \\
c_t = f_t * c_{(t-1)} + i_t * g_t \\
h_t = o_t * \tanh(c_t) \\
r_t = W_{hr} h_t
\end{array}\end{split}\]</div>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.apply" title="mxnet.gluon.rnn.LSTMPCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.begin_state" title="mxnet.gluon.rnn.LSTMPCell.begin_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">begin_state</span></code></a>([batch_size,Â func])</p></td>
<td><p>Initial state for this cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.cast" title="mxnet.gluon.rnn.LSTMPCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.collect_params" title="mxnet.gluon.rnn.LSTMPCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.export" title="mxnet.gluon.rnn.LSTMPCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.forward" title="mxnet.gluon.rnn.LSTMPCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs,Â states)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.hybridize" title="mxnet.gluon.rnn.LSTMPCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.infer_shape" title="mxnet.gluon.rnn.LSTMPCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(i,Â x,Â is_bidirect)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.infer_type" title="mxnet.gluon.rnn.LSTMPCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.initialize" title="mxnet.gluon.rnn.LSTMPCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.load" title="mxnet.gluon.rnn.LSTMPCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.load_dict" title="mxnet.gluon.rnn.LSTMPCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.load_parameters" title="mxnet.gluon.rnn.LSTMPCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.optimize_for" title="mxnet.gluon.rnn.LSTMPCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.register_child" title="mxnet.gluon.rnn.LSTMPCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.register_forward_hook" title="mxnet.gluon.rnn.LSTMPCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.register_forward_pre_hook" title="mxnet.gluon.rnn.LSTMPCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.register_op_hook" title="mxnet.gluon.rnn.LSTMPCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.reset" title="mxnet.gluon.rnn.LSTMPCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.reset_ctx" title="mxnet.gluon.rnn.LSTMPCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.reset_device" title="mxnet.gluon.rnn.LSTMPCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.save" title="mxnet.gluon.rnn.LSTMPCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.save_parameters" title="mxnet.gluon.rnn.LSTMPCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.setattr" title="mxnet.gluon.rnn.LSTMPCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.share_parameters" title="mxnet.gluon.rnn.LSTMPCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.state_info" title="mxnet.gluon.rnn.LSTMPCell.state_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_info</span></code></a>([batch_size])</p></td>
<td><p>shape and layout information of states</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.summary" title="mxnet.gluon.rnn.LSTMPCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.unroll" title="mxnet.gluon.rnn.LSTMPCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.zero_grad" title="mxnet.gluon.rnn.LSTMPCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.params" title="mxnet.gluon.rnn.LSTMPCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its childrenâs parameters).</p></td>
</tr>
</tbody>
</table>
<p>where <span class="math notranslate nohighlight">\(r_t\)</span> is the projected recurrent activation at time <cite>t</cite>,
<span class="math notranslate nohighlight">\(h_t\)</span> is the hidden state at time <cite>t</cite>, <span class="math notranslate nohighlight">\(c_t\)</span> is the
cell state at time <cite>t</cite>, <span class="math notranslate nohighlight">\(x_t\)</span> is the input at time <cite>t</cite>, and <span class="math notranslate nohighlight">\(i_t\)</span>,
<span class="math notranslate nohighlight">\(f_t\)</span>, <span class="math notranslate nohighlight">\(g_t\)</span>, <span class="math notranslate nohighlight">\(o_t\)</span> are the input, forget, cell, and
out gates, respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>) â Number of units in cell state symbol.</p></li>
<li><p><strong>projection_size</strong> (<em>int</em>) â Number of units in output symbol.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the linear
transformation of the inputs.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the linear
transformation of the hidden state.</p></li>
<li><p><strong>h2r_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the projection weights matrix, used for the linear
transformation of the recurrent state.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default 'lstmbias'</em>) â Initializer for the bias vector. By default, bias for the forget
gate is initialized to 1 while all other biases are initialized
to zero.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the bias vector.</p></li>
<li><p><strong>Inputs</strong> â <ul>
<li><p><strong>data</strong>: input tensor with shape <cite>(batch_size, input_size)</cite>.</p></li>
<li><p><strong>states</strong>: a list of two initial recurrent state tensors, with shape
<cite>(batch_size, projection_size)</cite> and <cite>(batch_size, hidden_size)</cite> respectively.</p></li>
</ul>
</p></li>
<li><p><strong>Outputs</strong> â <ul>
<li><p><strong>out</strong>: output tensor with shape <cite>(batch_size, num_hidden)</cite>.</p></li>
<li><p><strong>next_states</strong>: a list of two output recurrent state tensors. Each has
the same shape as <cite>states</cite>.</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.begin_state">
<code class="sig-name descname">begin_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em>, <em class="sig-param">func=&lt;function zeros&gt;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.begin_state" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initial state for this cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) â <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â Only required for NDArray API. Size of the batch (âNâ in layout)
dimension of input.</p></li>
<li><p><strong>**kwargs</strong> â Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states</strong> â Starting states for the first RNN step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested list of Symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#LSTMPCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.begin_state" title="mxnet.gluon.rnn.LSTMPCell.begin_state"><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></a></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.unroll" title="mxnet.gluon.rnn.LSTMPCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">i</em>, <em class="sig-param">x</em>, <em class="sig-param">is_bidirect</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#LSTMPCell.infer_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its
childrenâs parameters).</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.forward" title="mxnet.gluon.rnn.LSTMPCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.LSTMPCell.forward" title="mxnet.gluon.rnn.LSTMPCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.state_info">
<code class="sig-name descname">state_info</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#LSTMPCell.state_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.state_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.LSTMPCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.LSTMPCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.ModifierCell">
<em class="property">class </em><code class="sig-name descname">ModifierCell</code><span class="sig-paren">(</span><em class="sig-param">base_cell</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ModifierCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.HybridRecurrentCell</span></code></p>
<p>Base class for modifier cells. A modifier
cell takes a base cell, apply modifications
on it (e.g. Zoneout), and returns a new cell.</p>
<p>After applying modifiers the base cell should
no longer be called directly. The modifier cell
should be used instead.</p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.apply" title="mxnet.gluon.rnn.ModifierCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.begin_state" title="mxnet.gluon.rnn.ModifierCell.begin_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">begin_state</span></code></a>([func])</p></td>
<td><p>Initial state for this cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.cast" title="mxnet.gluon.rnn.ModifierCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.collect_params" title="mxnet.gluon.rnn.ModifierCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.export" title="mxnet.gluon.rnn.ModifierCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.forward" title="mxnet.gluon.rnn.ModifierCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs,Â states)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.hybridize" title="mxnet.gluon.rnn.ModifierCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.infer_shape" title="mxnet.gluon.rnn.ModifierCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(*args)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.infer_type" title="mxnet.gluon.rnn.ModifierCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.initialize" title="mxnet.gluon.rnn.ModifierCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.load" title="mxnet.gluon.rnn.ModifierCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.load_dict" title="mxnet.gluon.rnn.ModifierCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.load_parameters" title="mxnet.gluon.rnn.ModifierCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.optimize_for" title="mxnet.gluon.rnn.ModifierCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.register_child" title="mxnet.gluon.rnn.ModifierCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.register_forward_hook" title="mxnet.gluon.rnn.ModifierCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.register_forward_pre_hook" title="mxnet.gluon.rnn.ModifierCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.register_op_hook" title="mxnet.gluon.rnn.ModifierCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.reset" title="mxnet.gluon.rnn.ModifierCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.reset_ctx" title="mxnet.gluon.rnn.ModifierCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.reset_device" title="mxnet.gluon.rnn.ModifierCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.save" title="mxnet.gluon.rnn.ModifierCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.save_parameters" title="mxnet.gluon.rnn.ModifierCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.setattr" title="mxnet.gluon.rnn.ModifierCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.share_parameters" title="mxnet.gluon.rnn.ModifierCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.state_info" title="mxnet.gluon.rnn.ModifierCell.state_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_info</span></code></a>([batch_size])</p></td>
<td><p>shape and layout information of states</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.summary" title="mxnet.gluon.rnn.ModifierCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.unroll" title="mxnet.gluon.rnn.ModifierCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.zero_grad" title="mxnet.gluon.rnn.ModifierCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.params" title="mxnet.gluon.rnn.ModifierCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Return an attribute of instance, which is of type owner.</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.begin_state">
<code class="sig-name descname">begin_state</code><span class="sig-paren">(</span><em class="sig-param">func=&lt;function zeros&gt;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ModifierCell.begin_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.begin_state" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initial state for this cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) â <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â Only required for NDArray API. Size of the batch (âNâ in layout)
dimension of input.</p></li>
<li><p><strong>**kwargs</strong> â Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states</strong> â Starting states for the first RNN step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested list of Symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ModifierCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.begin_state" title="mxnet.gluon.rnn.ModifierCell.begin_state"><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></a></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.unroll" title="mxnet.gluon.rnn.ModifierCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return an attribute of instance, which is of type owner.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.forward" title="mxnet.gluon.rnn.ModifierCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.ModifierCell.forward" title="mxnet.gluon.rnn.ModifierCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.state_info">
<code class="sig-name descname">state_info</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ModifierCell.state_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.state_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ModifierCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ModifierCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.RNN">
<em class="property">class </em><code class="sig-name descname">RNN</code><span class="sig-paren">(</span><em class="sig-param">hidden_size</em>, <em class="sig-param">num_layers=1</em>, <em class="sig-param">activation='relu'</em>, <em class="sig-param">layout='TNC'</em>, <em class="sig-param">dropout=0</em>, <em class="sig-param">bidirectional=False</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">input_size=0</em>, <em class="sig-param">dtype='float32'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_layer.html#RNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RNN" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_layer._RNNLayer</span></code></p>
<p>Applies a multi-layer Elman RNN with <cite>tanh</cite> or <cite>ReLU</cite> non-linearity to an input sequence.</p>
<p>For each element in the input sequence, each layer computes the following
function:</p>
<div class="math notranslate nohighlight">
\[h_t = \tanh(w_{ih} * x_t + b_{ih}  +  w_{hh} * h_{(t-1)} + b_{hh})\]</div>
<p>where <span class="math notranslate nohighlight">\(h_t\)</span> is the hidden state at time <cite>t</cite>, and <span class="math notranslate nohighlight">\(x_t\)</span> is the output
of the previous layer at time <cite>t</cite> or <span class="math notranslate nohighlight">\(input_t\)</span> for the first layer.
If nonlinearity=âreluâ, then <cite>ReLU</cite> is used instead of <cite>tanh</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>) â The number of features in the hidden state h.</p></li>
<li><p><strong>num_layers</strong> (<em>int</em><em>, </em><em>default 1</em>) â Number of recurrent layers.</p></li>
<li><p><strong>activation</strong> (<em>{'relu'</em><em> or </em><em>'tanh'}</em><em>, </em><em>default 'relu'</em>) â The activation function to use.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>default 'TNC'</em>) â The format of input and output tensors. T, N and C stand for
sequence length, batch size, and feature dimensions respectively.</p></li>
<li><p><strong>dropout</strong> (<em>float</em><em>, </em><em>default 0</em>) â If non-zero, introduces a dropout layer on the outputs of each
RNN layer except the last layer.</p></li>
<li><p><strong>bidirectional</strong> (<em>bool</em><em>, </em><em>default False</em>) â If <cite>True</cite>, becomes a bidirectional RNN.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the linear
transformation of the inputs.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the bias vector.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the bias vector.</p></li>
<li><p><strong>input_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â The number of expected features in the input x.
If not specified, it will be inferred from input.</p></li>
<li><p><strong>dtype</strong> (<em>str</em><em>, </em><em>default 'float32'</em>) â Type to initialize the parameters and default states to</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>data</strong>: input tensor with shape <cite>(sequence_length, batch_size, input_size)</cite>
when <cite>layout</cite> is âTNCâ. For other layouts, dimensions are permuted accordingly
using transpose() operator which adds performance overhead. Consider creating
batches in TNC layout during data batching step.</p></li>
<li><p><strong>states</strong>: initial recurrent state tensor with shape
<cite>(num_layers, batch_size, num_hidden)</cite>. If <cite>bidirectional</cite> is True,
shape will instead be <cite>(2*num_layers, batch_size, num_hidden)</cite>. If
<cite>states</cite> is None, zeros will be used as default begin states.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>out</strong>: output tensor with shape <cite>(sequence_length, batch_size, num_hidden)</cite>
when <cite>layout</cite> is âTNCâ. If <cite>bidirectional</cite> is True, output shape will instead
be <cite>(sequence_length, batch_size, 2*num_hidden)</cite></p></li>
<li><p><strong>out_states</strong>: output recurrent state tensor with the same shape as <cite>states</cite>.
If <cite>states</cite> is None <cite>out_states</cite> will not be returned.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gluon</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># by default zeros are used as begin state</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># manually specify begin state.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h0</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.RNNCell">
<em class="property">class </em><code class="sig-name descname">RNNCell</code><span class="sig-paren">(</span><em class="sig-param">hidden_size</em>, <em class="sig-param">activation='tanh'</em>, <em class="sig-param">i2h_weight_initializer=None</em>, <em class="sig-param">h2h_weight_initializer=None</em>, <em class="sig-param">i2h_bias_initializer='zeros'</em>, <em class="sig-param">h2h_bias_initializer='zeros'</em>, <em class="sig-param">input_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RNNCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.HybridRecurrentCell</span></code></p>
<p>Elman RNN recurrent neural network cell.</p>
<p>Each call computes the following function:</p>
<div class="math notranslate nohighlight">
\[h_t = \tanh(w_{ih} * x_t + b_{ih}  +  w_{hh} * h_{(t-1)} + b_{hh})\]</div>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.apply" title="mxnet.gluon.rnn.RNNCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.begin_state" title="mxnet.gluon.rnn.RNNCell.begin_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">begin_state</span></code></a>([batch_size,Â func])</p></td>
<td><p>Initial state for this cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.cast" title="mxnet.gluon.rnn.RNNCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.collect_params" title="mxnet.gluon.rnn.RNNCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.export" title="mxnet.gluon.rnn.RNNCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.forward" title="mxnet.gluon.rnn.RNNCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs,Â states)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.hybridize" title="mxnet.gluon.rnn.RNNCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.infer_shape" title="mxnet.gluon.rnn.RNNCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(i,Â x,Â is_bidirect)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.infer_type" title="mxnet.gluon.rnn.RNNCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.initialize" title="mxnet.gluon.rnn.RNNCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.load" title="mxnet.gluon.rnn.RNNCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.load_dict" title="mxnet.gluon.rnn.RNNCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.load_parameters" title="mxnet.gluon.rnn.RNNCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.optimize_for" title="mxnet.gluon.rnn.RNNCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.register_child" title="mxnet.gluon.rnn.RNNCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.register_forward_hook" title="mxnet.gluon.rnn.RNNCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.register_forward_pre_hook" title="mxnet.gluon.rnn.RNNCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.register_op_hook" title="mxnet.gluon.rnn.RNNCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.reset" title="mxnet.gluon.rnn.RNNCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.reset_ctx" title="mxnet.gluon.rnn.RNNCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.reset_device" title="mxnet.gluon.rnn.RNNCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.save" title="mxnet.gluon.rnn.RNNCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.save_parameters" title="mxnet.gluon.rnn.RNNCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.setattr" title="mxnet.gluon.rnn.RNNCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.share_parameters" title="mxnet.gluon.rnn.RNNCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.state_info" title="mxnet.gluon.rnn.RNNCell.state_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_info</span></code></a>([batch_size])</p></td>
<td><p>shape and layout information of states</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.summary" title="mxnet.gluon.rnn.RNNCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.unroll" title="mxnet.gluon.rnn.RNNCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.zero_grad" title="mxnet.gluon.rnn.RNNCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.params" title="mxnet.gluon.rnn.RNNCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its childrenâs parameters).</p></td>
</tr>
</tbody>
</table>
<p>where <span class="math notranslate nohighlight">\(h_t\)</span> is the hidden state at time <cite>t</cite>, and <span class="math notranslate nohighlight">\(x_t\)</span> is the hidden
state of the previous layer at time <cite>t</cite> or <span class="math notranslate nohighlight">\(input_t\)</span> for the first layer.
If nonlinearity=âreluâ, then <cite>ReLU</cite> is used instead of <cite>tanh</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<em>int</em>) â Number of units in output symbol</p></li>
<li><p><strong>activation</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>default 'tanh'</em>) â Type of activation function.</p></li>
<li><p><strong>i2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the input weights matrix, used for the linear
transformation of the inputs.</p></li>
<li><p><strong>h2h_weight_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Initializer for the recurrent weights matrix, used for the linear
transformation of the recurrent state.</p></li>
<li><p><strong>i2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default 'zeros'</em>) â Initializer for the bias vector.</p></li>
<li><p><strong>h2h_bias_initializer</strong> (<em>str</em><em> or </em><a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a><em>, </em><em>default 'zeros'</em>) â Initializer for the bias vector.</p></li>
<li><p><strong>input_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â The number of expected features in the input x.
If not specified, it will be inferred from input.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><strong>data</strong>: input tensor with shape <cite>(batch_size, input_size)</cite>.</p></li>
<li><p><strong>states</strong>: a list of one initial recurrent state tensor with shape
<cite>(batch_size, num_hidden)</cite>.</p></li>
</ul>
</dd>
<dt>Outputs:</dt><dd><ul class="simple">
<li><p><strong>out</strong>: output tensor with shape <cite>(batch_size, num_hidden)</cite>.</p></li>
<li><p><strong>next_states</strong>: a list of one output recurrent state tensor with the
same shape as <cite>states</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.begin_state">
<code class="sig-name descname">begin_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em>, <em class="sig-param">func=&lt;function zeros&gt;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.begin_state" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initial state for this cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) â <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â Only required for NDArray API. Size of the batch (âNâ in layout)
dimension of input.</p></li>
<li><p><strong>**kwargs</strong> â Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states</strong> â Starting states for the first RNN step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested list of Symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RNNCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.begin_state" title="mxnet.gluon.rnn.RNNCell.begin_state"><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></a></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.unroll" title="mxnet.gluon.rnn.RNNCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">i</em>, <em class="sig-param">x</em>, <em class="sig-param">is_bidirect</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RNNCell.infer_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its
childrenâs parameters).</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.forward" title="mxnet.gluon.rnn.RNNCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.RNNCell.forward" title="mxnet.gluon.rnn.RNNCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.state_info">
<code class="sig-name descname">state_info</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RNNCell.state_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.state_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RNNCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RNNCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.RecurrentCell">
<em class="property">class </em><code class="sig-name descname">RecurrentCell</code><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.block.Block</span></code></p>
<p>Abstract base class for RNN cells</p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.apply" title="mxnet.gluon.rnn.RecurrentCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.begin_state" title="mxnet.gluon.rnn.RecurrentCell.begin_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">begin_state</span></code></a>([batch_size,Â func])</p></td>
<td><p>Initial state for this cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.cast" title="mxnet.gluon.rnn.RecurrentCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.collect_params" title="mxnet.gluon.rnn.RecurrentCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.forward" title="mxnet.gluon.rnn.RecurrentCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs,Â states)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.hybridize" title="mxnet.gluon.rnn.RecurrentCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.initialize" title="mxnet.gluon.rnn.RecurrentCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.load" title="mxnet.gluon.rnn.RecurrentCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.load_dict" title="mxnet.gluon.rnn.RecurrentCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.load_parameters" title="mxnet.gluon.rnn.RecurrentCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.register_child" title="mxnet.gluon.rnn.RecurrentCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.register_forward_hook" title="mxnet.gluon.rnn.RecurrentCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.register_forward_pre_hook" title="mxnet.gluon.rnn.RecurrentCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.register_op_hook" title="mxnet.gluon.rnn.RecurrentCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.reset" title="mxnet.gluon.rnn.RecurrentCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.reset_ctx" title="mxnet.gluon.rnn.RecurrentCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.reset_device" title="mxnet.gluon.rnn.RecurrentCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.save" title="mxnet.gluon.rnn.RecurrentCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.save_parameters" title="mxnet.gluon.rnn.RecurrentCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.setattr" title="mxnet.gluon.rnn.RecurrentCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.share_parameters" title="mxnet.gluon.rnn.RecurrentCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.state_info" title="mxnet.gluon.rnn.RecurrentCell.state_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_info</span></code></a>([batch_size])</p></td>
<td><p>shape and layout information of states</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.summary" title="mxnet.gluon.rnn.RecurrentCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.unroll" title="mxnet.gluon.rnn.RecurrentCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.zero_grad" title="mxnet.gluon.rnn.RecurrentCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.params" title="mxnet.gluon.rnn.RecurrentCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its childrenâs parameters).</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.begin_state">
<code class="sig-name descname">begin_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em>, <em class="sig-param">func=&lt;function zeros&gt;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell.begin_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.begin_state" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initial state for this cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) â <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â Only required for NDArray API. Size of the batch (âNâ in layout)
dimension of input.</p></li>
<li><p><strong>**kwargs</strong> â Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states</strong> â Starting states for the first RNN step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested list of Symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.begin_state" title="mxnet.gluon.rnn.RecurrentCell.begin_state"><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></a></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.unroll" title="mxnet.gluon.rnn.RecurrentCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its
childrenâs parameters).</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.forward" title="mxnet.gluon.rnn.RecurrentCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell.forward" title="mxnet.gluon.rnn.RecurrentCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.state_info">
<code class="sig-name descname">state_info</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell.state_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.state_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#RecurrentCell.unroll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.RecurrentCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.RecurrentCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.ResidualCell">
<em class="property">class </em><code class="sig-name descname">ResidualCell</code><span class="sig-paren">(</span><em class="sig-param">base_cell</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ResidualCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.ModifierCell</span></code></p>
<p>Adds residual connection as described in Wu et al, 2016
(<a class="reference external" href="https://arxiv.org/abs/1609.08144">https://arxiv.org/abs/1609.08144</a>).
Output of the cell is output of the base cell plus input.</p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.apply" title="mxnet.gluon.rnn.ResidualCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.cast" title="mxnet.gluon.rnn.ResidualCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.collect_params" title="mxnet.gluon.rnn.ResidualCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.export" title="mxnet.gluon.rnn.ResidualCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.forward" title="mxnet.gluon.rnn.ResidualCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs,Â states)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.hybridize" title="mxnet.gluon.rnn.ResidualCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.infer_shape" title="mxnet.gluon.rnn.ResidualCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(i,Â x,Â is_bidirect)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.infer_type" title="mxnet.gluon.rnn.ResidualCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.initialize" title="mxnet.gluon.rnn.ResidualCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.load" title="mxnet.gluon.rnn.ResidualCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.load_dict" title="mxnet.gluon.rnn.ResidualCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.load_parameters" title="mxnet.gluon.rnn.ResidualCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.optimize_for" title="mxnet.gluon.rnn.ResidualCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.register_child" title="mxnet.gluon.rnn.ResidualCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.register_forward_hook" title="mxnet.gluon.rnn.ResidualCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.register_forward_pre_hook" title="mxnet.gluon.rnn.ResidualCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.register_op_hook" title="mxnet.gluon.rnn.ResidualCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.reset" title="mxnet.gluon.rnn.ResidualCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.reset_ctx" title="mxnet.gluon.rnn.ResidualCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.reset_device" title="mxnet.gluon.rnn.ResidualCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.save" title="mxnet.gluon.rnn.ResidualCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.save_parameters" title="mxnet.gluon.rnn.ResidualCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.setattr" title="mxnet.gluon.rnn.ResidualCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.share_parameters" title="mxnet.gluon.rnn.ResidualCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.summary" title="mxnet.gluon.rnn.ResidualCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.unroll" title="mxnet.gluon.rnn.ResidualCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.zero_grad" title="mxnet.gluon.rnn.ResidualCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.params" title="mxnet.gluon.rnn.ResidualCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Return an attribute of instance, which is of type owner.</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ResidualCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.unroll" title="mxnet.gluon.rnn.ResidualCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">i</em>, <em class="sig-param">x</em>, <em class="sig-param">is_bidirect</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ResidualCell.infer_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return an attribute of instance, which is of type owner.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.forward" title="mxnet.gluon.rnn.ResidualCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.ResidualCell.forward" title="mxnet.gluon.rnn.ResidualCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ResidualCell.unroll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ResidualCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ResidualCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.SequentialRNNCell">
<em class="property">class </em><code class="sig-name descname">SequentialRNNCell</code><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#SequentialRNNCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.RecurrentCell</span></code></p>
<p>Sequentially stacking multiple RNN cells.</p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.add" title="mxnet.gluon.rnn.SequentialRNNCell.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a>(cell)</p></td>
<td><p>Appends a cell into the stack.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.apply" title="mxnet.gluon.rnn.SequentialRNNCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.begin_state" title="mxnet.gluon.rnn.SequentialRNNCell.begin_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">begin_state</span></code></a>(**kwargs)</p></td>
<td><p>Initial state for this cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.cast" title="mxnet.gluon.rnn.SequentialRNNCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.collect_params" title="mxnet.gluon.rnn.SequentialRNNCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.forward" title="mxnet.gluon.rnn.SequentialRNNCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(*args,Â **kwargs)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.hybridize" title="mxnet.gluon.rnn.SequentialRNNCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.initialize" title="mxnet.gluon.rnn.SequentialRNNCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.load" title="mxnet.gluon.rnn.SequentialRNNCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.load_dict" title="mxnet.gluon.rnn.SequentialRNNCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.load_parameters" title="mxnet.gluon.rnn.SequentialRNNCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.register_child" title="mxnet.gluon.rnn.SequentialRNNCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.register_forward_hook" title="mxnet.gluon.rnn.SequentialRNNCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.register_forward_pre_hook" title="mxnet.gluon.rnn.SequentialRNNCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.register_op_hook" title="mxnet.gluon.rnn.SequentialRNNCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.reset" title="mxnet.gluon.rnn.SequentialRNNCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.reset_ctx" title="mxnet.gluon.rnn.SequentialRNNCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.reset_device" title="mxnet.gluon.rnn.SequentialRNNCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.save" title="mxnet.gluon.rnn.SequentialRNNCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.save_parameters" title="mxnet.gluon.rnn.SequentialRNNCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.setattr" title="mxnet.gluon.rnn.SequentialRNNCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.share_parameters" title="mxnet.gluon.rnn.SequentialRNNCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.state_info" title="mxnet.gluon.rnn.SequentialRNNCell.state_info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_info</span></code></a>([batch_size])</p></td>
<td><p>shape and layout information of states</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.summary" title="mxnet.gluon.rnn.SequentialRNNCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.unroll" title="mxnet.gluon.rnn.SequentialRNNCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.zero_grad" title="mxnet.gluon.rnn.SequentialRNNCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.params" title="mxnet.gluon.rnn.SequentialRNNCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its childrenâs parameters).</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.add">
<code class="sig-name descname">add</code><span class="sig-paren">(</span><em class="sig-param">cell</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#SequentialRNNCell.add"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.add" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Appends a cell into the stack.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>cell</strong> (<a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell" title="mxnet.gluon.rnn.RecurrentCell"><em>RecurrentCell</em></a>) â The cell to add.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.begin_state">
<code class="sig-name descname">begin_state</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#SequentialRNNCell.begin_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.begin_state" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initial state for this cell.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em><em>, </em><em>default symbol.zeros</em>) â <p>Function for creating initial state.</p>
<p>For Symbol API, func can be <cite>symbol.zeros</cite>, <cite>symbol.uniform</cite>,
<cite>symbol.var etc</cite>. Use <cite>symbol.var</cite> if you want to directly
feed input as states.</p>
<p>For NDArray API, func can be <cite>ndarray.zeros</cite>, <cite>ndarray.ones</cite>, etc.</p>
</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default 0</em>) â Only required for NDArray API. Size of the batch (âNâ in layout)
dimension of input.</p></li>
<li><p><strong>**kwargs</strong> â Additional keyword arguments passed to func. For example
<cite>mean</cite>, <cite>std</cite>, <cite>dtype</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>states</strong> â Starting states for the first RNN step.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>nested list of Symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#SequentialRNNCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.begin_state" title="mxnet.gluon.rnn.SequentialRNNCell.begin_state"><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></a></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.unroll" title="mxnet.gluon.rnn.SequentialRNNCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code>âs parameter dictionary (does not include its
childrenâs parameters).</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.forward" title="mxnet.gluon.rnn.SequentialRNNCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.SequentialRNNCell.forward" title="mxnet.gluon.rnn.SequentialRNNCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.state_info">
<code class="sig-name descname">state_info</code><span class="sig-paren">(</span><em class="sig-param">batch_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#SequentialRNNCell.state_info"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.state_info" title="Permalink to this definition">Â¶</a></dt>
<dd><p>shape and layout information of states</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#SequentialRNNCell.unroll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.SequentialRNNCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.SequentialRNNCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell">
<em class="property">class </em><code class="sig-name descname">VariationalDropoutCell</code><span class="sig-paren">(</span><em class="sig-param">base_cell</em>, <em class="sig-param">drop_inputs=0.0</em>, <em class="sig-param">drop_states=0.0</em>, <em class="sig-param">drop_outputs=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#VariationalDropoutCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.ModifierCell</span></code></p>
<p>Applies Variational Dropout on base cell.
<a class="reference external" href="https://arxiv.org/pdf/1512.05287.pdf">https://arxiv.org/pdf/1512.05287.pdf</a></p>
<p>Variational dropout uses the same dropout mask across time-steps. It can be applied to RNN
inputs, outputs, and states. The masks for them are not shared.</p>
<p>The dropout mask is initialized when stepping forward for the first time and will remain
the same until .reset() is called. Thus, if using the cell and stepping manually without calling
.unroll(), the .reset() should be called after each sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_cell</strong> (<a class="reference internal" href="#mxnet.gluon.rnn.RecurrentCell" title="mxnet.gluon.rnn.RecurrentCell"><em>RecurrentCell</em></a>) â The cell on which to perform variational dropout.</p></li>
<li><p><strong>drop_inputs</strong> (<em>float</em><em>, </em><em>default 0.</em>) â The dropout rate for inputs. Wonât apply dropout if it equals 0.</p></li>
<li><p><strong>drop_states</strong> (<em>float</em><em>, </em><em>default 0.</em>) â The dropout rate for state inputs on the first state channel.
Wonât apply dropout if it equals 0.</p></li>
<li><p><strong>drop_outputs</strong> (<em>float</em><em>, </em><em>default 0.</em>) â The dropout rate for outputs. Wonât apply dropout if it equals 0.</p></li>
</ul>
</dd>
</dl>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.apply" title="mxnet.gluon.rnn.VariationalDropoutCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.cast" title="mxnet.gluon.rnn.VariationalDropoutCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.collect_params" title="mxnet.gluon.rnn.VariationalDropoutCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.export" title="mxnet.gluon.rnn.VariationalDropoutCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.forward" title="mxnet.gluon.rnn.VariationalDropoutCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs,Â states)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.hybridize" title="mxnet.gluon.rnn.VariationalDropoutCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.infer_shape" title="mxnet.gluon.rnn.VariationalDropoutCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(i,Â x,Â is_bidirect)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.infer_type" title="mxnet.gluon.rnn.VariationalDropoutCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.initialize" title="mxnet.gluon.rnn.VariationalDropoutCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.load" title="mxnet.gluon.rnn.VariationalDropoutCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.load_dict" title="mxnet.gluon.rnn.VariationalDropoutCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.load_parameters" title="mxnet.gluon.rnn.VariationalDropoutCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.optimize_for" title="mxnet.gluon.rnn.VariationalDropoutCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.register_child" title="mxnet.gluon.rnn.VariationalDropoutCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.register_forward_hook" title="mxnet.gluon.rnn.VariationalDropoutCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.register_forward_pre_hook" title="mxnet.gluon.rnn.VariationalDropoutCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.register_op_hook" title="mxnet.gluon.rnn.VariationalDropoutCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.reset" title="mxnet.gluon.rnn.VariationalDropoutCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.reset_ctx" title="mxnet.gluon.rnn.VariationalDropoutCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.reset_device" title="mxnet.gluon.rnn.VariationalDropoutCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.save" title="mxnet.gluon.rnn.VariationalDropoutCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.save_parameters" title="mxnet.gluon.rnn.VariationalDropoutCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.setattr" title="mxnet.gluon.rnn.VariationalDropoutCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.share_parameters" title="mxnet.gluon.rnn.VariationalDropoutCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.summary" title="mxnet.gluon.rnn.VariationalDropoutCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.unroll" title="mxnet.gluon.rnn.VariationalDropoutCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.zero_grad" title="mxnet.gluon.rnn.VariationalDropoutCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.params" title="mxnet.gluon.rnn.VariationalDropoutCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Return an attribute of instance, which is of type owner.</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#VariationalDropoutCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.unroll" title="mxnet.gluon.rnn.VariationalDropoutCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">i</em>, <em class="sig-param">x</em>, <em class="sig-param">is_bidirect</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#VariationalDropoutCell.infer_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return an attribute of instance, which is of type owner.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.forward" title="mxnet.gluon.rnn.VariationalDropoutCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.VariationalDropoutCell.forward" title="mxnet.gluon.rnn.VariationalDropoutCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#VariationalDropoutCell.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#VariationalDropoutCell.unroll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.VariationalDropoutCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.VariationalDropoutCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mxnet.gluon.rnn.ZoneoutCell">
<em class="property">class </em><code class="sig-name descname">ZoneoutCell</code><span class="sig-paren">(</span><em class="sig-param">base_cell</em>, <em class="sig-param">zoneout_outputs=0.0</em>, <em class="sig-param">zoneout_states=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ZoneoutCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.rnn.rnn_cell.ModifierCell</span></code></p>
<p>Applies Zoneout on base cell.</p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.apply" title="mxnet.gluon.rnn.ZoneoutCell.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(fn)</p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.cast" title="mxnet.gluon.rnn.ZoneoutCell.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(dtype)</p></td>
<td><p>Cast this Block to use another data type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.collect_params" title="mxnet.gluon.rnn.ZoneoutCell.collect_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collect_params</span></code></a>([select])</p></td>
<td><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> which match some given regular expressions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.export" title="mxnet.gluon.rnn.ZoneoutCell.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>(path[,Â epoch,Â remove_amp_cast])</p></td>
<td><p>Export HybridBlock to json format that can be loaded by <cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.forward" title="mxnet.gluon.rnn.ZoneoutCell.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(inputs,Â states)</p></td>
<td><p>Unrolls the recurrent cell for one time step.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.hybridize" title="mxnet.gluon.rnn.ZoneoutCell.hybridize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hybridize</span></code></a>([active])</p></td>
<td><p>Please refer description of HybridBlock hybridize().</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.infer_shape" title="mxnet.gluon.rnn.ZoneoutCell.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(i,Â x,Â is_bidirect)</p></td>
<td><p>Infers shape of Parameters from inputs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.infer_type" title="mxnet.gluon.rnn.ZoneoutCell.infer_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_type</span></code></a>(*args)</p></td>
<td><p>Infers data type of Parameters from inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.initialize" title="mxnet.gluon.rnn.ZoneoutCell.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>([init,Â device,Â verbose,Â force_reinit])</p></td>
<td><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.load" title="mxnet.gluon.rnn.ZoneoutCell.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix)</p></td>
<td><p>Load a model saved using the <cite>save</cite> API</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.load_dict" title="mxnet.gluon.rnn.ZoneoutCell.load_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_dict</span></code></a>(param_dict[,Â device,Â â¦])</p></td>
<td><p>Load parameters from dict</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.load_parameters" title="mxnet.gluon.rnn.ZoneoutCell.load_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_parameters</span></code></a>(filename[,Â device,Â â¦])</p></td>
<td><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.optimize_for" title="mxnet.gluon.rnn.ZoneoutCell.optimize_for"><code class="xref py py-obj docutils literal notranslate"><span class="pre">optimize_for</span></code></a>(x,Â *args[,Â backend,Â clear,Â â¦])</p></td>
<td><p>Partitions the current HybridBlock and optimizes it for a given backend without executing a forward pass.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.register_child" title="mxnet.gluon.rnn.ZoneoutCell.register_child"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_child</span></code></a>(block[,Â name])</p></td>
<td><p>Registers block as a child of self.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.register_forward_hook" title="mxnet.gluon.rnn.ZoneoutCell.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward hook on the block.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.register_forward_pre_hook" title="mxnet.gluon.rnn.ZoneoutCell.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a>(hook)</p></td>
<td><p>Registers a forward pre-hook on the block.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.register_op_hook" title="mxnet.gluon.rnn.ZoneoutCell.register_op_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_op_hook</span></code></a>(callback[,Â monitor_all])</p></td>
<td><p>Install callback monitor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.reset" title="mxnet.gluon.rnn.ZoneoutCell.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>Reset before re-using the cell for another graph.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.reset_ctx" title="mxnet.gluon.rnn.ZoneoutCell.reset_ctx"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_ctx</span></code></a>(ctx)</p></td>
<td><p>This function has been deprecated.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.reset_device" title="mxnet.gluon.rnn.ZoneoutCell.reset_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_device</span></code></a>(device)</p></td>
<td><p>Re-assign all Parameters to other devices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.save" title="mxnet.gluon.rnn.ZoneoutCell.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(prefix)</p></td>
<td><p>Save the model architecture and parameters to load again later</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.save_parameters" title="mxnet.gluon.rnn.ZoneoutCell.save_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_parameters</span></code></a>(filename[,Â deduplicate])</p></td>
<td><p>Save parameters to file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.setattr" title="mxnet.gluon.rnn.ZoneoutCell.setattr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setattr</span></code></a>(name,Â value)</p></td>
<td><p>Set an attribute to a new value for all Parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.share_parameters" title="mxnet.gluon.rnn.ZoneoutCell.share_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_parameters</span></code></a>(shared)</p></td>
<td><p>Share parameters recursively inside the model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.summary" title="mxnet.gluon.rnn.ZoneoutCell.summary"><code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code></a>(*inputs)</p></td>
<td><p>Print the summary of the modelâs output and parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.unroll" title="mxnet.gluon.rnn.ZoneoutCell.unroll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unroll</span></code></a>(length,Â inputs[,Â begin_state,Â â¦])</p></td>
<td><p>Unrolls an RNN cell across time steps.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.zero_grad" title="mxnet.gluon.rnn.ZoneoutCell.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a>()</p></td>
<td><p>Sets all Parametersâ gradient buffer to 0.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.params" title="mxnet.gluon.rnn.ZoneoutCell.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Return an attribute of instance, which is of type owner.</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.apply" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every child block as well as self.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<em>callable</em>) â Function to be applied to each submodule, of form <cite>fn(block)</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.cast">
<code class="sig-name descname">cast</code><span class="sig-paren">(</span><em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.cast" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Cast this Block to use another data type.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dtype</strong> (<em>str</em><em> or </em><em>numpy.dtype</em>) â The new data type.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.collect_params">
<code class="sig-name descname">collect_params</code><span class="sig-paren">(</span><em class="sig-param">select=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.collect_params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code> containing this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and all of its
childrenâs Parameters(default), also can returns the select <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code>
which match some given regular expressions.</p>
<p>For example, collect the specified parameters in [âconv1.weightâ, âconv1.biasâ, âfc.weightâ,
âfc.biasâ]:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;conv1.weight|conv1.bias|fc.weight|fc.bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or collect all parameters whose names end with âweightâ or âbiasâ, this can be done
using regular expressions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(</span><span class="s1">&#39;.*weight|.*bias&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>select</strong> (<em>str</em>) â regular expressions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>The selected <code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.export">
<code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">epoch=0</em>, <em class="sig-param">remove_amp_cast=True</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.export" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Export HybridBlock to json format that can be loaded by
<cite>gluon.SymbolBlock.imports</cite> or the C++ interface.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When there are only one input, it will have name <cite>data</cite>. When there
Are more than one inputs, they will be named as <cite>data0</cite>, <cite>data1</cite>, etc.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> or </em><em>None</em>) â Path to save model. Two files <cite>path-symbol.json</cite> and <cite>path-xxxx.params</cite>
will be created, where xxxx is the 4 digits epoch number.
If None, do not export to file but return Python Symbol object and
corresponding dictionary of parameters.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â Epoch number of saved model.</p></li>
<li><p><strong>remove_amp_cast</strong> (<em>bool</em><em>, </em><em>optional</em>) â Whether to remove the amp_cast and amp_multicast operators, before saving the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>symbol_filename</strong> (<em>str</em>) â Filename to which model symbols were saved, including <cite>path</cite> prefix.</p></li>
<li><p><strong>params_filename</strong> (<em>str</em>) â Filename to which model parameters were saved, including <cite>path</cite> prefix.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">states</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ZoneoutCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.forward" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls the recurrent cell for one time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>sym.Variable</em>) â Input symbol, 2D, of shape (batch_size * num_units).</p></li>
<li><p><strong>states</strong> (<em>list of sym.Variable</em>) â RNN state from previous step or the output of begin_state().</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> (<em>Symbol</em>) â Symbol corresponding to the output from the RNN when unrolling
for a single time step.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.
This can be used as an input state to the next time step
of this RNN.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-meth docutils literal notranslate"><span class="pre">begin_state()</span></code></dt><dd><p>This function can provide the states for the first time step.</p>
</dd>
<dt><a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.unroll" title="mxnet.gluon.rnn.ZoneoutCell.unroll"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unroll()</span></code></a></dt><dd><p>This function unrolls an RNN for a given number of (&gt;=1) time steps.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.hybridize">
<code class="sig-name descname">hybridize</code><span class="sig-paren">(</span><em class="sig-param">active=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.hybridize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Please refer description of HybridBlock hybridize().</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.infer_shape">
<code class="sig-name descname">infer_shape</code><span class="sig-paren">(</span><em class="sig-param">i</em>, <em class="sig-param">x</em>, <em class="sig-param">is_bidirect</em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ZoneoutCell.infer_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.infer_shape" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers shape of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.infer_type">
<code class="sig-name descname">infer_type</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.infer_type" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Infers data type of Parameters from inputs.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><em class="sig-param">init=&lt;mxnet.initializer.Uniform object&gt;</em>, <em class="sig-param">device=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">force_reinit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.initialize" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Initializes <code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code> s of this <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> and its children.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>init</strong> (<a class="reference internal" href="../../initializer/index.html#mxnet.initializer.Initializer" title="mxnet.initializer.Initializer"><em>Initializer</em></a>) â Global default Initializer to be used when <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Otherwise, <code class="xref py py-meth docutils literal notranslate"><span class="pre">Parameter.init()</span></code> takes precedence.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em>) â Keeps a copy of Parameters on one or many device(s).</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to verbosely print out details on initialization.</p></li>
<li><p><strong>force_reinit</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to force re-initialization if parameter is already initialized.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.load" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load a model saved using the <cite>save</cite> API</p>
<p>Reconfigures a model using the saved configuration. This function
does not regenerate the model architecture. It resets each Blockâs
parameter UUIDs as they were when saved in order to match the names of the
saved parameters.</p>
<p>This function assumes the Blocks in the model were created in the same
order they were when the model was saved. This is because each Block is
uniquely identified by Block class name and a unique ID in order (since
its an OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph (Symbol &amp; inputs) and settings are
restored if it had been hybridized before saving.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for loading this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.load_dict">
<code class="sig-name descname">load_dict</code><span class="sig-paren">(</span><em class="sig-param">param_dict</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.load_dict" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from dict</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>param_dict</strong> (<em>dict</em>) â Dictionary containing model parameters</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em>, </em><em>optional</em>) â Device context on which the memory is allocated. Default is
<cite>mxnet.device.current_device()</cite>.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represented in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this dict.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.load_parameters">
<code class="sig-name descname">load_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">device=None</em>, <em class="sig-param">allow_missing=False</em>, <em class="sig-param">ignore_extra=False</em>, <em class="sig-param">cast_dtype=False</em>, <em class="sig-param">dtype_source='current'</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.load_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Load parameters from file previously saved by <cite>save_parameters</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to parameter file.</p></li>
<li><p><strong>device</strong> (<a class="reference internal" href="../../device/index.html#mxnet.device.Device" title="mxnet.device.Device"><em>Device</em></a><em> or </em><em>list of Device</em><em>, </em><em>default cpu</em><em>(</em><em>)</em>) â Device(s) to initialize loaded parameters on.</p></li>
<li><p><strong>allow_missing</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently skip loading parameters not represents in the file.</p></li>
<li><p><strong>ignore_extra</strong> (<em>bool</em><em>, </em><em>default False</em>) â Whether to silently ignore parameters from the file that are not
present in this Block.</p></li>
<li><p><strong>cast_dtype</strong> (<em>bool</em><em>, </em><em>default False</em>) â Cast the data type of the NDArray loaded from the checkpoint to the dtype
provided by the Parameter if any.</p></li>
<li><p><strong>dtype_source</strong> (<em>str</em><em>, </em><em>default 'current'</em>) â must be in {âcurrentâ, âsavedâ}
Only valid if cast_dtype=True, specify the source of the dtype for casting
the parameters</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.optimize_for">
<code class="sig-name descname">optimize_for</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">backend=None</em>, <em class="sig-param">clear=False</em>, <em class="sig-param">partition_if_dynamic=True</em>, <em class="sig-param">static_alloc=False</em>, <em class="sig-param">static_shape=False</em>, <em class="sig-param">inline_limit=2</em>, <em class="sig-param">forward_bulk_size=None</em>, <em class="sig-param">backward_bulk_size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.optimize_for" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Partitions the current HybridBlock and optimizes it for a given backend
without executing a forward pass. Modifies the HybridBlock in-place.</p>
<p>Immediately partitions a HybridBlock using the specified backend. Combines
the work done in the hybridize API with part of the work done in the forward
pass without calling the CachedOp. Can be used in place of hybridize,
afterwards <cite>export</cite> can be called or inference can be run. See README.md in
example/extensions/lib_subgraph/README.md for more details.</p>
<p class="rubric">Examples</p>
<p># partition and then export to file
block.optimize_for(x, backend=âmyPartâ)
block.export(âpartitionedâ)</p>
<p># partition and then run inference
block.optimize_for(x, backend=âmyPartâ)
block(x)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â first input to model</p></li>
<li><p><strong>*args</strong> (<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a>) â other inputs to model</p></li>
<li><p><strong>backend</strong> (<em>str</em>) â The name of backend, as registered in <cite>SubgraphBackendRegistry</cite>, default None</p></li>
<li><p><strong>backend_opts</strong> (<em>dict of user-specified options to pass to the backend for partitioning</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
<li><p><strong>clear</strong> (<em>bool</em><em>, </em><em>default False</em>) â clears any previous optimizations</p></li>
<li><p><strong>partition_if_dynamic</strong> (<em>bool</em><em>, </em><em>default False</em>) â whether to partition the graph when dynamic shape op exists</p></li>
<li><p><strong>static_alloc</strong> (<em>bool</em><em>, </em><em>default False</em>) â Statically allocate memory to improve speed. Memory usage may increase.</p></li>
<li><p><strong>static_shape</strong> (<em>bool</em><em>, </em><em>default False</em>) â Optimize for invariant input shapes between iterations. Must also
set static_alloc to True. Change of input shapes is still allowed
but slower.</p></li>
<li><p><strong>inline_limit</strong> (<em>optional int</em><em>, </em><em>default 2</em>) â Maximum number of operators that can be inlined.</p></li>
<li><p><strong>forward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during forward pass.</p></li>
<li><p><strong>backward_bulk_size</strong> (<em>optional int</em><em>, </em><em>default None</em>) â Segment size of bulk execution during backward pass.</p></li>
<li><p><strong>**kwargs</strong> (<em>The backend options</em><em>, </em><em>optional</em>) â Passed on to <cite>PrePartition</cite> and <cite>PostPartition</cite> functions of <cite>SubgraphProperty</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.params">
<em class="property">property </em><code class="sig-name descname">params</code><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.params" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return an attribute of instance, which is of type owner.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.register_child">
<code class="sig-name descname">register_child</code><span class="sig-paren">(</span><em class="sig-param">block</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.register_child" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers block as a child of self. <code class="xref py py-class docutils literal notranslate"><span class="pre">Block</span></code> s assigned to self as
attributes will be registered automatically.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.register_forward_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward hook on the block.</p>
<p>The hook function is called immediately after <a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.forward" title="mxnet.gluon.rnn.ZoneoutCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input, output) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.register_forward_pre_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Registers a forward pre-hook on the block.</p>
<p>The hook function is called immediately before <a class="reference internal" href="#mxnet.gluon.rnn.ZoneoutCell.forward" title="mxnet.gluon.rnn.ZoneoutCell.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>.
It should not modify the input or output.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>callable</em>) â The forward hook function of form <cite>hook(block, input) -&gt; None</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.utils.HookHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.register_op_hook">
<code class="sig-name descname">register_op_hook</code><span class="sig-paren">(</span><em class="sig-param">callback</em>, <em class="sig-param">monitor_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.register_op_hook" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Install callback monitor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>function</em>) â Function called to inspect the values of the intermediate outputs
of blocks after hybridization. It takes 3 parameters:
name of the tensor being inspected (str)
name of the operator producing or consuming that tensor (str)
tensor being inspected (NDArray).</p></li>
<li><p><strong>monitor_all</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, monitor both input and output, otherwise monitor output only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/mxnet/gluon/rnn/rnn_cell.html#ZoneoutCell.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reset before re-using the cell for another graph.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.reset_ctx">
<code class="sig-name descname">reset_ctx</code><span class="sig-paren">(</span><em class="sig-param">ctx</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.reset_ctx" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This function has been deprecated. Please refer to <code class="docutils literal notranslate"><span class="pre">Block.reset_device</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.reset_device">
<code class="sig-name descname">reset_device</code><span class="sig-paren">(</span><em class="sig-param">device</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.reset_device" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-assign all Parameters to other devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (Device or list of Device, default <code class="xref py py-meth docutils literal notranslate"><span class="pre">device.current_device()</span></code>.) â Assign Parameter to given device. If device is a list of Device, a
copy will be made for each device.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.save" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save the model architecture and parameters to load again later</p>
<p>Saves the model architecture as a nested dictionary where each Block
in the model is a dictionary and its children are sub-dictionaries.</p>
<p>Each Block is uniquely identified by Block class name and a unique ID.
We save each Blockâs parameter UUID to restore later in order to match
the saved parameters.</p>
<p>Recursively traverses a Blockâs children in order (since its an
OrderedDict) and uses the unique ID to denote that specific Block.</p>
<p>Assumes that the model is created in an identical order every time.
If the model is not able to be recreated deterministically do not
use this set of APIs to save/load your model.</p>
<p>For HybridBlocks, the cached_graph is saved (Symbol &amp; inputs) if
it has already been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prefix</strong> (<em>str</em>) â The prefix to use in filenames for saving this model:
&lt;prefix&gt;-model.json and &lt;prefix&gt;-model.params</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.save_parameters">
<code class="sig-name descname">save_parameters</code><span class="sig-paren">(</span><em class="sig-param">filename</em>, <em class="sig-param">deduplicate=False</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.save_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Save parameters to file.</p>
<p>Saved parameters can only be loaded with <cite>load_parameters</cite>. Note that this
method only saves parameters, not model structure. If you want to save
model structures, please use <code class="xref py py-meth docutils literal notranslate"><span class="pre">HybridBlock.export()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) â Path to file.</p></li>
<li><p><strong>deduplicate</strong> (<em>bool</em><em>, </em><em>default False</em>) â If True, save shared parameters only once. Otherwise, if a Block
contains multiple sub-blocks that share parameters, each of the
shared parameters will be separately saved for every sub-block.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html">Saving and Loading Gluon Models</a></p>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.setattr">
<code class="sig-name descname">setattr</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.setattr" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set an attribute to a new value for all Parameters.</p>
<p>For example, set grad_req to null if you donât need gradient w.r.t a
modelâs Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;grad_req&#39;</span><span class="p">,</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>or change the learning rate multiplier:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">setattr</span><span class="p">(</span><span class="s1">&#39;lr_mult&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) â Name of the attribute.</p></li>
<li><p><strong>value</strong> (<em>valid type for attribute name</em>) â The new value for the attribute.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.share_parameters">
<code class="sig-name descname">share_parameters</code><span class="sig-paren">(</span><em class="sig-param">shared</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.share_parameters" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Share parameters recursively inside the model.</p>
<p>For example, if you want <code class="docutils literal notranslate"><span class="pre">dense1</span></code> to share <code class="docutils literal notranslate"><span class="pre">dense0</span></code>âs weights, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dense0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">dense1</span><span class="o">.</span><span class="n">share_parameters</span><span class="p">(</span><span class="n">dense0</span><span class="o">.</span><span class="n">collect_params</span><span class="p">())</span>
</pre></div>
</div>
<dl class="simple">
<dt>which equals to</dt><dd><p>dense1.weight = dense0.weight
dense1.bias = dense0.bias</p>
</dd>
</dl>
<p>Note that unlike the <cite>load_parameters</cite> or <cite>load_dict</cite> functions,
<cite>share_parameters</cite> results in the <cite>Parameter</cite> object being shared (or
tied) between the models, whereas <cite>load_parameters</cite> or <cite>load_dict</cite> only
set the value of the data dictionary of a model. If you call
<cite>load_parameters</cite> or <cite>load_dict</cite> after <cite>share_parameters</cite>, the loaded
value will be reflected in all networks that use the shared (or tied)
<cite>Parameter</cite> object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>shared</strong> (<em>Dict</em>) â Dict of the shared parameters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>this block</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">*inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.summary" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Print the summary of the modelâs output and parameters.</p>
<p>The network must have been initialized, and must not have been hybridized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<em>object</em>) â Any input that the model supports. For any tensor in the input, only
<a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.ndarray.NDArray</span></code></a> is supported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.unroll">
<code class="sig-name descname">unroll</code><span class="sig-paren">(</span><em class="sig-param">length</em>, <em class="sig-param">inputs</em>, <em class="sig-param">begin_state=None</em>, <em class="sig-param">layout='NTC'</em>, <em class="sig-param">merge_outputs=None</em>, <em class="sig-param">valid_length=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.unroll" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Unrolls an RNN cell across time steps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>length</strong> (<em>int</em>) â Number of steps to unroll.</p></li>
<li><p><strong>inputs</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><em>list of Symbol</em><em>, or </em><em>None</em>) â <p>If <cite>inputs</cite> is a single Symbol (usually the output
of Embedding symbol), it should have shape
(batch_size, length, â¦) if <cite>layout</cite> is âNTCâ,
or (length, batch_size, â¦) if <cite>layout</cite> is âTNCâ.</p>
<p>If <cite>inputs</cite> is a list of symbols (usually output of
previous unroll), they should all have shape
(batch_size, â¦).</p>
</p></li>
<li><p><strong>begin_state</strong> (<em>nested list of Symbol</em><em>, </em><em>optional</em>) â Input states created by <cite>begin_state()</cite>
or output state of another cell.
Created from <cite>begin_state()</cite> if <cite>None</cite>.</p></li>
<li><p><strong>layout</strong> (<em>str</em><em>, </em><em>optional</em>) â <cite>layout</cite> of input symbol. Only used if inputs
is a single Symbol.</p></li>
<li><p><strong>merge_outputs</strong> (<em>bool</em><em>, </em><em>optional</em>) â If <cite>False</cite>, returns outputs as a list of Symbols.
If <cite>True</cite>, concatenates output across time steps
and returns a single symbol with shape
(batch_size, length, â¦) if layout is âNTCâ,
or (length, batch_size, â¦) if layout is âTNCâ.
If <cite>None</cite>, output whatever is faster.</p></li>
<li><p><strong>valid_length</strong> (<a class="reference internal" href="../../legacy/symbol/symbol.html#mxnet.symbol.Symbol" title="mxnet.symbol.Symbol"><em>Symbol</em></a><em>, </em><a class="reference internal" href="../../legacy/ndarray/ndarray.html#mxnet.ndarray.NDArray" title="mxnet.ndarray.NDArray"><em>NDArray</em></a><em> or </em><em>None</em>) â <cite>valid_length</cite> specifies the length of the sequences in the batch without padding.
This option is especially useful for building sequence-to-sequence models where
the input and output sequences would potentially be padded.
If <cite>valid_length</cite> is None, all sequences are assumed to have the same length.
If <cite>valid_length</cite> is a Symbol or NDArray, it should have shape (batch_size,).
The ith element will be the length of the ith sequence in the batch.
The last valid state will be return and the padded outputs will be masked with 0.
Note that <cite>valid_length</cite> must be smaller or equal to <cite>length</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>outputs</strong> (<em>list of Symbol or Symbol</em>) â Symbol (if <cite>merge_outputs</cite> is True) or list of Symbols
(if <cite>merge_outputs</cite> is False) corresponding to the output from
the RNN from this unrolling.</p></li>
<li><p><strong>states</strong> (<em>list of Symbol</em>) â The new state of this RNN after this unrolling.
The type of this symbol is same as the output of <cite>begin_state()</cite>.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="mxnet.gluon.rnn.ZoneoutCell.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mxnet.gluon.rnn.ZoneoutCell.zero_grad" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets all Parametersâ gradient buffer to 0.</p>
</dd></dl>

</dd></dl>

</div>
</div>


        <hr class="feedback-hr-top" />
<div class="feedback-container">
    <div class="feedback-question">Did this page help you?</div>
    <div class="feedback-answer-container">
        <div class="feedback-answer yes-link" data-response="yes">Yes</div>
        <div class="feedback-answer no-link" data-response="no">No</div>
    </div>
    <div class="feedback-thank-you">Thanks for your feedback!</div>
</div>
<hr class="feedback-hr-bottom" />
        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">gluon.rnn</a><ul>
<li><a class="reference internal" href="#recurrent-cells">Recurrent Cells</a></li>
<li><a class="reference internal" href="#convolutional-recurrent-cells">Convolutional Recurrent Cells</a></li>
<li><a class="reference internal" href="#recurrent-layers">Recurrent Layers</a></li>
<li><a class="reference internal" href="#module-mxnet.gluon.rnn">API Reference</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>                    

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="../nn/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>gluon.nn</div>
         </div>
     </a>
     <a id="button-next" href="../utils/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>gluon.utils</div>
        </div>
     </a>
  </div>
            <footer class="site-footer h-card">
    <div class="wrapper">
        <div class="row">
            <div class="col-4">
                <h4 class="footer-category-title">Resources</h4>
                <ul class="contact-list">
                    <li><a href="https://lists.apache.org/list.html?dev@mxnet.apache.org">Mailing list</a> <a class="u-email" href="mailto:dev-subscribe@mxnet.apache.org">(subscribe)</a></li>
                    <li><a href="https://discuss.mxnet.io">MXNet Discuss forum</a></li>
                    <li><a href="https://github.com/apache/incubator-mxnet/issues">Github Issues</a></li>
                    <li><a href="https://github.com/apache/incubator-mxnet/projects">Projects</a></li>
                    <li><a href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home">Developer Wiki</a></li>
                    <li><a href="/community">Contribute To MXNet</a></li>
                </ul>
            </div>

            <div class="col-4"><ul class="social-media-list"><li><a href="https://github.com/apache/incubator-mxnet"><svg class="svg-icon"><use xlink:href="../../../_static/minima-social-icons.svg#github"></use></svg> <span class="username">apache/incubator-mxnet</span></a></li><li><a href="https://www.twitter.com/apachemxnet"><svg class="svg-icon"><use xlink:href="../../../_static/minima-social-icons.svg#twitter"></use></svg> <span class="username">apachemxnet</span></a></li><li><a href="https://youtube.com/apachemxnet"><svg class="svg-icon"><use xlink:href="../../../_static/minima-social-icons.svg#youtube"></use></svg> <span class="username">apachemxnet</span></a></li></ul>
</div>

            <div class="col-4 footer-text">
                <p>A flexible and efficient library for deep learning.</p>
            </div>
        </div>
    </div>
</footer>

<footer class="site-footer2">
    <div class="wrapper">
        <div class="row">
            <div class="col-3">
                <img src="../../../_static/apache_incubator_logo.png" class="footer-logo col-2">
            </div>
            <div class="footer-bottom-warning col-9">
                <p>Apache MXNet is an effort undergoing incubation at <a href="http://www.apache.org/">The Apache Software Foundation</a> (ASF), <span style="font-weight:bold">sponsored by the <i>Apache Incubator</i></span>. Incubation is required
                    of all newly accepted projects until a further review indicates that the infrastructure,
                    communications, and decision making process have stabilized in a manner consistent with other
                    successful ASF projects. While incubation status is not necessarily a reflection of the completeness
                    or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
                </p><p>"Copyright Â© 2017-2018, The Apache Software Foundation Apache MXNet, MXNet, Apache, the Apache
                    feather, and the Apache MXNet project logo are either registered trademarks or trademarks of the
                    Apache Software Foundation."</p>
            </div>
        </div>
    </div>
</footer>
        
  </body>
</html>